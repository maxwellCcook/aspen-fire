{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a136f5eb-c1ce-4e26-a439-7a3fdf42508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Package imports and environment variables\n",
    "\"\"\"\n",
    "\n",
    "# Import modules and env vars\n",
    "\n",
    "import os, time, glob\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "import contextlib\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from shapely import geometry\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry.polygon import orient\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "\n",
    "# Projection information\n",
    "geog_crs = 'EPSG:4326'  # Geographic projection\n",
    "proj_crs = 'EPSG:5070'  # Projected coordinate system\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6802ae-919b-4eff-9789-0fcce26063e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Download_Extract_VIIRS_ActiveFires:\n",
    "    \"\"\" Class to handle downloading and extracting VIIRS active fire detections for a given polygon \"\"\"\n",
    "\n",
    "    def __init__(self, geom, start_date, last_date, out_dir, id_col,\n",
    "                 geog_crs='EPSG:4326', proj_crs='EPSG:5070', \n",
    "                 buffer=None, short_names=None, delete_ds=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            geom: Geodataframe (point or polygon);\n",
    "            start_date: the first date in the search request;\n",
    "            last_date: the final date for the search results;\n",
    "            out_dir: Output directory where results should be downloaded and processed;\n",
    "            id_col: the column in the geodataframe which contains the unique ID;\n",
    "            crs: Projection information, derfaults to WGS84;\n",
    "            buffer: an optional buffer (meters) to be applied to the active fire locations;\n",
    "            short_names: Optional list of actual short names to download\n",
    "\n",
    "        Returns a GeoDataFrame of active fire locations\n",
    "        \"\"\"\n",
    "\n",
    "        self.gdf = geom.copy()\n",
    "\n",
    "        self.geog_crs = geog_crs\n",
    "        self.proj_crs = proj_crs\n",
    "        \n",
    "        # Create the bounds for search request\n",
    "        self.bounds = geom.to_crs(geog_crs).unary_union.envelope # make sure it is in geographic coordinates\n",
    "        self.coords = list(self.bounds.exterior.coords)\n",
    "        \n",
    "        self.date_range = (start_date, last_date)\n",
    "        self.out_dir = out_dir\n",
    "        self.id = self.gdf[id_col].iloc[0] # grab the fire ID\n",
    "        self.buffer = buffer\n",
    "        if self.buffer:\n",
    "            buffer_gdf = geom.geometry.buffer(buffer)\n",
    "            bounds = buffer_gdf.to_crs(geog_crs).unary_union.envelope\n",
    "            self.coords_buffer = list(bounds.exterior.coords)\n",
    "            del buffer_gdf, bounds\n",
    "            \n",
    "        if not os.path.exists(self.out_dir):\n",
    "            os.makedirs(self.out_dir)\n",
    "        \n",
    "        if short_names is not None:\n",
    "            self.short_names = short_names\n",
    "        else:\n",
    "            self.short_names = ['VNP14IMG', 'VJ114IMG']\n",
    "\n",
    "        # Geolocation short_names:\n",
    "        self.geoloc = ['VNP03IMG', 'VJ103IMG']\n",
    "\n",
    "        if delete_ds is not None:\n",
    "            self.delete_ds = delete_ds\n",
    "        else:\n",
    "            self.delete_ds = False\n",
    "\n",
    "    def _get_area(self):\n",
    "        \"\"\"\n",
    "        Return area (km2) of the search bounds\n",
    "        \"\"\"\n",
    "        total_area_sqm = self.gdf.geometry.area.sum()\n",
    "        total_area_km2 = total_area_sqm / 1e6\n",
    "        return total_area_km2\n",
    "\n",
    "    def _search_request(self):\n",
    "        \"\"\"\n",
    "        Returns dictionary from the earthaccess search results including footprint geometry for each short_name\n",
    "        \"\"\"\n",
    "\n",
    "        print(f'Fire ID: {self.id}')\n",
    "\n",
    "        search_dict = {} # to store the search results\n",
    "\n",
    "        for short_name in self.short_names:\n",
    "            \n",
    "            try:\n",
    "                # Search for products matching our short names\n",
    "                result = earthaccess.search_data(\n",
    "                    short_name=short_name,\n",
    "                    polygon=self.coords,\n",
    "                    temporal=self.date_range,\n",
    "                    count=1000, \n",
    "                )\n",
    "                \n",
    "                # Check if there is valid data, if not, skip\n",
    "                if len(result) != 0:\n",
    "                    # Append the search results data frame to the dictionary\n",
    "                    search_dict[short_name] = result\n",
    "                else:\n",
    "                    raise ValueError(f'No data found for: {short_name} -- Polygon ID {self.id}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Skipping polygon ID {self.id}: {short_name}\")\n",
    "                continue\n",
    "\n",
    "        if not search_dict:\n",
    "            return None  # Return None for invalid search results\n",
    "        else:\n",
    "            return search_dict\n",
    "\n",
    "    def download_results(self, result_dict):\n",
    "        \"\"\" downloads earthaccess search results to the output directory \"\"\"\n",
    "        if result_dict is not None:\n",
    "            for key, result in result_dict.items():\n",
    "                folder_name = key # the short_name\n",
    "                # Set the output directory as the ID and short_name\n",
    "                fd = os.path.join(self.out_dir, f'FIRED_{self.id}/{key}/')\n",
    "                # Download the the search results\n",
    "                with open(os.devnull, 'w') as f, contextlib.redirect_stdout(f):\n",
    "                    earthaccess.download(result, local_path=fd)\n",
    "\n",
    "    def create_fire_gdf(self):\n",
    "        \"\"\" Creates a geodataframe with active fire detections from a directory with NetCDF files \"\"\"\n",
    "        \n",
    "        # List of downloaded .nc files\n",
    "        nc_files = list_files(self.out_dir, \"*.nc\", recursive=True)\n",
    "    \n",
    "        out_fire_dfs = [] # to store the dataframes for each nc file\n",
    "        for nc_file in nc_files:\n",
    "            \n",
    "            # Read the nc file\n",
    "            ds = Dataset(nc_file, 'r', format = 'NETCDF4')\n",
    "\n",
    "            # Grab some NetCDF attributes\n",
    "            day_night_flag = ds.getncattr('DayNightFlag')\n",
    "            short_name = ds.getncattr('ShortName')\n",
    "            platform = ds.getncattr('PlatformShortName')\n",
    "            version = ds.getncattr('VersionID')\n",
    "            start_time_str = ds.getncattr('PGE_StartTime')\n",
    "            acq_datetime = datetime.strptime(start_time_str, '%Y-%m-%d %H:%M:%S.%f') # convert to datetime\n",
    "            julian_day = acq_datetime.timetuple().tm_yday # Calculate Julian Day\n",
    "\n",
    "            # Grab an array of the lat/lons of fire detections\n",
    "            # Filter the granule data to within the fire bounds\n",
    "            # fire_coords = get_coords(self.gdf, buffer=0.375)\n",
    "            fire_coords = self.coords_buffer\n",
    "            flats = np.array(ds.variables['FP_latitude'][:])  # lats as np array\n",
    "            flons = np.array(ds.variables['FP_longitude'][:])  # lons as np array\n",
    "            fll = np.logical_and.reduce(\n",
    "                (flons >= fire_coords[0][0], flons <= fire_coords[2][0], flats >= fire_coords[0][1], flats <= fire_coords[2][1]))\n",
    "    \n",
    "            # Extract fire pixel information\n",
    "            lats = flats[fll]\n",
    "            lons = flons[fll]\n",
    "            frp = np.array(ds.variables['FP_power'][:])[fll]\n",
    "            confidence = np.array(ds.variables['FP_confidence'][:])[fll]\n",
    "            fp_rad13 = np.array(ds.variables['FP_Rad13'][:])[fll]\n",
    "            fp_t4 = np.array(ds.variables['FP_T4'][:])[fll]\n",
    "            fp_t5 = np.array(ds.variables['FP_T5'][:])[fll]\n",
    "            view_az = np.array(ds.variables['FP_ViewAzAng'][:])[fll]\n",
    "            view_zen = np.array(ds.variables['FP_ViewZenAng'][:])[fll]\n",
    "\n",
    "            del ds, flats, flons, fll # clean up\n",
    "    \n",
    "            # Create a DataFrame with the fire pixel data\n",
    "            df = pd.DataFrame({\n",
    "                'fired_id': fire_id,\n",
    "                'acq_datetime': acq_datetime,\n",
    "                'acq_julian_day': julian_day,\n",
    "                'day_night': day_night_flag,\n",
    "                'short_name': short_name,\n",
    "                'platform': platform,\n",
    "                'version': version,\n",
    "                'latitude': lats,\n",
    "                'longitude': lons,\n",
    "                'frp': frp,\n",
    "                'fp_rad13': fp_rad13,\n",
    "                'fp_t4': fp_t4,\n",
    "                'fp_t5': fp_t5,\n",
    "                'confidence': confidence,\n",
    "                'view_az_an': view_az,\n",
    "                'view_zen_an': view_zen\n",
    "            })\n",
    "    \n",
    "            out_fire_dfs.append(df)\n",
    "    \n",
    "            # Clean up\n",
    "            if self.delete_ds is True:\n",
    "                os.remove(nc_file)\n",
    "\n",
    "            gc.collect() # garbage collector\n",
    "    \n",
    "        # Concatenate the out dfs\n",
    "        fire_data = pd.concat(out_fire_dfs) # for the entire fire\n",
    "        \n",
    "        # Create a GeoDataFrame\n",
    "        fp_points = gpd.GeoDataFrame(\n",
    "            fire_data, \n",
    "            geometry=gpd.points_from_xy(fire_data.longitude, fire_data.latitude),\n",
    "            crs=self.geog_crs) # Geographic coordinates\n",
    "        # Reproject to projected coordinate system\n",
    "        fp_points = fp_points.to_crs(self.proj_crs)\n",
    "\n",
    "        del fire_data\n",
    "\n",
    "        return fp_points\n",
    "            \n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "def get_coords(geom, buffer):\n",
    "    \"\"\" Returns the bounding box coordinates for a given geometry(ies) and buffer \"\"\"\n",
    "    geom['geometry'] = geom.geometry.buffer(buffer)\n",
    "    bounds = geom.to_crs(geog_crs).unary_union.envelope # make sure it is in geographic coordinates\n",
    "    coords = list(bounds.exterior.coords)\n",
    "    return coords\n",
    "    \n",
    "\n",
    "def pixel_buffer(gdf, pixel_size=375):\n",
    "    \"\"\"\n",
    "    Create square buffers (at nadir pixel) around points.\n",
    "    \"\"\"\n",
    "    buffers = gdf.geometry.apply(lambda point: box(\n",
    "        point.x - pixel_size / 2, point.y - pixel_size / 2,\n",
    "        point.x + pixel_size / 2, point.y + pixel_size / 2\n",
    "    ))\n",
    "    return gpd.GeoDataFrame(gdf.drop(columns='geometry'), geometry=buffers)\n",
    "\n",
    "\n",
    "def handle_duplicates(gdf):\n",
    "    \"\"\" Handles duplicate fire detections, retaining one \"\"\"\n",
    "    \n",
    "\n",
    "print(\"Class and functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0e1cf-749f-4778-977c-738c389ab997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "fires = gpd.read_file(os.path.join(maindir,'Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg'))\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f318f40-f772-49ce-9f3e-48714f874dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the download class for the fire perimeters individually\n",
    "outdir = os.path.join(maindir, 'Aim2/data/spatial/raw/VIIRS/')\n",
    "resdir = os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/')\n",
    "if not os.path.exists(resdir):\n",
    "    os.makedirs(resdir)\n",
    "\n",
    "# Get a list of fire IDs\n",
    "fire_ids = fires['fired_id'].unique()\n",
    "\n",
    "fp_points = [] # to store the output geodataframes\n",
    "no_data_ids = [] # to store fire IDs with no data available\n",
    "        \n",
    "for fire_id in fire_ids[0:5]:\n",
    "    # Retrieve the fire perimeter\n",
    "    fire = fires[fires['fired_id'] == fire_id]  \n",
    "    \n",
    "    # Initiate the download and extract class\n",
    "    downloader = Download_Extract_VIIRS_ActiveFires(\n",
    "        geom=fire,\n",
    "        start_date=fire['ig_date'].iloc[0],\n",
    "        last_date=fire['last_date'].iloc[0],\n",
    "        out_dir=outdir,\n",
    "        id_col='fired_id',\n",
    "        buffer=1000, # in meters?\n",
    "        short_names=['VNP14IMG', 'VJ114IMG', 'VNP03MODLL', 'VJ103MODLL'],\n",
    "        delete_ds=False\n",
    "    )\n",
    "    \n",
    "    # Retrieve the search results\n",
    "    try:\n",
    "        search_results = downloader._search_request()\n",
    "        if len(search_results) > 0:\n",
    "            # Downlaod the search results\n",
    "            downloader.download_results(search_results)\n",
    "            # Create the geodataframe, append to output list\n",
    "            fp_points_fire = downloader.create_fire_gdf()\n",
    "            fp_points.append(fp_points_fire)\n",
    "        else:\n",
    "            raise ValueError(f'No data found for {self.id}, skipping completely !')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping FIRED ID {fire_id}\\n{e}\")\n",
    "        no_data_ids.append(fire_id)\n",
    "        continue  # continue to the next fire id\n",
    "\n",
    "# Concatenate the results\n",
    "fp_points = gpd.GeoDataFrame(pd.concat(fp_points, ignore_index=True))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dab880-c386-42a3-a1d2-b6215adf92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507676bf-b4bb-4401-b4b3-de218acedf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fp_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0b7f7-21fb-48b3-afd8-975c385ffeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_points.to_file(os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/viirs_afd_geo_points.gpkg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe7c56-5eec-4f43-9491-8ab7d243dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pixel area\n",
    "fp_pixels = pixel_buffer(fp_points)\n",
    "fp_pixels.to_file(os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/viirs_afd_geo_pixels.gpkg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d230f1-f4a1-4afb-a7e0-2402e3fe1396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e82de-59c7-4e19-bd66-dcc46c25e1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd18d00-4685-46e7-a2ef-ccf2ed178972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f31a5b-9bd8-45fd-b418-d927373c0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(fp_points, time_threshold=8, distance_threshold=375):\n",
    "    \"\"\"\n",
    "    Remove duplicate fire detections based on time difference and spatial distance.\n",
    "    \n",
    "    Args:\n",
    "        fp_points (GeoDataFrame): GeoDataFrame containing fire detections with geometry and FRP information.\n",
    "        time_threshold (int): Time difference threshold in seconds.\n",
    "        distance_threshold (float): Distance threshold in meters (along-track dimension of the fire pixels).\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: Filtered GeoDataFrame with duplicates removed and FRP corrected.\n",
    "    \"\"\"\n",
    "    # Convert acquisition datetime to datetime if not already\n",
    "    if not pd.api.types.is_datetime64_any_dtype(fp_points['acq_datetime']):\n",
    "        fp_points['acq_datetime'] = pd.to_datetime(fp_points['acq_datetime'])\n",
    "\n",
    "    # Sort by acquisition datetime\n",
    "    fp_points = fp_points.sort_values(by='acq_datetime').reset_index(drop=True)\n",
    "\n",
    "    # Create a copy to store the final filtered results\n",
    "    filtered_fp_points = fp_points.copy()\n",
    "\n",
    "    # List to store indexes of duplicates to be removed\n",
    "    duplicates_to_remove = []\n",
    "\n",
    "    for i, point in fp_points.iterrows():\n",
    "        if i in duplicates_to_remove:\n",
    "            continue\n",
    "        \n",
    "        # Filter points within the time threshold\n",
    "        time_filtered = fp_points[\n",
    "            (fp_points['acq_datetime'] >= point['acq_datetime'] - timedelta(seconds=time_threshold)) &\n",
    "            (fp_points['acq_datetime'] <= point['acq_datetime'] + timedelta(seconds=time_threshold))\n",
    "        ]\n",
    "\n",
    "        for j, other_point in time_filtered.iterrows():\n",
    "            if i == j or j in duplicates_to_remove:\n",
    "                continue\n",
    "            \n",
    "            # Calculate distance between points\n",
    "            distance = point.geometry.distance(other_point.geometry)\n",
    "\n",
    "            if distance <= distance_threshold:\n",
    "                # Found a duplicate, retain one and remove the other\n",
    "                duplicates_to_remove.append(j)\n",
    "                # Average the FRP values\n",
    "                filtered_fp_points.loc[i, 'frp'] = (point['frp'] + other_point['frp']) / 2\n",
    "\n",
    "    # Remove duplicates\n",
    "    filtered_fp_points = filtered_fp_points.drop(index=duplicates_to_remove).reset_index(drop=True)\n",
    "\n",
    "    return filtered_fp_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be86d6-e418-45ae-975b-2e5e80dc7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_fp_points = remove_duplicates(fp_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0a414-154f-45d6-a41f-6443996fcf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_fp_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37727b40-cb17-40fe-aff9-71f97699df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pixel area\n",
    "fp_pixels = pixel_buffer(filtered_fp_points)\n",
    "fp_pixels.to_file(os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/viirs_afd_geo_pixels_rm.gpkg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ae497-e4fe-4161-a9bb-d2e12a57d193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5841a01-8582-411c-8f57-9192e704eef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bba84-ae4f-436c-be7e-2b9f5d67e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mosaic_frp_tif(afd_data, perim, fire_id, crs, out_dir):\n",
    "    \"\"\" \n",
    "    Creates a mosaic tif file from the active fire data for a given perimeter \n",
    "    Args:\n",
    "        afd_data: GeoDataFrame with active fire detection data\n",
    "        perim: the polygon perimeter to create the geotiff\n",
    "        crs: the projected coordinate system\n",
    "    Returns: Single geotiff file representing the FRP of the first day-of-burn for each short_name (satellite)\n",
    "    \"\"\"\n",
    "\n",
    "    platforms = afd_data['platform'].unique()\n",
    "\n",
    "    # Convert perimeter to the specified CRS\n",
    "    perim = perim.to_crs(crs)\n",
    "    perim['geometry'] = perim.unary_union.envelope     \n",
    "    \n",
    "    # Define the regular grid\n",
    "    minx, miny, maxx, maxy = perim.total_bounds\n",
    "    pixel_size = 375  # Approx. 375 m resolution\n",
    "    nrows = int((maxy - miny) / pixel_size)\n",
    "    ncols = int((maxx - minx) / pixel_size)\n",
    "    transform = from_origin(minx, maxy, pixel_size, pixel_size)\n",
    "\n",
    "    for platform in platforms:\n",
    "        for day_night in ['Day', 'Night']:\n",
    "            # Filter data by platform and day/night flag\n",
    "            afd_ = afd_data[(afd_data['platform'] == platform) & (afd_data['day_night'] == day_night)].copy()\n",
    "\n",
    "            # Create an empty raster array for Julian day (first day of burn), FRP on first day of burn, and maximum FRP\n",
    "            julian_arr = np.full((nrows, ncols), np.nan) # Julian day of first burn\n",
    "            frp_arr = np.full((nrows, ncols), np.nan) # FRP od first day of burn\n",
    "            date_arr = np.full((nrows, ncols), np.nan)\n",
    "\n",
    "            daily_frp_list = [] # store the daily arrays of julian day\n",
    "            daily_jul_list = [] # store the daily arrays of FRP\n",
    "            daily_date_list = []\n",
    "            \n",
    "            # Group data by day\n",
    "            afd_.loc[:, 'date'] = afd_['acq_datetime'].dt.date\n",
    "\n",
    "            for date in afd_['date'].unique():\n",
    "                \n",
    "                afd_day = afd_[afd_['date'] == date].copy()\n",
    "\n",
    "                # Create individual grids for each observation time within the day\n",
    "                day_grids = []\n",
    "                for time_ in afd_day['acq_datetime'].unique():\n",
    "                    afd_time = afd_day[afd_day['acq_datetime'] == time_].copy()\n",
    "                    afd_time_rast = rasterize_afd(afd_time, transform, (nrows, ncols))\n",
    "                    day_grids.append(afd_time_rast)\n",
    "\n",
    "                # Merge grids by taking the 99th percentile pixel values\n",
    "                if len(day_grids) == 1:\n",
    "                    max_grid = day_grids[0]\n",
    "                elif len(day_grids) > 1:\n",
    "                    combined_grids = np.array(day_grids)\n",
    "                    max_grid = np.nanmax(combined_grids, axis=0)\n",
    "                else:\n",
    "                    max_grid = np.full((nrows, ncols), np.nan) # keep the empty grid\n",
    "\n",
    "                # Update the first burn day and FRP rasters\n",
    "                mask = np.isnan(julian_arr) & (max_grid > 0)\n",
    "                julian_arr[mask] = date.timetuple().tm_yday\n",
    "                frp_arr[mask] = max_grid[mask]\n",
    "                date_arr[mask] = date.year * 10000 + date.month * 100 + date.day\n",
    "                \n",
    "                # Append daily arrays to lists\n",
    "                daily_frp_list.append(max_grid)\n",
    "                daily_jul_list.append(np.full((nrows, ncols), date.timetuple().tm_yday))\n",
    "                daily_date_list.append(np.full((nrows, ncols), date.year * 10000 + date.month * 100 + date.day))\n",
    "            \n",
    "            # Calculate the maximum FRP and the day of maximum FRP across all days\n",
    "            max_frp_arr = np.nanmax(np.array(daily_frp_list), axis=0)\n",
    "            day_max_frp_arr = np.full((nrows, ncols), np.nan)\n",
    "            date_max_frp_arr = np.full((nrows, ncols), np.nan)\n",
    "\n",
    "            for i in range(nrows):\n",
    "                for j in range(ncols):\n",
    "                    if not np.isnan(max_frp_arr[i, j]):\n",
    "                        max_index = np.nanargmax([day_grid[i, j] for day_grid in daily_frp_list])\n",
    "                        day_max_frp_arr[i, j] = daily_jul_list[max_index][i, j]\n",
    "                        date_max_frp_arr[i, j] = daily_date_list[max_index][i, j]\n",
    "\n",
    "            # Ensure pixels with no active fire data remain NaN\n",
    "            max_frp_arr[np.isnan(max_frp_arr)] = np.nan\n",
    "            day_max_frp_arr[np.isnan(day_max_frp_arr)] = np.nan\n",
    "            date_max_frp_arr[np.isnan(date_max_frp_arr)] = np.nan\n",
    "            \n",
    "            # Create multiband raster\n",
    "            out_tif = os.path.join(out_dir, f'{platform}_{fire_id}_{day_night}_mb.tif')\n",
    "\n",
    "            with rio.open(\n",
    "                out_tif, 'w', driver='GTiff', height=nrows, width=ncols, count=5, dtype='float32',\n",
    "                crs=crs, transform=transform\n",
    "            ) as dst:\n",
    "                dst.write(julian_arr, 1)\n",
    "                dst.write(frp_arr, 2)\n",
    "                dst.write(day_max_frp_arr, 3)\n",
    "                dst.write(max_frp_arr, 4)\n",
    "                dst.write(date_max_frp_arr, 5)\n",
    "                \n",
    "    return out_tif\n",
    "    \n",
    "\n",
    "def rasterize_afd(day_data, transform, out_shape):\n",
    "    \"\"\"\n",
    "    Rasterize the day's data to a numpy array.\n",
    "    Args:\n",
    "        day_data: GeoDataFrame with day's active fire detection data\n",
    "        transform: Affine transform for the output raster\n",
    "        out_shape: Shape of the output raster\n",
    "    Returns: Numpy array of the rasterized FRP values\n",
    "    \"\"\"\n",
    "    geometries = [(geom, value) for geom, value in zip(day_data.geometry, day_data['frp'])]\n",
    "    \n",
    "    day_raster = rasterize(\n",
    "        geometries,\n",
    "        out_shape=out_shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype='float32',\n",
    "        all_touched=True\n",
    "    )\n",
    "    return day_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558291e-93c2-4221-8452-0a8b5801c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the day/night mosaics\n",
    "\n",
    "fire_ids_new = fp_points['fired_id'].unique()\n",
    "\n",
    "mosaic_dir = os.path.join(maindir, 'Aim2/data/spatial/mod/VIIRS/grids/')\n",
    "if not os.path.exists(mosaic_dir):\n",
    "    os.makedirs(mosaic_dir)\n",
    "    \n",
    "for fire_id in fire_ids_new:\n",
    "    print(f'Creating mosaic rasters for: {fire_id}')\n",
    "    \n",
    "    perim = fires[fires['fired_id'] == fire_id].copy()\n",
    "    perim['geometry'] = perim.geometry.buffer(1000) # same buffer as was used to extract\n",
    "    \n",
    "    fp_da = fp_points[fp_points['fired_id'] == fire_id].copy()\n",
    "    \n",
    "    create_mosaic_frp_tif(fp_da, perim, fire_id, crs=proj_crs, out_dir=mosaic_dir)\n",
    "    \n",
    "    print('\\n ~~~ \\n')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "c3d482be-361d-4286-b949-6680bf24babb",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "albers = 'EPSG:5070' # albers CONUS\n",
    "utm = 'EPSG:32613' # UTM Zone 13N\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/'\n",
    "projdir = os.path.join(maindir, 'aspen-fire/Aim2/')\n",
    "\n",
    "print(\"Ready to go !\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af7d2100-d318-41ce-970d-7686f0359b88",
   "metadata": {},
   "source": [
    "# load the aggregated FRP grids (regular 375m2 grids summarizing FRP from VIIRS)\n",
    "fp = os.path.join(projdir,'data/spatial/mod/VIIRS/viirs_snpp_jpss1_afd_latlon_fires_pixar_gridstats.gpkg')\n",
    "grid = gpd.read_file(fp)\n",
    "print(f\"\\nThere are [{len(grid)}] grids across [{len(grid['Fire_ID'].unique())}] fires.\\n\")\n",
    "\n",
    "# create a unique ID\n",
    "grid['grid_idx'] = grid['Fire_ID'].astype(str) + grid['grid_index'].astype(str)\n",
    "\n",
    "# add the centroid lat/lon to the grid data\n",
    "df = grid.to_crs(4326) # WGS coords for lat/lon\n",
    "df['x'] = df.geometry.centroid.x  # Longitude (x-coordinate)\n",
    "df['y'] = df.geometry.centroid.y  # Latitude\n",
    "grid = grid.merge(df[['grid_idx','x','y']], on='grid_idx', how='left')\n",
    "del df\n",
    "print(f\"\\n{grid.columns}\\n\")\n",
    "\n",
    "# Drop any duplicate grids ...\n",
    "print(f\"Dropping [{grid.duplicated(subset=['grid_idx','Fire_ID']).sum()}] duplicate grids.\\n\")\n",
    "grid = grid.drop_duplicates(subset=['grid_idx','Fire_ID'], keep='first')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a764d47-cb80-444c-90cb-1afbd44746b0",
   "metadata": {},
   "source": [
    "# Check out the distribution of grid overlap with FRP observations\n",
    "thresh = 0.50\n",
    "print(f\"Fractional overlap:\\n{grid['overlap'].describe()}\\n\")\n",
    "n_small = grid[grid['overlap'] < thresh]['grid_idx'].count() \n",
    "\n",
    "# Plot the distribution of the fractional overlap\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(grid['overlap'], kde=True, bins=50, color='dodgerblue', alpha=0.7)\n",
    "\n",
    "# Add vertical line for the threshold and for 100%\n",
    "plt.axvline(x=thresh, color='red', linestyle='--', label=f'{thresh*100}% Threshold')\n",
    "plt.axvline(x=1, color='grey', linestyle='--', label='100% Overlap')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Cumulative Fractional Overlap')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.text(16.5, plt.ylim()[1] * 0.7, \n",
    "         f'N = {n_small} [{round(n_small/len(grid)*100,2)}%]', \n",
    "         fontsize=10, color='black')\n",
    "\n",
    "# Save the plot\n",
    "out_path = os.path.join(projdir, 'figures/grid_overlap_distribution.png')\n",
    "plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "print(f\"Plot saved to: {out_path}\")\n",
    "\n",
    "# filter out grids below the overlap threshold\n",
    "print(f\"\\nDropping [{n_small} ({round(n_small/len(grid)*100,2)}%)] grids with <{thresh*100}% fractional overlap.\")\n",
    "grid = grid[grid['overlap'] >= thresh] # remove these observations\n",
    "print(len(grid))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Gather LANDFIRE variables for the study region\n",
    "\n",
    "LANDFIRE ca. 2016; [EVT, CC, CH, CBD, CBH, ]"
   ],
   "id": "1ddae7e0d617d259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fuel_vars = {\n",
    "    'CC': 'https://lfps.usgs.gov/arcgis/rest/services/Landfire_LF200/US_200CC_19/ImageServer',\n",
    "    'CH': 'https://lfps.usgs.gov/arcgis/rest/services/Landfire_LF200/US_200CH_19/ImageServer',\n",
    "    'CBD': 'https://lfps.usgs.gov/arcgis/rest/services/Landfire_LF200/US_200CBD_19/ImageServer',\n",
    "    'CBH': 'https://lfps.usgs.gov/arcgis/rest/services/Landfire_LF200/US_200CBH_19/ImageServer'\n",
    "}\n",
    "\n",
    "# reproject the grid and get the bounds\n",
    "grid_wgs = grid.to_crs('EPSG:4326')\n",
    "\n",
    "# grab the EVT raster to use for zones\n",
    "evt_url = 'https://lfps.usgs.gov/arcgis/rest/services/Landfire_LF200/US_200EVT/ImageServer'\n",
    "print(f\"Downloading the EVT raster from: {evt_url}\")\n",
    "evt_da = get_image_service_array(evt_url, grid_wgs, out_prefix='EVT')\n",
    "\n",
    "# crop to gridcells\n",
    "# match the CRS\n",
    "grid_prj = grid.to_crs(evt_da.rio.crs)\n",
    "# create the crop extent\n",
    "bbox = box(*grid_prj.total_bounds) # make a bounding box\n",
    "bbox = gpd.GeoDataFrame(geometry=[bbox], crs='EPSG:5070')\n",
    "evt_da = evt_da.rio.clip(bbox.geometry) # do the crop\n",
    "\n",
    "# get a list of EVT values\n",
    "evt_arr = evt_da.values\n",
    "evt_nodata = evt_da.rio.nodata\n",
    "evt_vals = np.unique(evt_arr)\n",
    "evt_vals = evt_vals[~np.isnan(evt_vals) & (evt_vals != evt_nodata)]\n",
    "print(f\"Found [{len(evt_vals)}] EVT codes\")\n",
    "del evt_nodata, evt_arr"
   ],
   "id": "9ef707ae46a4ba05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# identify EVT codes of interest\n",
    "# first, download the data dictionary\n",
    "dd = list_files(os.getcwd(),'*EVT.csv',recursive=True)[0]\n",
    "print(dd)\n",
    "if not dd:\n",
    "    print(\"Downloading data dictionary\")\n",
    "    dd = download_lf_csv('EVT')\n",
    "else:\n",
    "    dd = pd.read_csv(dd)\n",
    "# merge with the codes\n",
    "evt_vals_df = pd.DataFrame({'EVT': evt_vals.astype(int)})\n",
    "evt_df = evt_vals_df.merge(dd, left_on='EVT', right_on='VALUE')\n",
    "evt_df"
   ],
   "id": "294444a2b230544b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evt_df.columns",
   "id": "1589060ef47a5ad1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evt_df['EVT_SBCLS'].unique()",
   "id": "7a4fa2db469a3659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# filter to forested EVTs, look at the SAF code\n",
    "trees_shrubs = ['Deciduous open tree canopy', 'Evergreen open tree canopy',\n",
    "                'Evergreen closed tree canopy', 'Mixed evergreen-deciduous open tree canopy',\n",
    "                'Evergreen sparse tree canopy']\n",
    "evt_df_tree = evt_df[evt_df['EVT_SBCLS'].isin(trees_shrubs)]\n",
    "evt_df_tree['SAF_SRM'].unique()"
   ],
   "id": "dfdffb2577b5cbf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# filter to species of interest using the SAF code\n",
    "saf_keep = [\n",
    "    'SAF 217: Aspen',\n",
    "    'SRM 504: Juniper-Pinyon Pine Woodland',\n",
    "    'SAF 218: Lodgepole Pine',\n",
    "    'SAF 210: Interior Douglas-Fir',\n",
    "    'SAF 211: White Fir',\n",
    "    'SAF 237: Interior Ponderosa Pine',\n",
    "    'SAF 206: Engelmann Spruce-Subalpine Fir',\n",
    "    'LF 41: Deciduous Shrubland'\n",
    "]\n",
    "\n",
    "# gather new set of EVT codes:\n",
    "evt_df_tree_evt = evt_df_tree[evt_df_tree['SAF_SRM'].isin(saf_keep)]\n",
    "print(f\"Filtered to [{len(evt_df_tree_evt['EVT'].unique())}] EVT codes\")"
   ],
   "id": "bdc2f48a59c36d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the fuels arrays\n",
    "print(\"\\nAccessing fuel rasters\")\n",
    "\n",
    "fuel_arrs = {} # to store the results\n",
    "for var, url in fuel_vars.items():\n",
    "    print(f\"\\nDownloading [{var}] raster from: {url}\")\n",
    "    # get the raster\n",
    "    da = get_image_service_array(url, grid_wgs, out_prefix=var)\n",
    "    # crop it using the bounding box we created earlier\n",
    "    da = da.rio.clip(bbox.geometry) # crop to the extent bounds\n",
    "    # add to the results dictionary\n",
    "    fuel_arrs[var] = da\n",
    "    del da\n",
    "\n",
    "print(\"\\nFuel rasters successfully processed\")"
   ],
   "id": "fb1150233e966d99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Gather the USFS TreeMap bands (ca. 2016)\n",
    "\n",
    "BALIVE, SDI, and QMD"
   ],
   "id": "54aa5c4aa4feb99f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load the TreeMap rasters (locally stored)\n",
    "tm_paths = {\n",
    "    'BALIVE': list_files(os.path.join(maindir, 'data/landcover/USFS/RDS_TreeMap/'), ext='*_BALIVE.tif', recursive=True)[0],\n",
    "    'SDI': list_files(os.path.join(maindir, 'data/landcover/USFS/RDS_TreeMap/'), ext='*SDI*.tif', recursive=True)[0],\n",
    "    'QMD': list_files(os.path.join(maindir, 'data/landcover/USFS/RDS_TreeMap/'), ext='*QMD*.tif', recursive=True)[0]\n",
    "}\n",
    "print(tm_paths, \"\\n\")\n",
    "\n",
    "# store the cropped arrays\n",
    "tm_arrs = {}\n",
    "ref = next(iter(fuel_arrs.values()))  # reference raster\n",
    "for tm, fp in tm_paths.items():\n",
    "    print(f\"\\nProcessing [{tm}]\")\n",
    "    # open the raster files\n",
    "    with rio.open(fp) as src:\n",
    "        bounds = grid.to_crs(src.crs).total_bounds\n",
    "        window = from_bounds(*bounds, transform=src.transform)\n",
    "        data = src.read(1, window=window)\n",
    "\n",
    "        # Build spatial coordinates\n",
    "        transform = src.window_transform(window)\n",
    "        height, width = data.shape\n",
    "        x_coords = np.arange(width) * transform.a + transform.c + transform.a / 2\n",
    "        y_coords = np.arange(height) * transform.e + transform.f + transform.e / 2\n",
    "\n",
    "        da = xr.DataArray(\n",
    "            data,\n",
    "            dims=(\"y\", \"x\"),\n",
    "            coords={\"y\": y_coords, \"x\": x_coords},\n",
    "            name=tm\n",
    "        )\n",
    "        da.rio.write_crs(src.crs, inplace=True)\n",
    "        da.rio.write_transform(transform, inplace=True)\n",
    "\n",
    "        # reproject to match the reference\n",
    "        da_prj = da.rio.reproject_match(ref)\n",
    "\n",
    "        tm_arrs[tm] = da_prj # add to the array dictionary\n",
    "        del da, da_prj\n",
    "\n",
    "print(\"\\nProcessing TreeMap layers complete.\")"
   ],
   "id": "f4790755400e598d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create the data stack and convert to dataframe summary\n",
    "\n",
    "Stack the EVT and fuels arrays, the TreeMap bands, and a rasterized 'grid_idx' into one multiband array. Then, convert to a data frame and calculate the EVT-specific fuel conditions for each 'grid_idx'."
   ],
   "id": "aafa7e229022082"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a raster grid for grid_idx to use as zones\n",
    "# convert grid_idx to numeric\n",
    "grid_prj['grid_idx'] = pd.to_numeric(grid_prj['grid_idx'], errors='coerce')\n",
    "grid_idx_da = rasterize_grid_idx(grid_prj, ref_da=evt_da)\n",
    "print(\"Created the 'grid_idx' raster\")\n",
    "print(f\"Output shape: {grid_idx_da.shape}\")\n",
    "print(f\"Reference image shape: {evt_da.shape}\")"
   ],
   "id": "d1cd7ca01800765f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# stack the bands\n",
    "da_stack = xr.Dataset({\n",
    "    var: da\n",
    "    for var, da in fuel_arrs.items()\n",
    "})\n",
    "\n",
    "# add the EVT, TreeMap and grid_idx\n",
    "da_stack['EVT'] = evt_da\n",
    "da_stack['BALIVE'] = tm_arrs['BALIVE']\n",
    "da_stack['SDI'] = tm_arrs['SDI']\n",
    "da_stack['QMD'] = tm_arrs['QMD']\n",
    "da_stack['grid_idx'] = grid_idx_da\n",
    "\n",
    "da_stack"
   ],
   "id": "efb95348ec8cc8e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gather the dataframe\n",
    "df = da_stack.to_dataframe().reset_index()\n",
    "df = df.dropna(subset=['EVT']) # keep valid rows\n",
    "df = df[df['grid_idx'] != 0] # filter where grid_idx != 0 (background)\n",
    "# filter to EVT codes of interest\n",
    "df = df[df['EVT'].isin(evt_df_tree_evt['EVT'].unique())]\n",
    "df['EVT'] = df['EVT'].astype(int) # force EVT code to integer\n",
    "\n",
    "# group and summarize by grid_idx\n",
    "df = df.groupby(['grid_idx','EVT']).agg({\n",
    "    'CC': 'mean',\n",
    "    'CH': 'mean',\n",
    "    'CBH': 'mean',\n",
    "    'CBD': 'mean',\n",
    "    'BALIVE': 'mean',\n",
    "    'SDI': 'mean',\n",
    "    'QMD': 'mean'\n",
    "}).reset_index()\n",
    "df.head()"
   ],
   "id": "991fc1a710cf4aaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# join the EVT names\n",
    "dd_ = dd[['VALUE','SAF_SRM']]\n",
    "grid_evt = df.merge(dd_, left_on='EVT', right_on='VALUE')\n",
    "grid_evt"
   ],
   "id": "77c2079fc5d6217d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(len(grid_evt))\n",
    "print(grid_evt['SDI'].isna().sum())\n",
    "grid_evt[grid_evt['SDI'].isna()]['SAF_SRM'].value_counts()"
   ],
   "id": "f759d1e24406d81a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# manage the EVT values, reclassing\n",
    "grid_evt['SAF_SRM'].unique()"
   ],
   "id": "72137c68c6a25940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aggregate species into forest groups\n",
    "# These groups represent common pairings for the Southern Rockies\n",
    "spp_grouping = {\n",
    "    'SAF 217: Aspen': 'Aspen',\n",
    "    'SAF 206: Engelmann Spruce-Subalpine Fir': 'Spruce-fir',\n",
    "    'SAF 237: Interior Ponderosa Pine': 'Ponderosa pine',\n",
    "    'SAF 218: Lodgepole Pine': 'Lodgepole pine',\n",
    "    'SAF 210: Interior Douglas-Fir': 'Douglas-fir',\n",
    "    'SAF 211: White Fir': 'White fir',\n",
    "    'SRM 504: Juniper-Pinyon Pine Woodland': 'Pinon-juniper',\n",
    "}\n",
    "\n",
    "# create the remap table\n",
    "spp_remap = {} # dictionary to store the remap values\n",
    "# Iterate over groups to create the species remap dictionary\n",
    "for keywords, spp_group in spp_grouping.items():\n",
    "    # Find species matching the keywords\n",
    "    spp = grid_evt[grid_evt['SAF_SRM'].str.contains(keywords, case=False, na=False)]\n",
    "    # Add matching species to the remap dictionary\n",
    "    spp_remap.update(\n",
    "        {name: spp_group for name in spp['SAF_SRM'].unique()}\n",
    "    )\n",
    "    del spp\n",
    "\n",
    "# Apply the remap to create a new grouped species column\n",
    "grid_evt['fortypnm_gp'] = grid_evt['SAF_SRM'].map(spp_remap).fillna(grid_evt['SAF_SRM'])\n",
    "\n",
    "# separate the aspen classes\n",
    "# Override with EVT-based rule for Aspen separation\n",
    "grid_evt.loc[grid_evt['EVT'] == 7011, 'fortypnm_gp'] = 'Aspen'\n",
    "grid_evt.loc[grid_evt['EVT'] == 7061, 'fortypnm_gp'] = 'Aspenâ€“Mixed'\n",
    "\n",
    "# Verify the updated species groups\n",
    "grid_evt[['grid_idx', 'SAF_SRM', 'fortypnm_gp']].drop_duplicates().head(8)"
   ],
   "id": "f61ad2ef84ee63fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate the EVT proportion per gridcell\n",
    "zs_evt = compute_band_stats(grid_prj, evt_da, id_col='grid_idx', attr='EVT')\n",
    "# tidy the data frame\n",
    "zs_evt = zs_evt[['grid_idx', 'EVT', 'pct_cover']]\n",
    "zs_evt.rename(columns={'pct_cover': 'proportion'}, inplace=True)\n",
    "zs_evt"
   ],
   "id": "ba7dcdac18bb01aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# merge the EVT proportion\n",
    "grid_evt_pr = grid_evt.merge(zs_evt, on=['grid_idx', 'EVT'])\n",
    "grid_evt_pr"
   ],
   "id": "b75f756024f68a67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# group and recalculate fuel characteristics\n",
    "grid_evt_rg = (\n",
    "    grid_evt_pr\n",
    "    .groupby(['grid_idx', 'fortypnm_gp'])\n",
    "    .agg({\n",
    "        'proportion': 'sum',\n",
    "        'CC': 'mean',\n",
    "        'CH': 'mean',\n",
    "        'CBH': 'mean',\n",
    "        'CBD': 'mean',\n",
    "        'BALIVE': 'mean',\n",
    "        'SDI': 'mean',\n",
    "        'QMD': 'mean'\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "grid_evt_rg"
   ],
   "id": "a0de8d18970d98bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# tidy some of the columns\n",
    "grid_evt_pr = grid_evt_pr[['grid_idx', 'fortypnm_gp', 'proportion', 'CC', 'CH', 'CBH', 'CBD', 'BALIVE', 'SDI', 'QMD']]\n",
    "# save this file out.\n",
    "out_fp = os.path.join(projdir,'data/tabular/mod/gridstats_lf.csv')\n",
    "grid_evt_pr.to_csv(out_fp)\n",
    "print(f\"Saved file to: {out_fp}\")"
   ],
   "id": "23dcfd0aa77342a0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

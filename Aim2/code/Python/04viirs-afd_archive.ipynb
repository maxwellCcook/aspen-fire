{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49947ce4-1f30-4924-896d-542778ac24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import os, time, glob, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "\n",
    "from shapely.geometry import box\n",
    "from datetime import datetime\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # suppresses annoying geopandas warning\n",
    "\n",
    "proj = 'EPSG:5070'\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/'\n",
    "projdir = os.path.join(maindir, 'aspen-fire/Aim2/')\n",
    "\n",
    "print(\"Ready to go !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad1174f-72bd-4e7f-8716-a96ee53ac573",
   "metadata": {},
   "source": [
    "## Wrangle the MODIS 1km and VIIRS 375m Active Fire Detections (AFD)\n",
    "\n",
    "We downloaded the archive AFD for MODIS Collection 6.1 (1km), the Suomi National Polar-Orbiting Partnership (VIIRS S-NPP 375m) and NOAA-20 (VIIRS NOAA-20 375m) data products from the NASA FIRMS (https://firms.modaps.eosdis.nasa.gov/download/) between 2018-2023 in the western US. \n",
    "\n",
    "The VIIRS observations are split into archive (2018-2022) and \"NRT\" (2022-2023). These files need to be merged prior to performing the tidying.\n",
    "\n",
    "To start with, we will create a tidy database of VIIRS observations for both the S-NPP and NOAA-20 vintages. Then, we will look at creating a combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f1a3f-ed29-4066-9e8e-6ddb84ba2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Set up the file paths\n",
    "\n",
    "modis = os.path.join(projdir,'data/spatial/raw/NASA-FIRMS/DL_FIRE_M-C61_476781/')\n",
    "snpp = os.path.join(projdir,'data/spatial/raw/NASA-FIRMS/DL_FIRE_SV-C2_476784/')\n",
    "noaa = os.path.join(projdir,'data/spatial/raw/NASA-FIRMS/DL_FIRE_J1V-C2_476782/')\n",
    "\n",
    "# Store these in a dictionary\n",
    "dict = {\n",
    "    \"MOD61\": modis,\n",
    "    \"SNPP\": snpp,\n",
    "    \"NOAA-20\": noaa\n",
    "}\n",
    "\n",
    "# Buffer fire perimeters for the extraction\n",
    "fire_buffer = fired_aspen.copy().to_crs(proj)\n",
    "fire_buffer['geometry'] = fire_buffer.geometry.buffer(1000)  # 1km buffer\n",
    "fire_buffer = fire_buffer[['fired_id','ig_date','last_date','geometry']] \n",
    "\n",
    "# Process each of the archive data products\n",
    "gdfs = {} # dictionary to store the geo data frames\n",
    "for key, path in dict.items():\n",
    "    print(f'Processing: {key}')\n",
    "    # Read in the archive vector data\n",
    "    vect = glob.glob(path+\"*.shp\")\n",
    "    print([os.path.basename(v) for v in vect])\n",
    "    if len(vect) > 1:\n",
    "        print(\"~Merging archive and NRT data.\")\n",
    "        archive = gpd.read_file([v for v in vect if \"archive\" in v][0]).to_crs(proj)\n",
    "        nrt = gpd.read_file([v for v in vect if \"nrt\" in v][0]).to_crs(proj)\n",
    "        # Concatenate the archive and NRT\n",
    "        afd = pd.concat([archive, nrt], ignore_index=True)\n",
    "        del archive, nrt\n",
    "    else:\n",
    "        afd = gpd.read_file(vect[0]).to_crs(proj)\n",
    "\n",
    "    # Add some attribute information\n",
    "    afd['VID'] = afd.index # unique ID column\n",
    "\n",
    "    # Remove low-confidence observations\n",
    "    try:\n",
    "        afd = afd[afd['CONFIDENCE'] != 'l']\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}\")\n",
    "\n",
    "    del vect\n",
    "\n",
    "    #################################################\n",
    "    # Extract AFDs within wildfire data (aspen fires)\n",
    "    \n",
    "    # Extract AFDs\n",
    "    afd_aspen = gpd.sjoin(afd, fire_buffer, how='inner', predicate='within')\n",
    "    print(afd_aspen.columns)\n",
    "    \n",
    "    del afd\n",
    "    \n",
    "    ####################################################\n",
    "    # Perform temporal filtering to remove false-positive matches\n",
    "\n",
    "    # First, create date columns\n",
    "    afd_aspen['ACQ_DATE'] = pd.to_datetime(afd_aspen['ACQ_DATE'])\n",
    "    afd_aspen['ACQ_MONTH'] = afd_aspen['ACQ_DATE'].dt.month.astype(int)\n",
    "    afd_aspen['ACQ_YEAR'] = afd_aspen['ACQ_DATE'].dt.year.astype(int)\n",
    "    afd_aspen['ig_date'] = pd.to_datetime(afd_aspen['ig_date'])\n",
    "    afd_aspen['last_date'] = pd.to_datetime(afd_aspen['last_date'])\n",
    "\n",
    "    # Filter based on ignition month and year\n",
    "    afd_aspen_f = afd_aspen[\n",
    "        (afd_aspen['ACQ_YEAR'] >= afd_aspen['ig_date'].dt.year.astype(int)) & \n",
    "        (afd_aspen['ACQ_MONTH'] >= afd_aspen['ig_date'].dt.month.astype(int)) &\n",
    "        (afd_aspen['ACQ_YEAR'] <= afd_aspen['last_date'].dt.year.astype(int)) &\n",
    "        (afd_aspen['ACQ_MONTH'] <= afd_aspen['last_date'].dt.month.astype(int))\n",
    "    ]\n",
    "    \n",
    "    # Keep unique rows\n",
    "    afd_aspen_f = afd_aspen_f.drop_duplicates(subset='VID', keep='first')    \n",
    "\n",
    "    del afd_aspen\n",
    "    \n",
    "    #############################################\n",
    "    # Remove fires with less than 10 observations\n",
    "\n",
    "    # Get a count per fire\n",
    "    afd_counts = afd_aspen_f.groupby('fired_id').size().reset_index(name='counts')\n",
    "\n",
    "    # Get a list of IDs of fires with > 1 obs.\n",
    "    ids = afd_counts[afd_counts[\"counts\"] > 1]\n",
    "    \n",
    "    # Grab the new list of unique FIRED ids\n",
    "    ids = ids['fired_id'].unique().tolist()\n",
    "    \n",
    "    # Filter the datasets based on these FIRED ids\n",
    "    afd_aspen_f = afd_aspen_f[afd_aspen_f['fired_id'].isin(ids)]\n",
    "    fired_aspen_f = fired_aspen[fired_aspen['fired_id'].isin(ids)]\n",
    "\n",
    "    print(f\"Minimum obs./fire: {afd_counts['counts'].min()}; \\nMaximum obs./fire: {afd_counts['counts'].max()}\")\n",
    "    print(f\"Number of fires after filtering: {len(fired_aspen_f)}\")\n",
    "    print(f\"Number of obs. after filtering: {len(afd_aspen_f)}\")\n",
    "\n",
    "    del afd_counts, ids\n",
    "    \n",
    "    #################################################\n",
    "    # Plot the distribution of observations over time\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    afd_aspen_f['ACQ_DATE'].hist(bins=100)\n",
    "    plt.title(f'{key} - AFDs (2018-2023)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Observations')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    ##############################\n",
    "    # Append to the new dictionary\n",
    "    gdfs[key] = afd_aspen_f\n",
    "\n",
    "print(f\"Total elapsed time: {round((time.time() - t0))} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac4edf-fb95-4ded-a0a8-5b891092fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out the files as they are currently\n",
    "gdfs['MOD61'].to_file(os.path.join(projdir,'data/spatial/mod/AFD/mod61_archive_afd_aspen.gpkg'))\n",
    "gdfs['SNPP'].to_file(os.path.join(projdir,'data/spatial/mod/AFD/snpp_archive_afd_aspen.gpkg'))\n",
    "gdfs['NOAA-20'].to_file(os.path.join(projdir,'data/spatial/mod/AFD/noaa20_archive_afd_aspen.gpkg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62ba95-1fd1-46f5-8410-24ec31b1ea4f",
   "metadata": {},
   "source": [
    "## Handling acquisition time-of-day and spatially overlapping observations\n",
    "\n",
    "The VIIRS S-NPP AFD have many overlapping observations during a single fire event. In some cases, the overlapping points are on the same day and time but with different FRP values. In these cases, it may be best to \n",
    "\n",
    "From here on we can work with just the SNPP because it has the most consistency across our time period (NOAA-20 started in 2020). Later we can investigate the combination of the three datasets or at least make a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3242f-e553-429e-98a2-ce1a54d98a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the SNPP observations\n",
    "\n",
    "snpp_aspen = gdfs['SNPP']\n",
    "\n",
    "# Filter out FRP == 0\n",
    "snpp_aspen = snpp_aspen[snpp_aspen['FRP'] > 0]\n",
    "snpp_aspen.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde5c63-9f4b-4135-b864-28394d58ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snpp_aspen['FRP'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3307bd8-489b-4ee0-9529-3c3be14a0e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snpp_aspen['ACQ_TIME'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c9594-c6f2-44b4-8b4a-73367b296cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "snpp_aspen = snpp_aspen.reset_index()\n",
    "snpp_aspen = snpp_aspen.rename(columns={'index':'index_'})\n",
    "snpp_aspen = snpp_aspen.drop(['index_right'], axis=1)\n",
    "print(snpp_aspen.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b746a9b-abee-42a0-b6d0-3b21b54bb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a datetime object as a new column (in UTC)\n",
    "\n",
    "import pytz\n",
    "\n",
    "# Function to convert ACQ_DATE and ACQ_TIME to a datetime object in UTC\n",
    "def convert_to_datetime(acq_date, acq_time):\n",
    "    # Ensure ACQ_TIME is in HHMM format\n",
    "    if len(acq_time) == 3:\n",
    "        acq_time = '0' + acq_time\n",
    "    elif len(acq_time) == 2:\n",
    "        acq_time = '00' + acq_time\n",
    "    elif len(acq_time) == 1:\n",
    "        acq_time = '000' + acq_time\n",
    "\n",
    "    acq_date_str = acq_date.strftime('%Y-%m-%d')\n",
    "    dt = datetime.strptime(acq_date_str + acq_time, '%Y-%m-%d%H%M')\n",
    "    dt_utc = pytz.utc.localize(dt)  # Localize the datetime object to UTC\n",
    "    return dt_utc\n",
    "\n",
    "# Apply the conversion function to create a new datetime column\n",
    "snpp_aspen.loc[:, 'ACQ_DATETIME'] = snpp_aspen.apply(lambda row: convert_to_datetime(row['ACQ_DATE'], row['ACQ_TIME']), axis=1)\n",
    "\n",
    "# Print the resulting GeoDataFrame with timezone-aware datetime objects\n",
    "print(snpp_aspen['ACQ_DATETIME'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5367a4-bfda-42fd-8b3e-dbe008d946c3",
   "metadata": {},
   "source": [
    "#### Case 1: Same day/time observations with different FRP values (spatially overlapping)\n",
    "\n",
    "In this case, we have overlapping observations which have the same datetime but (sometimes) different FRP values. To handle this, we can group observations by datetime and perform a dissolve, taking the mean FRP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6921c-46c7-4522-8b09-0acb672ec1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial intersection to identify overlapping observations\n",
    "overlap = gpd.sjoin(snpp_aspen, snpp_aspen, predicate='intersects', lsuffix='left', rsuffix='right')\n",
    "print(overlap.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58264f6-89f0-410a-8c49-9ba8dc28a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique group ID for each set of intersecting observations with the same DATETIME\n",
    "overlap['_VID_'] = overlap.groupby(['ACQ_DATETIME_left', 'ACQ_DATETIME_right']).ngroup()\n",
    "print(overlap[['ACQ_DATETIME_left', 'ACQ_DATETIME_right','_VID_']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6aec0-04db-4aba-92df-2f508426d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 90th percentile of VPD among the observations\n",
    "\n",
    "# Join the new _VID_ back to the original dataframe using VID\n",
    "snpp_aspen_ = snpp_aspen.merge(\n",
    "    overlap[['VID_left', '_VID_']].drop_duplicates(), \n",
    "    left_on='VID', right_on='VID_left', how='left').reset_index(drop=True)\n",
    "\n",
    "# Calculate the 90th percentile FRP for each _VID_\n",
    "def pct90(group):\n",
    "    group['FRP_90'] = np.percentile(group['FRP'], 90)\n",
    "    return group\n",
    "\n",
    "# Apply the function to calculate the 90th percentile FRP\n",
    "snpp_aspen_ = snpp_aspen_.groupby('_VID_').apply(pct90).reset_index(drop=True)\n",
    "snpp_aspen_[['_VID_','VID','ACQ_DATETIME','LATITUDE','LONGITUDE','FRP','FRP_90','VERSION']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a700c8-36fd-450c-860b-633643b7ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissolve by the same day/time VID to create a new geometry with the 90th percentile FRP\n",
    "\n",
    "snpp_aspen_dis = snpp_aspen_.dissolve(by='_VID_').reset_index() # this takes the first of each, which should be OK\n",
    "\n",
    "snpp_aspen_dis.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc1d92-d59f-4c75-bbb8-92b257ed8d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out a version of these data\n",
    "\n",
    "# Create the buffered VIIRS obs.\n",
    "snpp_aspen_plot = snpp_aspen_dis.copy()\n",
    "snpp_aspen_plot['geometry'] = snpp_aspen_plot.geometry.buffer(375, cap_style=3)  # square buffer 375m\n",
    "\n",
    "# Save the VIIRS observations (points)\n",
    "snpp_aspen_dis = snpp_aspen_dis.to_crs(proj)\n",
    "snpp_aspen_dis.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/VIIRS/viirs_snpp_pt_fired_events_west_aspen.gpkg'))\n",
    "\n",
    "# Save the VIIRS observations (plots)\n",
    "snpp_aspen_plot = snpp_aspen_plot.to_crs(proj)\n",
    "snpp_aspen_plot.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/VIIRS/viirs_snpp_plot_fired_events_west_aspen.gpkg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc6917-32a5-4bd1-82d3-519d62162846",
   "metadata": {},
   "source": [
    "## Tidy the FRP data: remove null values, check on the obs./fire, and check on date matches\n",
    "\n",
    "Some observations may not be joined correctly (i.e., spatial overlap but wrong ignition year, etc). We may also have some fires with too few observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c9f15-de1b-4eb8-a81d-fcfa8fdf00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on the observation counts again\n",
    "viirs_counts = snpp_aspen_dis.groupby('fired_id').size().reset_index(name='counts')\n",
    "print(viirs_counts['counts'].min())\n",
    "print(viirs_counts['counts'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788052d-f496-4c13-8043-5b0e3900666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a map of the fire with the most observations\n",
    "\n",
    "# Sort the VIIRS counts\n",
    "viirs_counts = viirs_counts.sort_values('counts', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Take the first row (the maximum)\n",
    "max_obs = viirs_counts.iloc[0]['fired_id']\n",
    "print(max_obs)\n",
    "\n",
    "# Filter the fire perimeter and VIIRS obs.\n",
    "perim = fired_aspen[fired_aspen['fired_id'] == max_obs]\n",
    "obs = snpp_aspen_dis[snpp_aspen_dis['fired_id'] == max_obs]\n",
    "obs = obs.copy()\n",
    "obs['FRP_log'] = np.log1p(obs['FRP'])\n",
    "obs = obs[obs['DAYNIGHT'] == 'D']\n",
    "print(len(obs))\n",
    "\n",
    "# Create the map\n",
    "fig, ax = plt.subplots(figsize=(4, 5.5))\n",
    "# Plot VIIRS points\n",
    "obs.plot(column='FRP_log', ax=ax, legend=True,\n",
    "         legend_kwds={'label': \"Fire Radiative Power (FRP)\", 'orientation': \"horizontal\"},\n",
    "         cmap='magma', markersize=1, alpha=0.7)\n",
    "# Plot the fire perimeter\n",
    "perim.plot(ax=ax, color='none', edgecolor='black', linewidth=1, label='Fire Perimeter')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the map as a PNG\n",
    "plt.savefig(os.path.join(maindir,'aspen-fire/Aim2/figures/FigX_MullenFire_FRP.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a3a8a-188c-42d2-b80b-4ca3fdb45eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(frp_aspen_f['pct_aspen']))\n",
    "print(len(frp_aspen_f['FRP']))\n",
    "      \n",
    "# Scatterplot of FRP and aspen_pct (fire perimeter)\n",
    "plt.figure(figsize=(6, 4))  # Set the figure size\n",
    "plt.scatter(frp_aspen_f['pct_aspen'], frp_aspen_f['FRP'], alpha=0.5)  # Plot with some transparency\n",
    "\n",
    "# Add titles and labels\n",
    "plt.ylabel('Fire Radiative Power (FRP)')\n",
    "plt.xlabel('Aspen %')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efaf3e5-a759-4a62-9fe6-e27bb67b7c17",
   "metadata": {},
   "source": [
    "## Join VIIRS observations to daily FIRED perimeters\n",
    "\n",
    "We want to summarize VIIRS observations on a daily basis and then associate them with the correct daily polygon from FIRED. The initial step is to group observations by day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc08450-0652-4253-8b7c-883ac7bba401",
   "metadata": {},
   "source": [
    "## Create the VIIRS observation buffer (375m2)\n",
    "\n",
    "The archive VIIRS data is distributed as shapefiles with centroids representing the pixel center of a VIIRS observation. In order to assess characteristics within the VIIRS observations, we want to create a 375m2 buffer around the centroid locations to approximate the VIIRS pixel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f1f18-6c8d-465c-9968-3b1bd2069874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the buffered VIIRS obs.\n",
    "frp_aspen_plot = frp_aspen_f.copy()\n",
    "frp_aspen_plot['geometry'] = frp_aspen_plot.geometry.buffer(375, cap_style=3)  # square buffer 375m\n",
    "\n",
    "print(len(fired_aspen))\n",
    "\n",
    "# Let's plot one fire using the FRP column to color the \"plots\"\n",
    "\n",
    "# Filter the fire perimeter and VIIRS obs.\n",
    "perim = fired_aspen[fired_aspen['fired_id'] == \"42306\"]  # Williams Fork Fire \"45811.0\"\n",
    "obs = frp_aspen_plot[frp_aspen_plot['fired_id'] == \"42306\"]\n",
    "obs = obs.copy()\n",
    "obs['FRP_log'] = np.log1p(obs['FRP'])\n",
    "obs = obs[obs['DAYNIGHT'] == 'D']  # plot only daytime observations\n",
    "print(len(obs))\n",
    "\n",
    "# Create the map\n",
    "fig, ax = plt.subplots(figsize=(4, 5.5))\n",
    "# Plot VIIRS points\n",
    "obs.plot(column='FRP_log', ax=ax, legend=True,\n",
    "         legend_kwds={'label': \"Fire Radiative Power (FRP)\"},\n",
    "         cmap='magma', markersize=1, alpha=0.7)\n",
    "# Plot the fire perimeter\n",
    "perim.plot(ax=ax, color='none', edgecolor='black', linewidth=1, label='Fire Perimeter')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fde961-5339-4fa8-a49b-b2837f847102",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = fired_aspen.copy()\n",
    "centroid['geometry'] = centroid.geometry.centroid\n",
    "\n",
    "# Make a spatial map of the centroids now\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "states.plot(ax=ax, edgecolor='black', linewidth=1, color='none')\n",
    "\n",
    "# Plot centroids\n",
    "centroid['size'] = centroid['pct_aspen'] * 10  # Adjust the scaling factor as necessary\n",
    "centroid.plot(\n",
    "    ax=ax, markersize=centroid['pct_aspen'], \n",
    "    column='pct_aspen', cmap='viridis', \n",
    "    legend=True, alpha=0.6, \n",
    "    legend_kwds={'label': \"Aspen Percent\"})\n",
    "\n",
    "# Optional: Plot the original fire perimeters for context\n",
    "fired_aspen.plot(ax=ax, color='none', edgecolor='gray', linewidth=0.5)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.grid(True)\n",
    "\n",
    "del centroid\n",
    "\n",
    "# Save the map as a PNG\n",
    "plt.savefig(os.path.join(maindir,'aspen-fire/Aim2/figures/Fig1_aspen_fires.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53bb198-3886-4bf7-9e21-b5066e886a14",
   "metadata": {},
   "source": [
    "## Tidy and save out the necessary files\n",
    "\n",
    "Now that we have a tidy dataframe for both wildfires with >=5% pre-fire aspen cover and their associated nominal or high confidence VIIRS observations, we can save these files out for further processing. \n",
    "\n",
    "Some of the processing will occur in GEE, so for these files we want to save a simplified SHP with only the required attribute information (they will be joined back to the full data after processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90fab6-0022-4efd-8518-fc2c3fe6cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on the observation counts again\n",
    "viirs_counts = frp_aspen_plot.groupby('fired_id').size().reset_index(name='counts')\n",
    "print(viirs_counts['counts'].min())\n",
    "print(viirs_counts['counts'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a6062-0619-44d1-9f15-0b1fb10beb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the daily files\n",
    "# Get the list of IDs\n",
    "ids = fired_aspen['fired_id'].unique()\n",
    "\n",
    "# Load the daily polygons, subset to aspen fires\n",
    "daily['id'] = daily['id'].astype(str)\n",
    "daily = daily[daily['id'].isin(ids)]\n",
    "print(len(daily['id'].unique()))\n",
    "\n",
    "# Save the daily wildfire perimeters\n",
    "daily = daily.to_crs(proj)  # ensure the correct projection before exporting\n",
    "daily.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/FIRED/fired_daily_west_aspen.gpkg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8436dc3-3a72-4097-8f8d-5c1b981c4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the wildfire perimeters\n",
    "fired_aspen = fired_aspen.to_crs(proj)  # ensure the correct projection before exporting\n",
    "fired_aspen.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg'))\n",
    "\n",
    "# Save the VIIRS observations (points)\n",
    "frp_aspen_f = frp_aspen_f.to_crs(proj)\n",
    "frp_aspen_f.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/VIIRS/viirs_obs_fired_events_west_aspen.gpkg'))\n",
    "\n",
    "# Save the VIIRS observations (plots)\n",
    "frp_aspen_plot = frp_aspen_plot.to_crs(proj)\n",
    "frp_aspen_plot.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/VIIRS/viirs_plots_fired_events_west_aspen.gpkg'))\n",
    "\n",
    "# Tidy the files for GEE imports\n",
    "\n",
    "# FIRED perimeters (1km buffer)\n",
    "print(fired_aspen_1km.columns)\n",
    "fired_aspen_gee = fired_aspen_1km[['fired_id','ig_date','ig_year','last_date','mx_grw_dte','geometry']]\n",
    "fired_aspen_gee['ig_date'] = fired_aspen_gee['ig_date'].astype(str)\n",
    "fired_aspen_gee['last_date'] = fired_aspen_gee['ig_date'].astype(str)\n",
    "fired_aspen_gee.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/GEE/fired_events_west_aspen.shp'))\n",
    "\n",
    "# VIIRS \"plots\"\n",
    "print(frp_aspen_plot.columns)\n",
    "frp_aspen_gee = frp_aspen_plot[['fired_id','VID','ACQ_DATE','DAYNIGHT','geometry']]\n",
    "frp_aspen_gee['ACQ_DATE'] = frp_aspen_gee['ACQ_DATE'].astype(str)\n",
    "frp_aspen_gee.to_file(os.path.join(maindir,'aspen-fire/Aim2/data/spatial/mod/GEE/viirs_plots_fired_events_west_aspen.shp'))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad0142-b6bd-43c3-9412-46a9fc8090e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4304963-566f-47d9-85a3-4276af7aae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed79fc-f553-4792-85cd-1605d2444728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124db6e-c51a-46c2-8783-879bac319421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

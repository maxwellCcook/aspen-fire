{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ec03ae-2946-4baf-a5f7-f722a615f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Downloading VIIRS Active Fire Detections (AFD) with 'earthaccess' python API\n",
    "\n",
    "For a given geometry (in this case, fire perimeters), download data granules for:\n",
    "\n",
    "VIIRS AFD Products:\n",
    "    - VIIRS/NPP Active Fires 6-Min L2 Swath 375m V002 (VNP14IMG)\n",
    "    - VIIRS/JPSS1 Active Fires 6-Min L2 Swath 375m V002 (VJ1IMG)\n",
    "VIIRS Geolocation Products:\n",
    "    - VIIRS/NPP Imagery Resolution Terrain Corrected Geolocation 6-Min L1 Swath 375 m (VNP03IMG)\n",
    "    - VIIRS/JPSS1 Imagery Resolution Terrain Corrected Geolocation L1 6-Min Swath 375 m (VJ103IMG)\n",
    "\n",
    "Return: \n",
    "    - Downloaded NetCDF granules for the above products\n",
    "    - GeoDataFrame representing active fire pixel locations and attributes (before geolocation)\n",
    "\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import os, time, glob\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "import contextlib\n",
    "import traceback\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "datadir = os.path.join(maindir,'Aim2/data/spatial/raw/VIIRS/')\n",
    "dataoutdir = os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/')\n",
    "\n",
    "print(\"Ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73b7ebd1-d1ba-400d-8b65-d3b993c033ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class and functions ready !\n"
     ]
    }
   ],
   "source": [
    "# Class & Functions !\n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "class Download_VIIRS_AFD:\n",
    "    \"\"\" Downloads VIIRS Active Fire Data (AFD) for a give GeoPandas GeoDataFrame \"\"\"\n",
    "    def __init__(self, start_date, last_date, gdf = gpd.GeoDataFrame(), \n",
    "                 geog_crs = 'EPSG:4326', proj_crs = 'EPSG:5070', id_col='fired_id',\n",
    "                 short_names = ['VNP14IMG', 'VJ114IMG', 'VNP03IMG', 'VJ103IMG'],\n",
    "                 buffer = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - start_date: the intial date for the granule search\n",
    "            - last_date: the final date for the granule search\n",
    "            - gdf: GeoDataFrame for search request\n",
    "            - geog_crs: Geographic projection (to retrieve coordinate pairs in lat/lon)\n",
    "            - id_col: unique identifier in the GeoDataFrame\n",
    "            - short_names: the granules to be downloaded\n",
    "        Returns:\n",
    "            - Downloaded files (VIIRS Active Fire Data NetCDF and Geolocation information)\n",
    "            - GeoDataFrame with non-geolocated (raw) fire detections\n",
    "        \"\"\"\n",
    "        \n",
    "        self.id = gdf[id_col].iloc[0] # grab the unique ID\n",
    "        self.crs = gdf.crs # the native CRS definition for the input geodataframe\n",
    "        self.geog_crs = geog_crs\n",
    "        self.proj_crs = proj_crs\n",
    "        if buffer is not None:\n",
    "            self.gdf = gdf\n",
    "            self.gdf = self.gdf.assign(geometry=self.gdf.buffer(buffer)) # buffer units in meters\n",
    "        else:\n",
    "            self.gdf = gdf\n",
    "        self.bounds = self.gdf.to_crs(geog_crs).unary_union.envelope # for bounds, coords ensure geographic projection\n",
    "        self.coords = list(self.bounds.exterior.coords)\n",
    "        self.short_names = short_names\n",
    "        self.out_dir = os.path.join(datadir, f'FIRED_{self.id}')\n",
    "        self.date_range = (start_date, last_date)\n",
    "    \n",
    "    \n",
    "    def ea_search_request(self):\n",
    "        \"\"\" generate an earthaccess search request with the given parameters \"\"\"\n",
    "        print(f'Fire ID: {self.id}')\n",
    "        search_dict = {} # to store the search results\n",
    "        for short_name in self.short_names:\n",
    "            try:\n",
    "                # Search for products matching our short names\n",
    "                result = earthaccess.search_data(\n",
    "                    short_name=short_name,\n",
    "                    polygon=self.coords,\n",
    "                    temporal=self.date_range,\n",
    "                    count=1000, \n",
    "                )\n",
    "            \n",
    "                # Check if there is valid data, if not, skip\n",
    "                if len(result) != 0:\n",
    "                    # Append the search results data frame to the dictionary\n",
    "                    search_dict[short_name] = result\n",
    "                else:\n",
    "                    raise ValueError(f'No data found for: {short_name} -- Polygon ID {self.id}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Skipping polygon ID {self.id}: {short_name}\")\n",
    "                continue\n",
    "\n",
    "        if not search_dict:\n",
    "            return None  # Return None for invalid search results\n",
    "        else:\n",
    "            return search_dict\n",
    "\n",
    "    \n",
    "    def download_results(self, search_dict):\n",
    "        \"\"\" Downloads the search results to directory \"\"\"\n",
    "        if search_dict is not None:\n",
    "            for key, result in search_dict.items():\n",
    "                # Set the output directory based on short_name\n",
    "                fd = os.path.join(self.out_dir, f'{key}/')\n",
    "                if not os.path.exists(fd):\n",
    "                    os.makedirs(fd)\n",
    "                if len(os.listdir(fd)) < len(result):\n",
    "                    # Download the the search results\n",
    "                    with open(os.devnull, 'w') as f, contextlib.redirect_stdout(f):\n",
    "                        earthaccess.download(result, local_path=fd)\n",
    "                else:\n",
    "                    print(\"Files already downloaded, skipping ! \")\n",
    "\n",
    "    \n",
    "    def create_fire_gdf(self):\n",
    "        \"\"\" Creates a geodataframe with active fire detections from a directory with NetCDF files \"\"\"\n",
    "\n",
    "        afd_short_names = ['VNP14IMG', 'VJ114IMG'] # only process the AFD data, not geolocation data\n",
    "        \n",
    "        # List of downloaded .nc files\n",
    "        nc_files = list_files(self.out_dir, \"*.nc\", recursive=True)\n",
    "        nc_files = [f for f in nc_files if any(short_name in f for short_name in afd_short_names)]\n",
    "    \n",
    "        out_fire_dfs = [] # to store the dataframes for each nc file\n",
    "        for nc_file in nc_files:\n",
    "            \n",
    "            # Read the nc file\n",
    "            ds = Dataset(nc_file, 'r')\n",
    "\n",
    "            # Grab some NetCDF attributes\n",
    "            day_night_flag = ds.getncattr('DayNightFlag')\n",
    "            short_name = ds.getncattr('ShortName')\n",
    "            platform = ds.getncattr('PlatformShortName')\n",
    "            version = ds.getncattr('VersionID')\n",
    "            start_time_str = ds.getncattr('PGE_StartTime')\n",
    "            acq_datetime = datetime.strptime(start_time_str, '%Y-%m-%d %H:%M:%S.%f') # convert to datetime\n",
    "            julian_day = acq_datetime.timetuple().tm_yday # Calculate Julian Day\n",
    "\n",
    "            # Grab an array of the lat/lons of fire detections\n",
    "            fire_coords = self.coords\n",
    "            flats = np.array(ds.variables['FP_latitude'][:])  # lats as np array\n",
    "            flons = np.array(ds.variables['FP_longitude'][:])  # lons as np array\n",
    "            fll = np.logical_and.reduce(\n",
    "                (flons >= fire_coords[0][0], flons <= fire_coords[2][0], flats >= fire_coords[0][1], flats <= fire_coords[2][1]))\n",
    "    \n",
    "            # Extract fire pixel information\n",
    "            lats = flats[fll]\n",
    "            lons = flons[fll]\n",
    "            frp = np.array(ds.variables['FP_power'][:])[fll]\n",
    "            confidence = np.array(ds.variables['FP_confidence'][:])[fll]\n",
    "            fp_rad13 = np.array(ds.variables['FP_Rad13'][:])[fll]\n",
    "            fp_t4 = np.array(ds.variables['FP_T4'][:])[fll]\n",
    "            fp_t5 = np.array(ds.variables['FP_T5'][:])[fll]\n",
    "            view_az = np.array(ds.variables['FP_ViewAzAng'][:])[fll]\n",
    "            view_zen = np.array(ds.variables['FP_ViewZenAng'][:])[fll]\n",
    "\n",
    "            del ds, flats, flons, fll # clean up\n",
    "    \n",
    "            # Create a DataFrame with the fire pixel data\n",
    "            df = pd.DataFrame({\n",
    "                'fired_id': fire_id,\n",
    "                'acq_datetime': acq_datetime,\n",
    "                'acq_julian_day': julian_day,\n",
    "                'day_night': day_night_flag,\n",
    "                'short_name': short_name,\n",
    "                'platform': platform,\n",
    "                'version': version,\n",
    "                'latitude': lats,\n",
    "                'longitude': lons,\n",
    "                'frp': frp,\n",
    "                'fp_rad13': fp_rad13,\n",
    "                'fp_t4': fp_t4,\n",
    "                'fp_t5': fp_t5,\n",
    "                'confidence': confidence,\n",
    "                'view_az_an': view_az,\n",
    "                'view_zen_an': view_zen\n",
    "            })\n",
    "    \n",
    "            out_fire_dfs.append(df)\n",
    "\n",
    "            del df # clean up\n",
    "\n",
    "            gc.collect() # garbage collector\n",
    "    \n",
    "        # Concatenate the out dfs\n",
    "        fire_data = pd.concat(out_fire_dfs) # for the entire fire\n",
    "        \n",
    "        # Create a GeoDataFrame\n",
    "        fp_points = gpd.GeoDataFrame(\n",
    "            fire_data, \n",
    "            geometry=gpd.points_from_xy(fire_data.longitude, fire_data.latitude),\n",
    "            crs=self.geog_crs) # Geographic coordinates\n",
    "        # Reproject to projected coordinate system\n",
    "        fp_points = fp_points.to_crs(self.proj_crs)\n",
    "\n",
    "        del fire_data\n",
    "\n",
    "        return fp_points\n",
    "\n",
    "\n",
    "print(\"Class and functions ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1db138-d9da-4606-a1fe-7154b40c17aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fired_id', 'ig_date', 'ig_day', 'ig_month', 'ig_year', 'last_date',\n",
      "       'event_dur', 'tot_pix', 'tot_ar_km2', 'fsr_px_dy', 'fsr_km2_dy',\n",
      "       'mx_grw_px', 'mn_grw_px', 'mu_grw_px', 'mx_grw_km2', 'mn_grw_km2',\n",
      "       'mu_grw_km2', 'mx_grw_dte', 'x', 'y', 'ig_utm_x', 'ig_utm_y', 'lc_code',\n",
      "       'lc_mode', 'lc_name', 'lc_desc', 'lc_type', 'eco_mode', 'eco_name',\n",
      "       'eco_type', 'tot_perim', 'pct_aspen', 'geometry'],\n",
      "      dtype='object')\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Load the fire dataset\n",
    "fires_path = os.path.join(maindir,'Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c72c3128-d09b-4523-a0e9-bf90a63b5bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire ID: 3518\n",
      "Granules found: 17\n",
      "Granules found: 16\n",
      "Granules found: 17\n",
      "Granules found: 16\n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n",
      "Fire ID: 4014\n",
      "Granules found: 65\n",
      "Granules found: 61\n",
      "Granules found: 65\n",
      "Granules found: 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf82cddc4dec420686fa16777406a64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea741a06e854ae5a67ce9e705cc3b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/pqdm/_base.py:65\u001b[0m, in \u001b[0;36m_parallel_process\u001b[0;34m(iterable, function, n_jobs, executor, argument_type, exception_behaviour, tqdm_class, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m processing_opts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(futures)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm_class(as_completed(futures), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprocessing_opts):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m search_results \u001b[38;5;241m=\u001b[39m downloader\u001b[38;5;241m.\u001b[39mea_search_request()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(search_results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Downlaod the search results\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mdownloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Create the active fire detection geodataframe\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     fp_points_fire \u001b[38;5;241m=\u001b[39m downloader\u001b[38;5;241m.\u001b[39mcreate_fire_gdf()\n",
      "Cell \u001b[0;32mIn[12], line 91\u001b[0m, in \u001b[0;36mDownload_VIIRS_AFD.download_results\u001b[0;34m(self, search_dict)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(fd)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Download the the search results\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mdevnull, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, contextlib\u001b[38;5;241m.\u001b[39mredirect_stdout(f):\n\u001b[0;32m---> 91\u001b[0m         \u001b[43mearthaccess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded, skipping ! \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/earthaccess/api.py:188\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(granules, local_path, provider, threads)\u001b[0m\n\u001b[1;32m    186\u001b[0m     granules \u001b[38;5;241m=\u001b[39m [granules]\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mearthaccess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__store__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgranules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mprint\u001b[39m(err)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/earthaccess/store.py:475\u001b[0m, in \u001b[0;36mStore.get\u001b[0;34m(self, granules, local_path, provider, threads)\u001b[0m\n\u001b[1;32m    472\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m Path(local_path)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(granules):\n\u001b[0;32m--> 475\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgranules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m files\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/multimethod/__init__.py:363\u001b[0m, in \u001b[0;36mmultimethod.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DispatchError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/earthaccess/store.py:582\u001b[0m, in \u001b[0;36mStore._get_granules\u001b[0;34m(self, granules, local_path, provider, threads)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m downloaded_files\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# if the data are cloud-based, but we are not in AWS,\u001b[39;00m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;66;03m# it will be downloaded as if it was on prem\u001b[39;00m\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_onprem_granules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/earthaccess/store.py:643\u001b[0m, in \u001b[0;36mStore._download_onprem_granules\u001b[0;34m(self, urls, directory, threads)\u001b[0m\n\u001b[1;32m    640\u001b[0m directory\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    642\u001b[0m arguments \u001b[38;5;241m=\u001b[39m [(url, directory) \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls]\n\u001b[0;32m--> 643\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/pqdm/threads.py:22\u001b[0m, in \u001b[0;36mpqdm\u001b[0;34m(array, function, n_jobs, argument_type, bounded, exception_behaviour, tqdm_class, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpqdm\u001b[39m(\n\u001b[1;32m     13\u001b[0m     array: Iterable[Any],\n\u001b[1;32m     14\u001b[0m     function: Callable[[Any], Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     21\u001b[0m ):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_process\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43miterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margument_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBoundedThreadPoolExecutor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbounded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_behaviour\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexception_behaviour\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/pqdm/_base.py:40\u001b[0m, in \u001b[0;36m_parallel_process\u001b[0;34m(iterable, function, n_jobs, executor, argument_type, exception_behaviour, tqdm_class, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _handle_singular_processor(\n\u001b[1;32m     37\u001b[0m         iterable, function, argument_type, tqdm_class, tqdm_opts\n\u001b[1;32m     38\u001b[0m     )\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m executor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexecutor_opts) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     42\u001b[0m     submitting_opts \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(tqdm_opts)\n\u001b[1;32m     43\u001b[0m     submitting_opts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQUEUEING TASKS | \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m submitting_opts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get a list of fire IDs\n",
    "fire_ids = fires['fired_id'].unique()\n",
    "\n",
    "fp_points = [] # to store the output geodataframes\n",
    "no_data_ids = [] # to store fire IDs with no data\n",
    "\n",
    "for fire_id in fire_ids[0:5]:\n",
    "    fire = fires.loc[fires['fired_id'] == fire_id]\n",
    "    # Initiate the download and extract class\n",
    "    downloader = Download_VIIRS_AFD(\n",
    "        gdf=fire,\n",
    "        start_date=fire['ig_date'].iloc[0],\n",
    "        last_date=fire['last_date'].iloc[0],\n",
    "        buffer=1000, # in meters\n",
    "    )\n",
    "    # Retrieve the search results\n",
    "    try:\n",
    "        search_results = downloader.ea_search_request()\n",
    "        if len(search_results) > 0:\n",
    "            # Downlaod the search results\n",
    "            downloader.download_results(search_results)\n",
    "            # Create the active fire detection geodataframe\n",
    "            fp_points_fire = downloader.create_fire_gdf()\n",
    "            fp_points.append(fp_points_fire)\n",
    "            del fp_points_fire\n",
    "        else:\n",
    "            raise ValueError(f'No data granules found for {self.id}, skipping completely !')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping FIRED ID {fire_id}\\n{e}\")\n",
    "        traceback.print_exc()  # This will print the full traceback\n",
    "        no_data_ids.append(fire_id)\n",
    "        continue  # continue to the next fire id\n",
    "\n",
    "# Concatenate the results and save out the geodataframe of latlon fire pixels (non-geolocated)\n",
    "fp_points = gpd.GeoDataFrame(pd.concat(fp_points, ignore_index=True))\n",
    "fp_points.to_file(outdatadir,'viirs_fp_latlon_points.gpkg')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b059333-a117-4896-a17a-f672c286e4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

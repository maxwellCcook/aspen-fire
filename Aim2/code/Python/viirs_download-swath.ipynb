{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ec03ae-2946-4baf-a5f7-f722a615f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Downloading VIIRS Active Fire Detections (AFD) with 'earthaccess' python API\n",
    "\n",
    "For a given geometry (in this case, fire perimeters), download data granules for:\n",
    "\n",
    "VIIRS AFD Products:\n",
    "    - VIIRS/NPP Active Fires 6-Min L2 Swath 375m V002 (VNP14IMG)\n",
    "    - VIIRS/JPSS1 Active Fires 6-Min L2 Swath 375m V002 (VJ1IMG)\n",
    "VIIRS Geolocation Products:\n",
    "    - VIIRS/NPP Imagery Resolution Terrain Corrected Geolocation 6-Min L1 Swath 375 m (VNP03IMG)\n",
    "    - VIIRS/JPSS1 Imagery Resolution Terrain Corrected Geolocation L1 6-Min Swath 375 m (VJ103IMG)\n",
    "\n",
    "Return: \n",
    "    - Downloaded NetCDF granules for the above products\n",
    "    - GeoDataFrame representing active fire pixel locations and attributes (before geolocation)\n",
    "\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import os, time, glob\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "import contextlib\n",
    "import traceback\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "datadir = os.path.join(maindir,'Aim2/data/spatial/raw/VIIRS/')\n",
    "dataoutdir = os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/')\n",
    "\n",
    "print(\"Ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b7ebd1-d1ba-400d-8b65-d3b993c033ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class and functions ready !\n"
     ]
    }
   ],
   "source": [
    "# Class & Functions !\n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "class Download_VIIRS_AFD:\n",
    "    \"\"\" Downloads VIIRS Active Fire Data (AFD) for a give GeoPandas GeoDataFrame \"\"\"\n",
    "    def __init__(self, start_date, last_date, gdf = gpd.GeoDataFrame(), \n",
    "                 geog_crs = 'EPSG:4326', proj_crs = 'EPSG:5070', id_col='fired_id',\n",
    "                 short_names = ['VNP14IMG', 'VJ114IMG', 'VNP03IMG', 'VJ103IMG'],\n",
    "                 buffer = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - start_date: the intial date for the granule search\n",
    "            - last_date: the final date for the granule search\n",
    "            - gdf: GeoDataFrame for search request\n",
    "            - geog_crs: Geographic projection (to retrieve coordinate pairs in lat/lon)\n",
    "            - id_col: unique identifier in the GeoDataFrame\n",
    "            - short_names: the granules to be downloaded\n",
    "        Returns:\n",
    "            - Downloaded files (VIIRS Active Fire Data NetCDF and Geolocation information)\n",
    "            - GeoDataFrame with non-geolocated (raw) fire detections\n",
    "        \"\"\"\n",
    "        \n",
    "        self.id = gdf[id_col].iloc[0] # grab the unique ID\n",
    "        self.crs = gdf.crs # the native CRS definition for the input geodataframe\n",
    "        self.geog_crs = geog_crs\n",
    "        self.proj_crs = proj_crs\n",
    "        if buffer is not None:\n",
    "            self.gdf = gdf\n",
    "            self.gdf = self.gdf.assign(geometry=self.gdf.buffer(buffer)) # buffer units in meters\n",
    "        else:\n",
    "            self.gdf = gdf\n",
    "        self.bounds = self.gdf.to_crs(geog_crs).unary_union.envelope # for bounds, coords ensure geographic projection\n",
    "        self.coords = list(self.bounds.exterior.coords)\n",
    "        self.short_names = short_names\n",
    "        self.out_dir = os.path.join(datadir, f'FIRED_{self.id}')\n",
    "        self.date_range = (start_date, last_date)\n",
    "    \n",
    "    \n",
    "    def ea_search_request(self):\n",
    "        \"\"\" generate an earthaccess search request with the given parameters \"\"\"\n",
    "        print(f'Fire ID: {self.id}')\n",
    "        search_dict = {} # to store the search results\n",
    "        for short_name in self.short_names:\n",
    "            try:\n",
    "                # Search for products matching our short names\n",
    "                result = earthaccess.search_data(\n",
    "                    short_name=short_name,\n",
    "                    polygon=self.coords,\n",
    "                    temporal=self.date_range,\n",
    "                    count=1000, \n",
    "                )\n",
    "            \n",
    "                # Check if there is valid data, if not, skip\n",
    "                if len(result) != 0:\n",
    "                    # Append the search results data frame to the dictionary\n",
    "                    search_dict[short_name] = result\n",
    "                else:\n",
    "                    raise ValueError(f'No data found for: {short_name} -- Polygon ID {self.id}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Skipping polygon ID {self.id}: {short_name}\")\n",
    "                continue\n",
    "\n",
    "        if not search_dict:\n",
    "            return None  # Return None for invalid search results\n",
    "        else:\n",
    "            return search_dict\n",
    "\n",
    "    \n",
    "    def download_results(self, search_dict):\n",
    "        \"\"\" Downloads the search results to directory \"\"\"\n",
    "        if search_dict is not None:\n",
    "            for key, result in search_dict.items():\n",
    "                # Set the output directory based on short_name\n",
    "                fd = os.path.join(self.out_dir, f'{key}/')\n",
    "                if not os.path.exists(fd):\n",
    "                    os.makedirs(fd)\n",
    "                if len(os.listdir(fd)) < len(result):\n",
    "                    # Download the the search results\n",
    "                    with open(os.devnull, 'w') as f, contextlib.redirect_stdout(f):\n",
    "                        earthaccess.download(result, local_path=fd)\n",
    "                else:\n",
    "                    print(\"Files already downloaded, skipping ! \")\n",
    "\n",
    "    \n",
    "    def create_fire_gdf(self):\n",
    "        \"\"\" Creates a geodataframe with active fire detections from a directory with NetCDF files \"\"\"\n",
    "\n",
    "        afd_short_names = ['VNP14IMG', 'VJ114IMG'] # only process the AFD data, not geolocation data\n",
    "        \n",
    "        # List of downloaded .nc files\n",
    "        nc_files = list_files(self.out_dir, \"*.nc\", recursive=True)\n",
    "        nc_files = [f for f in nc_files if any(short_name in f for short_name in afd_short_names)]\n",
    "    \n",
    "        out_fire_dfs = [] # to store the dataframes for each nc file\n",
    "        for nc_file in nc_files:\n",
    "            \n",
    "            # Read the nc file\n",
    "            ds = Dataset(nc_file, 'r')\n",
    "\n",
    "            # Grab some NetCDF attributes\n",
    "            day_night_flag = ds.getncattr('DayNightFlag')\n",
    "            short_name = ds.getncattr('ShortName')\n",
    "            platform = ds.getncattr('PlatformShortName')\n",
    "            version = ds.getncattr('VersionID')\n",
    "            start_time_str = ds.getncattr('PGE_StartTime')\n",
    "            acq_datetime = datetime.strptime(start_time_str, '%Y-%m-%d %H:%M:%S.%f') # convert to datetime\n",
    "            julian_day = acq_datetime.timetuple().tm_yday # Calculate Julian Day\n",
    "\n",
    "            # Grab an array of the lat/lons of fire detections\n",
    "            fire_coords = self.coords\n",
    "            flats = np.array(ds.variables['FP_latitude'][:])  # lats as np array\n",
    "            flons = np.array(ds.variables['FP_longitude'][:])  # lons as np array\n",
    "            fll = np.logical_and.reduce(\n",
    "                (flons >= fire_coords[0][0], flons <= fire_coords[2][0], flats >= fire_coords[0][1], flats <= fire_coords[2][1]))\n",
    "    \n",
    "            # Extract fire pixel information\n",
    "            lats = flats[fll]\n",
    "            lons = flons[fll]\n",
    "            frp = np.array(ds.variables['FP_power'][:])[fll]\n",
    "            confidence = np.array(ds.variables['FP_confidence'][:])[fll]\n",
    "            fp_rad13 = np.array(ds.variables['FP_Rad13'][:])[fll]\n",
    "            fp_t4 = np.array(ds.variables['FP_T4'][:])[fll]\n",
    "            fp_t5 = np.array(ds.variables['FP_T5'][:])[fll]\n",
    "            view_az = np.array(ds.variables['FP_ViewAzAng'][:])[fll]\n",
    "            view_zen = np.array(ds.variables['FP_ViewZenAng'][:])[fll]\n",
    "\n",
    "            del ds, flats, flons, fll # clean up\n",
    "    \n",
    "            # Create a DataFrame with the fire pixel data\n",
    "            df = pd.DataFrame({\n",
    "                'fired_id': fire_id,\n",
    "                'acq_datetime': acq_datetime,\n",
    "                'acq_julian_day': julian_day,\n",
    "                'day_night': day_night_flag,\n",
    "                'short_name': short_name,\n",
    "                'platform': platform,\n",
    "                'version': version,\n",
    "                'latitude': lats,\n",
    "                'longitude': lons,\n",
    "                'frp': frp,\n",
    "                'fp_rad13': fp_rad13,\n",
    "                'fp_t4': fp_t4,\n",
    "                'fp_t5': fp_t5,\n",
    "                'confidence': confidence,\n",
    "                'view_az_an': view_az,\n",
    "                'view_zen_an': view_zen\n",
    "            })\n",
    "    \n",
    "            out_fire_dfs.append(df)\n",
    "\n",
    "            del df # clean up\n",
    "\n",
    "            gc.collect() # garbage collector\n",
    "    \n",
    "        # Concatenate the out dfs\n",
    "        fire_data = pd.concat(out_fire_dfs) # for the entire fire\n",
    "        \n",
    "        # Create a GeoDataFrame\n",
    "        fp_points = gpd.GeoDataFrame(\n",
    "            fire_data, \n",
    "            geometry=gpd.points_from_xy(fire_data.longitude, fire_data.latitude),\n",
    "            crs=self.geog_crs) # Geographic coordinates\n",
    "        # Reproject to projected coordinate system\n",
    "        fp_points = fp_points.to_crs(self.proj_crs)\n",
    "\n",
    "        del fire_data\n",
    "\n",
    "        return fp_points\n",
    "\n",
    "\n",
    "print(\"Class and functions ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1db138-d9da-4606-a1fe-7154b40c17aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fired_id', 'ig_date', 'ig_day', 'ig_month', 'ig_year', 'last_date',\n",
      "       'event_dur', 'tot_pix', 'tot_ar_km2', 'fsr_px_dy', 'fsr_km2_dy',\n",
      "       'mx_grw_px', 'mn_grw_px', 'mu_grw_px', 'mx_grw_km2', 'mn_grw_km2',\n",
      "       'mu_grw_km2', 'mx_grw_dte', 'x', 'y', 'ig_utm_x', 'ig_utm_y', 'lc_code',\n",
      "       'lc_mode', 'lc_name', 'lc_desc', 'lc_type', 'eco_mode', 'eco_name',\n",
      "       'eco_type', 'tot_perim', 'pct_aspen', 'geometry'],\n",
      "      dtype='object')\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Load the fire dataset\n",
    "fires_path = os.path.join(maindir,'Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c72c3128-d09b-4523-a0e9-bf90a63b5bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire ID: 3518\n",
      "Granules found: 17\n",
      "Granules found: 16\n",
      "Granules found: 17\n",
      "Granules found: 16\n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n",
      "Fire ID: 4014\n",
      "Granules found: 65\n",
      "Granules found: 61\n",
      "Granules found: 65\n",
      "Granules found: 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb355075ee34fc8b40082f00dda9a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914d3b43b0524592971e1828d1dc68ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480580a0f21f4a35a5779734fe6763ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8b11f1962e4cd894e52397b3dbf1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971a02d53fc047478e6a49fe73ae82d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6fe9d1aaf644e1b2d91a670baec98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire ID: 4131\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VNP14IMG\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VJ114IMG\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VNP03IMG\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VJ103IMG\n",
      "Skipping FIRED ID 4131\n",
      "object of type 'NoneType' has no len()\n",
      "Fire ID: 4225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/lm/1zg27k9x385csjv9gkj8jqm80000gp/T/ipykernel_6519/1085234379.py\", line 19, in <module>\n",
      "    if len(search_results) > 0:\n",
      "TypeError: object of type 'NoneType' has no len()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 48\n",
      "Granules found: 49\n",
      "Granules found: 48\n",
      "Granules found: 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea04975cbd3c4c7bb15073c809425163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5d185a7b4c4185a8829470ee096bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfdf5b2d4124e9e9ffe24674f2284a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a892eec74ae40699a2bd3747c274b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92282e08a89f48d28c1a88faa12aa9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2702c11aee7243ea8ee9b895fbe69384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire ID: 5006\n",
      "Granules found: 28\n",
      "Granules found: 29\n",
      "Granules found: 28\n",
      "Granules found: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184aff60eb674632b86a509d112cbe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd41a6da9c994d118bd93ad269f2ceb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145a177617014782b609eac2bd4d8231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac31ad8076746dcb0a6925d10a5a37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223ff15562874bdb8f737d2b72502fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc65d9e8e954136bf0f285e459a1047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'outdatadir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Concatenate the results and save out the geodataframe of latlon fire pixels (non-geolocated)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m fp_points \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(pd\u001b[38;5;241m.\u001b[39mconcat(fp_points, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m---> 37\u001b[0m fp_points\u001b[38;5;241m.\u001b[39mto_file(\u001b[43moutdatadir\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviirs_fp_latlon_points.gpkg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outdatadir' is not defined"
     ]
    }
   ],
   "source": [
    "# Get a list of fire IDs\n",
    "fire_ids = fires['fired_id'].unique()\n",
    "\n",
    "fp_points = [] # to store the output geodataframes\n",
    "no_data_ids = [] # to store fire IDs with no data\n",
    "\n",
    "for fire_id in fire_ids[0:5]:\n",
    "    fire = fires.loc[fires['fired_id'] == fire_id]\n",
    "    # Initiate the download and extract class\n",
    "    downloader = Download_VIIRS_AFD(\n",
    "        gdf=fire,\n",
    "        start_date=fire['ig_date'].iloc[0],\n",
    "        last_date=fire['last_date'].iloc[0],\n",
    "        buffer=1000, # in meters\n",
    "    )\n",
    "    # Retrieve the search results\n",
    "    try:\n",
    "        search_results = downloader.ea_search_request()\n",
    "        if len(search_results) > 0:\n",
    "            # Downlaod the search results\n",
    "            downloader.download_results(search_results)\n",
    "            # Create the active fire detection geodataframe\n",
    "            fp_points_fire = downloader.create_fire_gdf()\n",
    "            fp_points.append(fp_points_fire)\n",
    "            del fp_points_fire\n",
    "        else:\n",
    "            raise ValueError(f'No data granules found for {self.id}, skipping completely !')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping FIRED ID {fire_id}\\n{e}\")\n",
    "        traceback.print_exc()  # This will print the full traceback\n",
    "        no_data_ids.append(fire_id)\n",
    "        continue  # continue to the next fire id\n",
    "\n",
    "# Concatenate the results and save out the geodataframe of latlon fire pixels (non-geolocated)\n",
    "fp_points = gpd.GeoDataFrame(pd.concat(fp_points, ignore_index=True))\n",
    "fp_points.to_file(outdatadir,'viirs_fp_latlon_points.gpkg')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b059333-a117-4896-a17a-f672c286e4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ec03ae-2946-4baf-a5f7-f722a615f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import os, time, glob\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "import contextlib\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "datadir = os.path.join(maindir,'Aim2/data/spatial/raw/VIIRS/')\n",
    "\n",
    "print(\"Ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b7ebd1-d1ba-400d-8b65-d3b993c033ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class and functions ready !\n"
     ]
    }
   ],
   "source": [
    "# Class & Functions !\n",
    "\n",
    "class Download_VIIRS_AFD:\n",
    "    \"\"\" Downloads VIIRS Active Fire Data (AFD) for a give GeoPandas GeoDataFrame \"\"\"\n",
    "    def __init__(self, start_date, last_date, gdf = gpd.GeoDataFrame(), \n",
    "                 geog_crs = 'EPSG:4326', id_col='fired_id',\n",
    "                 short_names = ['VNP14IMG', 'VJ114IMG', 'VNP03MODLL', 'VJ103MODLL'],\n",
    "                 buffer = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - gdf: GeoDataFrame for search request\n",
    "            - geog_crs: Geographic projection (to retrieve coordinate pairs in lat/lon)\n",
    "            - id_col: unique identifier in the GeoDataFrame\n",
    "        Returns:\n",
    "            - Downloaded files (VIIRS Active Fire Data NetCDF and Geolocation information)\n",
    "            - GeoDataFrame with non-geolocated (raw) fire detections\n",
    "        \"\"\"\n",
    "        self.id = gdf[id_col].iloc[0] # grab the unique ID\n",
    "        self.crs = gdf.crs # the native CRS definition for the input geodataframe\n",
    "        if buffer is not None:\n",
    "            self.gdf = gdf\n",
    "            self.gdf = self.gdf.assign(geometry=self.gdf.buffer(buffer)) # buffer units in meters\n",
    "        else:\n",
    "            self.gdf = gdf\n",
    "        self.bounds = self.gdf.to_crs(geog_crs).unary_union.envelope # for bounds, coords ensure geographic projection\n",
    "        self.coords = list(self.bounds.exterior.coords)\n",
    "        self.short_names = short_names\n",
    "        self.out_dir = os.path.join(datadir, f'FIRED_{self.id}')\n",
    "        self.date_range = (start_date, last_date)\n",
    "    \n",
    "    \n",
    "    def ea_search_request(self):\n",
    "        \"\"\" generate an earthaccess search request with the given parameters \"\"\"\n",
    "        print(f'Fire ID: {self.id}')\n",
    "        search_dict = {} # to store the search results\n",
    "        for short_name in self.short_names:\n",
    "            try:\n",
    "                # Search for products matching our short names\n",
    "                result = earthaccess.search_data(\n",
    "                    short_name=short_name,\n",
    "                    polygon=self.coords,\n",
    "                    temporal=self.date_range,\n",
    "                    count=1000, \n",
    "                )\n",
    "            \n",
    "                # Check if there is valid data, if not, skip\n",
    "                if len(result) != 0:\n",
    "                    # Append the search results data frame to the dictionary\n",
    "                    search_dict[short_name] = result\n",
    "                else:\n",
    "                    raise ValueError(f'No data found for: {short_name} -- Polygon ID {self.id}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Skipping polygon ID {self.id}: {short_name}\")\n",
    "                continue\n",
    "\n",
    "        if not search_dict:\n",
    "            return None  # Return None for invalid search results\n",
    "        else:\n",
    "            return search_dict\n",
    "\n",
    "    \n",
    "    def download_results(self, search_dict):\n",
    "        \"\"\" Downloads the search results to directory \"\"\"\n",
    "        if search_dict is not None:\n",
    "            for key, result in search_dict.items():\n",
    "                # Set the output directory based on short_name\n",
    "                fd = os.path.join(self.out_dir, f'{key}/')\n",
    "                if not os.path.exists(fd):\n",
    "                    os.makedirs(fd)\n",
    "                if len(os.listdir(fd)) == 0:\n",
    "                    # Download the the search results\n",
    "                    with open(os.devnull, 'w') as f, contextlib.redirect_stdout(f):\n",
    "                        earthaccess.download(result, local_path=fd)\n",
    "                else:\n",
    "                    print(\"Files already downloaded, skipping ! \")\n",
    "\n",
    "    \n",
    "    def create_fire_gdf(self):\n",
    "        \"\"\" Creates a geodataframe with active fire detections from a directory with NetCDF files \"\"\"\n",
    "        \n",
    "        # List of downloaded .nc files\n",
    "        nc_files = list_files(self.out_dir, \"*.nc\", recursive=True)\n",
    "    \n",
    "        out_fire_dfs = [] # to store the dataframes for each nc file\n",
    "        for nc_file in nc_files:\n",
    "            \n",
    "            # Read the nc file\n",
    "            ds = Dataset(nc_file, 'r', format = 'NETCDF4')\n",
    "\n",
    "            # Grab some NetCDF attributes\n",
    "            day_night_flag = ds.getncattr('DayNightFlag')\n",
    "            short_name = ds.getncattr('ShortName')\n",
    "            platform = ds.getncattr('PlatformShortName')\n",
    "            version = ds.getncattr('VersionID')\n",
    "            start_time_str = ds.getncattr('PGE_StartTime')\n",
    "            acq_datetime = datetime.strptime(start_time_str, '%Y-%m-%d %H:%M:%S.%f') # convert to datetime\n",
    "            julian_day = acq_datetime.timetuple().tm_yday # Calculate Julian Day\n",
    "\n",
    "            # Grab an array of the lat/lons of fire detections\n",
    "            fire_coords = self.coords\n",
    "            flats = np.array(ds.variables['FP_latitude'][:])  # lats as np array\n",
    "            flons = np.array(ds.variables['FP_longitude'][:])  # lons as np array\n",
    "            fll = np.logical_and.reduce(\n",
    "                (flons >= fire_coords[0][0], flons <= fire_coords[2][0], flats >= fire_coords[0][1], flats <= fire_coords[2][1]))\n",
    "    \n",
    "            # Extract fire pixel information\n",
    "            lats = flats[fll]\n",
    "            lons = flons[fll]\n",
    "            frp = np.array(ds.variables['FP_power'][:])[fll]\n",
    "            confidence = np.array(ds.variables['FP_confidence'][:])[fll]\n",
    "            fp_rad13 = np.array(ds.variables['FP_Rad13'][:])[fll]\n",
    "            fp_t4 = np.array(ds.variables['FP_T4'][:])[fll]\n",
    "            fp_t5 = np.array(ds.variables['FP_T5'][:])[fll]\n",
    "            view_az = np.array(ds.variables['FP_ViewAzAng'][:])[fll]\n",
    "            view_zen = np.array(ds.variables['FP_ViewZenAng'][:])[fll]\n",
    "\n",
    "            del ds, flats, flons, fll # clean up\n",
    "    \n",
    "            # Create a DataFrame with the fire pixel data\n",
    "            df = pd.DataFrame({\n",
    "                'fired_id': fire_id,\n",
    "                'acq_datetime': acq_datetime,\n",
    "                'acq_julian_day': julian_day,\n",
    "                'day_night': day_night_flag,\n",
    "                'short_name': short_name,\n",
    "                'platform': platform,\n",
    "                'version': version,\n",
    "                'latitude': lats,\n",
    "                'longitude': lons,\n",
    "                'frp': frp,\n",
    "                'fp_rad13': fp_rad13,\n",
    "                'fp_t4': fp_t4,\n",
    "                'fp_t5': fp_t5,\n",
    "                'confidence': confidence,\n",
    "                'view_az_an': view_az,\n",
    "                'view_zen_an': view_zen\n",
    "            })\n",
    "    \n",
    "            out_fire_dfs.append(df)\n",
    "    \n",
    "            # # Clean up\n",
    "            # if self.delete_ds is True:\n",
    "            #     os.remove(nc_file)\n",
    "\n",
    "            gc.collect() # garbage collector\n",
    "    \n",
    "        # Concatenate the out dfs\n",
    "        fire_data = pd.concat(out_fire_dfs) # for the entire fire\n",
    "        \n",
    "        # Create a GeoDataFrame\n",
    "        fp_points = gpd.GeoDataFrame(\n",
    "            fire_data, \n",
    "            geometry=gpd.points_from_xy(fire_data.longitude, fire_data.latitude),\n",
    "            crs=self.geog_crs) # Geographic coordinates\n",
    "        # Reproject to projected coordinate system\n",
    "        fp_points = fp_points.to_crs(self.proj_crs)\n",
    "\n",
    "        del fire_data\n",
    "\n",
    "        return fp_points\n",
    "\n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "print(\"Class and functions ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d1db138-d9da-4606-a1fe-7154b40c17aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fired_id', 'ig_date', 'ig_day', 'ig_month', 'ig_year', 'last_date',\n",
      "       'event_dur', 'tot_pix', 'tot_ar_km2', 'fsr_px_dy', 'fsr_km2_dy',\n",
      "       'mx_grw_px', 'mn_grw_px', 'mu_grw_px', 'mx_grw_km2', 'mn_grw_km2',\n",
      "       'mu_grw_km2', 'mx_grw_dte', 'x', 'y', 'ig_utm_x', 'ig_utm_y', 'lc_code',\n",
      "       'lc_mode', 'lc_name', 'lc_desc', 'lc_type', 'eco_mode', 'eco_name',\n",
      "       'eco_type', 'tot_perim', 'pct_aspen', 'geometry'],\n",
      "      dtype='object')\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Load the fire dataset\n",
    "fires_path = os.path.join(maindir,'Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72c3128-d09b-4523-a0e9-bf90a63b5bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire ID: 3518\n",
      "Granules found: 17\n",
      "Granules found: 16\n",
      "Granules found: 34\n",
      "Granules found: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314d52653b614226811b7d5fc4ab5682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b948860bfb1e414f807f519f70503618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504c1ad5e0e941f3af3385265e46034a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307f7a3732dd4de3919d8a2f79fedd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087b1b4b2fc14118b8b98bd09cfe85c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164518a8792f4072bfdaf88ee306d98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping FIRED ID 3518\n",
      "'Download_VIIRS_AFD' object has no attribute 'delete_ds'\n",
      "Fire ID: 4014\n",
      "Granules found: 65\n",
      "Granules found: 61\n",
      "Granules found: 131\n",
      "Granules found: 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c973b899a84886a294249c129e168d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87559f7b187d457e8708a1e0c2a7c8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c5de1fb41042f089461afca3e52fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c099e0a3a34e2c8ad7f38942e54824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b72e1721784b058cdd46a5eff85925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cdf49d78544c1cb6f5b56121cde2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping FIRED ID 4014\n",
      "'Download_VIIRS_AFD' object has no attribute 'delete_ds'\n",
      "Fire ID: 4131\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VNP14IMG\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VJ114IMG\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VNP03MODLL\n",
      "Granules found: 0\n",
      "Skipping polygon ID 4131: VJ103MODLL\n",
      "Skipping FIRED ID 4131\n",
      "object of type 'NoneType' has no len()\n",
      "Fire ID: 4225\n",
      "Granules found: 48\n",
      "Granules found: 49\n",
      "Granules found: 96\n",
      "Granules found: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3c3a9b63c540539bcb91e51db6d099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92c6cc510044b7c8f9568fde9b361be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping polygon ID 4225: VJ103MODLL\n",
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef5443a3c2d4c3f94a9e7ae3e5576e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping FIRED ID 4225\n",
      "'Download_VIIRS_AFD' object has no attribute 'delete_ds'\n",
      "Fire ID: 5006\n",
      "Granules found: 28\n",
      "Granules found: 29\n",
      "Granules found: 51\n",
      "Granules found: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a752996915430da860020948face9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2637085ae4d145729731dce017da7024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded, skipping ! \n",
      "Files already downloaded, skipping ! \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca8cbaba330458f8af89556a127a588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbc64a83406499b8229a902b1cb0aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c743dac5f0674693ae0f699202c60555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44ec970c9914b7a974aa3d4fae8b145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping FIRED ID 5006\n",
      "'Download_VIIRS_AFD' object has no attribute 'delete_ds'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# continue to the next fire id\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Concatenate the results\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m fp_points \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/pandas/core/reshape/concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Get a list of fire IDs\n",
    "fire_ids = fires['fired_id'].unique()\n",
    "\n",
    "fp_points = [] # to store the output geodataframes\n",
    "no_data_ids = [] # to store fire IDs with no data\n",
    "\n",
    "for fire_id in fire_ids[0:5]:\n",
    "    fire = fires.loc[fires['fired_id'] == fire_id]\n",
    "    # Initiate the download and extract class\n",
    "    downloader = Download_VIIRS_AFD(\n",
    "        gdf=fire,\n",
    "        start_date=fire['ig_date'].iloc[0],\n",
    "        last_date=fire['last_date'].iloc[0],\n",
    "        buffer=1000, # in meters\n",
    "    )\n",
    "    # Retrieve the search results\n",
    "    try:\n",
    "        search_results = downloader.ea_search_request()\n",
    "        if len(search_results) > 0:\n",
    "            # Downlaod the search results\n",
    "            downloader.download_results(search_results)\n",
    "            # Create the active fire detection geodataframe\n",
    "            fp_points_fire = downloader.create_fire_gdf()\n",
    "            fp_points.append(fp_points_fire)\n",
    "            del fp_points_fire\n",
    "        else:\n",
    "            raise ValueError(f'No data found for {self.id}, skipping completely !')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping FIRED ID {fire_id}\\n{e}\")\n",
    "        no_data_ids.append(fire_id)\n",
    "        continue  # continue to the next fire id\n",
    "\n",
    "# Concatenate the results\n",
    "fp_points = gpd.GeoDataFrame(pd.concat(fp_points, ignore_index=True))\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

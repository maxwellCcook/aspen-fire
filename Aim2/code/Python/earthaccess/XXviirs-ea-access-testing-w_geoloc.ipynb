{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860cfb56-6520-41c9-8e7e-ea17b878000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing remote access to VIIRS active fire data\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, time\n",
    "import earthaccess as ea\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "        \n",
    "# Directories\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/'\n",
    "projdir = os.path.join(maindir, 'aspen-fire/Aim2/')\n",
    "\n",
    "# Output directories\n",
    "dataraw = os.path.join(projdir,'data/spatial/raw/VIIRS/')\n",
    "datamod = os.path.join(projdir,'data/spatial/mod/VIIRS/')\n",
    "\n",
    "print(\"Ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eab1cdf-802d-4de3-ae46-b68e99cfca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: \n",
      "Index(['Fire_ID', 'Fire_Name', 'NIFC_ACRES', 'FINAL_ACRES', 'pct_aspen',\n",
      "       'INCIDENT_ID', 'INCIDENT_NAME', 'START_YEAR', 'CAUSE', 'DISCOVERY_DATE',\n",
      "       'DISCOVERY_DOY', 'WF_CESSATION_DATE', 'WF_CESSATION_DOY',\n",
      "       'STR_DESTROYED_TOTAL', 'STR_DAMAGED_TOTAL', 'STR_THREATENED_MAX',\n",
      "       'EVACUATION_REPORTED', 'PEAK_EVACUATIONS', 'WF_PEAK_AERIAL',\n",
      "       'WF_PEAK_PERSONNEL', 'na_l3name', 'first_obs_date', 'last_obs_date',\n",
      "       'obs_count', 'geometry'],\n",
      "      dtype='object')\n",
      "\n",
      "There are [50] fires.\n"
     ]
    }
   ],
   "source": [
    "# Load the fire dataset for the Southern Rockies\n",
    "fires = gpd.read_file(os.path.join(projdir,'data/spatial/mod/NIFC/nifc-ics_2018_to_2023-aspen-obs.gpkg'))\n",
    "fires = fires[fires['na_l3name'] == 'Southern Rockies']\n",
    "\n",
    "# tidy the fire id and name columns\n",
    "fires.rename(columns={'NIFC_ID': 'Fire_ID', 'NIFC_NAME': 'Fire_Name'}, inplace=True)\n",
    "fires['obs_count'] = fires['obs_count'].fillna(0).astype(int) # fill NaN as 0 obs.\n",
    "fires = fires[fires['obs_count'] >= 10]\n",
    "\n",
    "# tidy the date columns\n",
    "fires['DISCOVERY_DATE'] = pd.to_datetime(fires['DISCOVERY_DATE']).dt.date\n",
    "fires['WF_CESSATION_DATE'] = pd.to_datetime(fires['WF_CESSATION_DATE']).dt.date\n",
    "\n",
    "print(f\"Available attributes: \\n{fires.columns}\")\n",
    "print(f\"\\nThere are [{len(fires)}] fires.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff9c103-7857-4ac0-b432-84489e80cd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding coordinates: [(-105.91670123621584, 40.451623739399885), (-105.18607078366145, 40.451623739399885), (-105.18607078366145, 40.788201870344174), (-105.91670123621584, 40.788201870344174), (-105.91670123621584, 40.451623739399885)]\n",
      "Date range for EA search request: (Timestamp('2020-08-13 00:00:00'), Timestamp('2020-10-24 00:00:00'))\n"
     ]
    }
   ],
   "source": [
    "# Grab a test fire (Cameron Peak)\n",
    "\n",
    "fire = fires[fires['Fire_Name'] == '416']\n",
    "\n",
    "buffer=1000\n",
    "coords, extent = get_coords(fire, buffer)\n",
    "print(f\"Bounding coordinates: {coords}\")\n",
    "\n",
    "start_date = fire['first_obs_date'].iloc[0]\n",
    "last_date = fire['last_obs_date'].iloc[0]\n",
    "date_range = (start_date, last_date)\n",
    "print(f\"Date range for EA search request: {date_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65931b59-d490-477e-8500-36b668db1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = ('2020-08-13', '2020-08-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceaf0c3-74ba-42b1-ac0a-01f18086eb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2ec4aa-7ec3-4916-a4de-a0c9d2ba5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search query with earthaccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947d7679-31c3-452b-b559-54cc47640bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 46\n"
     ]
    }
   ],
   "source": [
    "query = ea.search_data(\n",
    "    short_name=['VJ114IMG', 'VNP14IMG'], \n",
    "    polygon=coords,\n",
    "    temporal=date_range, \n",
    "    cloud_hosted=True,\n",
    "    count=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3c57db-b5dc-4d5c-9465-4275bc01bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "granules = [g['umm']['DataGranule']['Identifiers'][0]['Identifier']\n",
    "            for g in query if 'VJ114IMG' in g['umm']['DataGranule']['Identifiers'][0]['Identifier']]\n",
    "N = len(granules)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff31e877-77ce-4c3c-818c-6b9d1ceb07a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening 46 granules, approx size: 3.76 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be56f296171d40c4a994513bed022e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273186baba8d4a31a4a62cb8df761efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b761d36b6643a381b02e4600d720e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open the fileset remotely\n",
    "fileset = ea.open(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea9073b-eca9-4ae1-bea6-1837efb666e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<File-like object HTTPFileSystem, https://data.laadsdaac.earthdatacloud.nasa.gov/prod-lads/VJ103IMG/VJ103IMG.A2020226.0800.021.2021068002120.nc>\n"
     ]
    }
   ],
   "source": [
    "print(fileset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a97d020-af08-4d2e-8767-f797933fc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a total of 23 fire swaths.\n"
     ]
    }
   ],
   "source": [
    "# isolate the fire swaths from the geolocation swaths\n",
    "vj114_files = [f for f in fileset if 'VJ114IMG' in str(f)]\n",
    "print(f\"Processing a total of {len(vj114_files)} fire swaths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747c2214-3643-44e0-955b-e4c6227b7f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the fire swath: https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VJ114IMG.002/VJ114IMG.A2020226.0800.002.2024070113843/VJ114IMG.A2020226.0800.002.2024070113843.nc\n",
      "\n",
      "\tNo active fires detected in VJ114IMG.A2020226.0800.002.2024070113843.nc. Skipping...\n",
      "\n",
      "Opening the fire swath: https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VJ114IMG.002/VJ114IMG.A2020226.0936.002.2024070113845/VJ114IMG.A2020226.0936.002.2024070113845.nc\n",
      "\n",
      "\tNo active fires detected in VJ114IMG.A2020226.0936.002.2024070113845.nc. Skipping...\n",
      "\n",
      "Opening the fire swath: https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VJ114IMG.002/VJ114IMG.A2020226.1924.002.2024070113841/VJ114IMG.A2020226.1924.002.2024070113841.nc\n",
      "\n",
      "\tNo active fires detected in VJ114IMG.A2020226.1924.002.2024070113841.nc. Skipping...\n",
      "\n",
      "Opening the fire swath: https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VJ114IMG.002/VJ114IMG.A2020226.2100.002.2024070113843/VJ114IMG.A2020226.2100.002.2024070113843.nc\n",
      "\tProcessed the fire data in 0.0006711522738138835\n",
      "Opening the geolocation file: VJ103IMG.A2020226.2100.021.2021068012315.nc\n",
      "\tIt took 0.1299068013827006 to extract line and sample ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'geo_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt1)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to extract line and sample ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# mask to fire bounding extent\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     geo_scene \u001b[38;5;241m=\u001b[39m ((\u001b[43mgeo_slice\u001b[49m\u001b[38;5;241m.\u001b[39mlongitude \u001b[38;5;241m>\u001b[39m extent[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m&\u001b[39m (geo_slice\u001b[38;5;241m.\u001b[39mlongitude \u001b[38;5;241m<\u001b[39m extent[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     52\u001b[0m                  (geo_slice\u001b[38;5;241m.\u001b[39mlatitude \u001b[38;5;241m>\u001b[39m extent[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m&\u001b[39m (geo_slice\u001b[38;5;241m.\u001b[39mlatitude \u001b[38;5;241m<\u001b[39m extent[\u001b[38;5;241m3\u001b[39m]))\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt1)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to gather the geo scene ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Populate the dataframe\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geo_slice' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "for fp in vj114_files[0:5]:\n",
    "    df = pd.DataFrame() # to store the active fire data\n",
    "    t1 = time.time()\n",
    "    print(f\"Opening the fire swath: {fp.url}\")\n",
    "    with xr.open_dataset(fp, phony_dims='access') as swath:\n",
    "        # get the granule ID and associated geolocation swath\n",
    "        granule_id = swath.LocalGranuleID\n",
    "        geo_id = swath.VNP03IMG\n",
    "        \n",
    "        # Check for fire pixels in the specified region\n",
    "        lonfp = swath.variables['FP_longitude'][:] # fire pixel longitude\n",
    "        latfp = swath.variables['FP_latitude'][:] # fire pixel latitude\n",
    "        fire_scene = ((lonfp > extent[0]) & (lonfp < extent[1]) & \n",
    "                      (latfp > extent[2]) & (latfp < extent[3]))\n",
    "        if not fire_scene.any():  # Check for any fire pixels in region\n",
    "            print(f\"\\n\\tNo active fires detected in {granule_id}. Skipping...\\n\")\n",
    "            del fire_scene\n",
    "            continue # skip if no fire pixels in region\n",
    "        del fire_scene\n",
    "        \n",
    "        # granule attributes\n",
    "        daynight = swath.DayNightFlag #string Day or Night\n",
    "\n",
    "        # variables\n",
    "        fire = swath['fire mask'] # the fire mask\n",
    "        frp = swath.variables['FP_power'][:] # fire radiative power\n",
    "        t4 = swath.variables['FP_T4'][:] # I04 brightness temp (kelvins)\n",
    "        t5 = swath.variables['FP_T5'][:] # I05 brightness temp (kelvins)\n",
    "        \n",
    "        # tree = cKDTree(np.array([lonfp, latfp]).T) #search tree for finding nearest FRP\n",
    "\n",
    "    print(f\"\\tProcessed the fire data in {(time.time() - t1) / 60}\")\n",
    "\n",
    "    # open the associated geolocation file\n",
    "    print(f\"Opening the geolocation file: {geo_id}\")\n",
    "    t1 = time.time()\n",
    "\n",
    "    geods = [f for f in fileset if geo_id in str(f)][0]\n",
    "    with xr.open_dataset(\n",
    "        geods, group='geolocation_data', phony_dims='access',\n",
    "        drop_variables=['height', 'range', 'sensor_azimuth', 'sensor_zenith', \n",
    "                        'solar_azimuth', 'solar_zenith', 'land_water_mask', 'quality_flag']\n",
    "    ) as geo_ds:\n",
    "        # extract the pixel positions\n",
    "        i, j = np.indices(geo_ds.longitude.shape) #line and sample\n",
    "        print(f\"\\tIt took {(time.time() - t1) / 60} to extract line and sample ...\")\n",
    "        \n",
    "        # mask to fire bounding extent\n",
    "        geo_scene = ((geo_slice.longitude > extent[0]) & (geo_slice.longitude < extent[1]) & \n",
    "                     (geo_slice.latitude > extent[2]) & (geo_slice.latitude < extent[3])).values\n",
    "        print(f\"\\tIt took {(time.time() - t1) / 60} to gather the geo scene ...\")\n",
    "            \n",
    "    # Populate the dataframe\n",
    "    print(f\"Creating fire data frame...\")\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # gather information from file name\n",
    "    timestamp = granule_id.split('.')[1:3]\n",
    "    year = timestamp[0][1:5]\n",
    "    day = timestamp[0][5:8]\n",
    "    acqtime = timestamp[1]\n",
    "    acqdate = dt.datetime.strptime(year+day, '%Y%j').strftime('%-m/%-d/%Y')\n",
    "    \n",
    "    df['longitude'] = list(geo_ds.longitude.values[geo_scene])\n",
    "    df['latitude'] = list(geo_ds.latitude.values[geo_scene])\n",
    "    df['j'] = list(j[geo_scene]) #sample number for pixel size lookup\n",
    "    df['fire_mask'] = list(fire.values[geo_scene])\n",
    "    df['confidence'] = pd.Categorical( df.fire_mask)\n",
    "    df.confidence = df.confidence.replace(\n",
    "        {0:'x', 1:'x', 2:'x', 3:'x', 4:'x', 5:'x', 6:'x', 7:'l', 8:'n', 9:'h'})\n",
    "    df['daynight'] = daynight\n",
    "    df['acq_date'] = acqdate\n",
    "    df['acq_time'] = acqtime\n",
    "    df['granule_id'] = granule_id\n",
    "    df['geo_id'] = geo_id\n",
    "    \n",
    "    print(f\"\\tIt took {(time.time() - t1) / 60} to create the fire dataframe ...\")\n",
    "\n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"\\nTotal elapsed time: {t2:.2f} minutes.\\n\")\n",
    "print(\"\\n~~~~~~~~~~\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc4d9e-b578-4f8d-87ff-25bfb519889c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de504339-323b-4e3a-b37f-6e2db8fdfd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866193a0-a296-44ae-af98-be671e84982b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04076fc-a58d-46b3-94b4-94b43f408603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccde85-88f1-40ad-ad4d-97a6b86f6886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578688c-5e6f-4a9d-bc3b-3d410ed2ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all the files with xarray, examine the first\n",
    "def preprocess(ds):\n",
    "    # Assign coordinates based on the dimensions\n",
    "    ds = ds.assign_coords(\n",
    "        phony_dim_1=np.arange(ds.dims['phony_dim_1']),\n",
    "        phony_dim_2=np.arange(ds.dims['phony_dim_2']),\n",
    "    )\n",
    "    return ds\n",
    "    \n",
    "da = xr.open_mfdataset(\n",
    "    vnp14_fileset, \n",
    "    preprocess=preprocess,\n",
    "    combine='by_coords', \n",
    "    phony_dims='access'\n",
    ")\n",
    "print(f\"There are [{len(da)}] .nc files in the fileset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d144c6b-4bec-41ed-84ab-c8e093742c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "da['fire mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604a2a8-7d53-4b7b-b90f-741247b5d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "lonfp = da['FP_longitude'].values\n",
    "latfp = da['FP_latitude'].values\n",
    "\n",
    "# Filter the data for fire pixels\n",
    "frp = da.variables['FP_power'].values # fire radiative power\n",
    "t4 = da.variables['FP_T4'].values # I04 brightness temp (kelvins)\n",
    "t5 = da.variables['FP_T5'].values # I05 brightness temp (kelvins)\n",
    "\n",
    "# Create a DataFrame to store fire data\n",
    "fire_data = pd.DataFrame({\n",
    "    'longitude': lonfp.ravel(),\n",
    "    'latitude': latfp.ravel(),\n",
    "    'FRP': frp.ravel(),\n",
    "    'T4': t4.ravel(),\n",
    "    'T5': t5.ravel()\n",
    "})\n",
    "\n",
    "# Add metadata if available\n",
    "fire_data['daynight'] = da.attrs.get('DayNightFlag', 'Unknown')  # Granule day/night flag\n",
    "fire_data['granule_id'] = da.attrs.get('LocalGranuleID', 'Unknown')\n",
    "fire_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b550e50-59c5-43c4-b86f-c697be1e7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fire_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d078e-88e6-4291-9e99-b17edbda2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the files\n",
    "ea.download(query, self.out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab8b51-f3fb-4310-be39-310c6a4af16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10682c08-ce0b-48fd-94ac-e319c57eb5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021213e-0630-4b3c-859a-cf500c0357bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

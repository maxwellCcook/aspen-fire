{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652e9667-ea08-4b6a-97d0-dec73a5242b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success !\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os, shutil, time, glob, warnings, math\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "import h5py\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from affine import Affine\n",
    "from pyresample import geometry as geom\n",
    "from pyresample import kd_tree as kdt\n",
    "from os.path import join\n",
    "from osgeo import gdal, gdal_array, gdalconst, osr\n",
    "from scipy.interpolate import RegularGridInterpolator as RGI\n",
    "\n",
    "# Explicitly use GDAL exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# Projection information\n",
    "geog_crs = 'EPSG:4326'  # Geographic projection\n",
    "prj_crs = 'EPSG:5070'  # Projected coordinate system- WGS 84 NAD83 UTM Zone 13N\n",
    "\n",
    "# File path information\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "datadir = os.path.join(maindir,'Aim2/data/spatial/raw/VIIRS/')\n",
    "\n",
    "# File path information\n",
    "print(\"Success !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3a3566-b1cd-4ca3-8c29-4c157fbcd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to process VIIRS NetCDF files is ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Function to convert swath to grid\n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "def utmLookup(lat, lon):\n",
    "    utm = str((math.floor((lon + 180) / 6) % 60) + 1)\n",
    "    if len(utm) == 1:\n",
    "        utm = '0' + utm\n",
    "    if lat >= 0:\n",
    "        epsg_code = '326' + utm\n",
    "    else:\n",
    "        epsg_code = '327' + utm\n",
    "    return epsg_code\n",
    "\n",
    "\n",
    "def interpolate_geolocation(lat, lon, target_shape):\n",
    "    \"\"\" Interpolate the geolocation data to the target shape \"\"\"\n",
    "    lat_int = RGI((np.arange(lat.shape[0]), np.arange(lat.shape[1])), lat)\n",
    "    lon_int = RGI((np.arange(lon.shape[0]), np.arange(lon.shape[1])), lon)\n",
    "    target_coords = np.meshgrid(\n",
    "        np.linspace(0, lat.shape[0] - 1, target_shape[0]), \n",
    "        np.linspace(0, lon.shape[1] - 1, target_shape[1]), \n",
    "        indexing='ij')\n",
    "    target_coords = np.stack(target_coords, axis=-1)\n",
    "    lat_res = lat_int(target_coords)\n",
    "    lon_res = lon_int(target_coords)\n",
    "    return lat_res, lon_res\n",
    "\n",
    "\n",
    "def subset_array(array, areaDef, boundingCoords):\n",
    "    \"\"\" Subset the array using the fire perimeter coordinates \"\"\"\n",
    "    min_lon, min_lat = np.min(boundingCoords[:, 0]), np.min(boundingCoords[:, 1])\n",
    "    max_lon, max_lat = np.max(boundingCoords[:, 0]), np.max(boundingCoords[:, 1])\n",
    "    \n",
    "    # Transform the coordinates to array indices\n",
    "    col_start = int((min_lon - areaDef.area_extent[0]) / areaDef.pixel_size_x)\n",
    "    col_end = int((max_lon - areaDef.area_extent[0]) / areaDef.pixel_size_x)\n",
    "    row_start = int((areaDef.area_extent[3] - max_lat) / areaDef.pixel_size_y)\n",
    "    row_end = int((areaDef.area_extent[3] - min_lat) / areaDef.pixel_size_y)\n",
    "\n",
    "    return array[row_start:row_end, col_start:col_end]\n",
    "\n",
    "\n",
    "def viirs_swath2grid(fireDA, geoDA, shortName, sdsName, ecoSDS, geomCoords, out_dir):\n",
    "    \"\"\" Converts VIIRS AFD NetCDF SDS to grid and exports as GeoTIFF \"\"\"\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - fireDA: The NetCDF file containing the fire information (*.nc)\n",
    "        - geoDA: The corresponding geolocation file (*.h5)\n",
    "        - shortName: The short name for the data product (e.g., VNP14IMG, VJ114IMG)\n",
    "        - sdsName: The name for the Science Dataset (SDS) (e.g., FP_power)\n",
    "        - geomBounds: the bounding geometry to create the output spatial array\n",
    "        - geomCoords: list of coordinate pairs, used to filter the data array\n",
    "    Returns:\n",
    "        - Spatial (projected) array for the given SDS and bounding geometry\n",
    "    \"\"\"\n",
    "\n",
    "    #################################################################\n",
    "    # Open the geolocation file (.h5) and read contents (lat/lon SDS)\n",
    "    geo = h5py.File(geoDA)\n",
    "    geo_objs = []\n",
    "    geo.visit(geo_objs.append) # stores the SDS objects\n",
    "\n",
    "    # Get the file name \n",
    "    geoName = os.path.basename(geoDA).split('.h5')[0]\n",
    "\n",
    "    # Retrieve the coordinate SDS\n",
    "    latSD = [str(obj) for obj in geo_objs if isinstance(geo[obj], h5py.Dataset) and '/Latitude' in obj]\n",
    "    lonSD = [str(obj) for obj in geo_objs if isinstance(geo[obj], h5py.Dataset) and '/Longitude' in obj]\n",
    "    # Open coordinates as arrays\n",
    "    lat = geo[latSD[0]][()].astype(np.float32)\n",
    "    lon = geo[lonSD[0]][()].astype(np.float32)\n",
    "    print(f\"latGEO shape: {lat.shape}\\nlonGEO shape: {lon.shape}\\nData Type: {type(lat)}\")\n",
    "\n",
    "    dims = lat.shape # shape of the swath coordinate array\n",
    "\n",
    "    # lat[lat == geo[latSD[0]].attrs['_FillValue']] = np.nan\n",
    "    # lon[lon == geo[lonSD[0]].attrs['_FillValue']] = np.nan\n",
    "\n",
    "    # Get the middle swatch latlon\n",
    "    midLat, midLon = np.mean(lat), np.mean(lon) \n",
    "\n",
    "    # Identify the UTM Zone of the middle swath (NOT IMPLEMENTED YET)\n",
    "    utm_zone = utmLookup(midLat, midLon)\n",
    "    print(f\"UTM Zone of middle swath: {utm_zone}\")\n",
    "    \n",
    "    ############################\n",
    "    # Load data from NetCDF file\n",
    "    ds = Dataset(fireDA, 'r')\n",
    "\n",
    "    # Check if it is day or night\n",
    "    daynight = ds.getncattr('DayNightFlag')\n",
    "    \n",
    "    # Grab the Fire Pixel information (sparse arrays representing only pixel locations of active fire detections)\n",
    "    FP_power = ds.variables['FP_power'][:]\n",
    "    FP_latitude = ds.variables['FP_latitude'][:]\n",
    "    FP_longitude = ds.variables['FP_longitude'][:]\n",
    "\n",
    "    # Grab the fire mask (full array)\n",
    "    fire_mask = ds.variables['fire mask'][:]\n",
    "\n",
    "    # Debugging prints\n",
    "    print(f\"FP_power shape: {FP_power.shape}\") # see the sparse array\n",
    "    print(f\"FP_latitude shape: {FP_latitude.shape}\")\n",
    "    print(f\"FP_longitude shape: {FP_longitude.shape}\")\n",
    "    print(f\"Fire Mask shape: {fire_mask.shape}\") # see the full array\n",
    "\n",
    "    # Resample the latlon SDS shape to match the fire mask (750m geolocation to 375m)\n",
    "    lat_res, lon_res = interpolate_geolocation(lat, lon, fire_mask.shape)\n",
    "    print(f\"Resampled lat shape: {lat_res.shape}, Resampled lon shape: {lon_res.shape}\")\n",
    "    \n",
    "    # Create swath and area definition using coordinate arrays and projection information\n",
    "    swathDef = geom.SwathDefinition(lons=lon_res, lats=lat_res) # from 'pyresample' geom\n",
    "    epsg, proj, pName = '4326', 'latlong', 'Geographic'  # Set output projection to Geographic CRS\n",
    "    llLon, llLat, urLon, urLat = np.nanmin(lon_res), np.nanmin(lat_res), np.nanmax(lon_res), np.nanmax(lat_res)\n",
    "    areaExtent = (llLon, llLat, urLon, urLat)\n",
    "    projDict = {'proj': proj, 'datum': 'WGS84'}\n",
    "\n",
    "    # Calculate the pixel dimensions, cols, and rows\n",
    "    ps = np.min([abs(areaExtent[2] - areaExtent[0]) / fire_mask.shape[1],\n",
    "                 abs(areaExtent[3] - areaExtent[1]) / fire_mask.shape[0]]) \n",
    "    # ps = 0.00333663072035137202  # Hard-coded estimate of pixel size in degrees\n",
    "    cols = int(round((areaExtent[2] - areaExtent[0]) / ps))  # Calculate the output cols\n",
    "    rows = int(round((areaExtent[3] - areaExtent[1]) / ps))  # Calculate the output rows\n",
    "\n",
    "    print(f\"Pixel Dims: {ps};\\nNumber of columns: {cols};\\nNumber of rows: {rows}\")\n",
    "\n",
    "    # Define output geometry and set up resampling\n",
    "    areaDef = geom.AreaDefinition(epsg, pName, epsg, projDict, cols, rows, areaExtent) \n",
    "    index, outdex, indexArr, distArr = kdt.get_neighbour_info(swathDef, areaDef, 1125, neighbours=1)\n",
    "\n",
    "    print(f'Area Definition Shape: {areaDef.shape}')\n",
    "\n",
    "    # Perform kdtree resampling (swath 2 grid conversion) --- for the fire mask\n",
    "    fv = -9999\n",
    "    sdGEO = kdt.get_sample_from_neighbour_info('nn', areaDef.shape, fire_mask, index, outdex, indexArr, fill_value=fv)\n",
    "\n",
    "    # Create a full grid for FP_power based on the fire mask grid using pyresample's kd_tree.resample_nearest\n",
    "    fv = np.nan\n",
    "    \n",
    "    # Create a new swatch definition\n",
    "    swathDef_fire = geom.SwathDefinition(lons=FP_longitude, lats=FP_latitude) # fll is within the geometry bounds\n",
    "    FP_power_grid = kdt.resample_nearest(swathDef_fire, FP_power, areaDef, radius_of_influence=375, fill_value=fv)\n",
    "    \n",
    "    # # Subset the FRP grid using the fire perimeter coordinates\n",
    "    # coords_array = np.array(geomCoords)\n",
    "    # FP_power_grid_s = subset_array(FP_power_grid, areaDef, coords_array)\n",
    "\n",
    "    del sdGEO # clean up\n",
    "    \n",
    "    # Gather the geotransform definition\n",
    "    gt = [areaDef.area_extent[0], ps, 0, areaDef.area_extent[3], 0, -ps]\n",
    "    \n",
    "    # Set up the GeoTIFF export for day or night\n",
    "    outDir = os.path.join(out_dir, f'georeferenced/{shortName}/{daynight}')\n",
    "    # Check the directory exists, make it if not\n",
    "    if not os.path.exists(outDir):\n",
    "        os.makedirs(outDir)\n",
    "\n",
    "    # Set up output name\n",
    "    identifier_ = identifier.replace(\".\", \"_\")\n",
    "    platform_datetime = identifier_.split('_')[0] + \"_\" + identifier_.split('_')[1] + \"_\" + identifier_.split('_')[2]\n",
    "    outName = os.path.join(outDir, sdsName + '_' + platform_datetime + '.tif')\n",
    "    print(\"output file:\\n{}\\n\".format(outName))\n",
    "    \n",
    "    # Get driver, specify dimensions, define and set output geotransform\n",
    "    height, width = FP_power_grid.shape  # Define geotiff dimensions\n",
    "    driv = gdal.GetDriverByName('GTiff')\n",
    "    dataType = gdal_array.NumericTypeCodeToGDALTypeCode(FP_power_grid.dtype)\n",
    "    d = driv.Create(outName, width, height, 1, dataType)\n",
    "    d.SetGeoTransform(gt)\n",
    "\n",
    "    # Create and set output projection, write output array data\n",
    "    # Define target SRS\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(int(epsg))\n",
    "    d.SetProjection(srs.ExportToWkt())\n",
    "    band = d.GetRasterBand(1)\n",
    "    band.WriteArray(FP_power_grid)\n",
    "\n",
    "    # Define fill value if it exists, if not, set to mask fill value\n",
    "    if fv is not None and fv != 'NaN':\n",
    "        band.SetNoDataValue(fv)\n",
    "    else:\n",
    "        try:\n",
    "            band.SetNoDataValue(FP_power_grid.fill_value)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        except TypeError:\n",
    "            pass\n",
    "    \n",
    "    band.FlushCache()\n",
    "    d, band = None, None\n",
    "    \n",
    "\n",
    "def get_coords(geom, buffer):\n",
    "    \"\"\" Returns the bounding box coordinates for a given geometry(ies) and buffer \"\"\"\n",
    "    _geom = geom.copy()\n",
    "    _geom['geometry'] = _geom.geometry.buffer(buffer)\n",
    "    bounds = _geom.to_crs(geog_crs).unary_union.envelope # make sure it is in geographic coordinates\n",
    "    coords = list(bounds.exterior.coords)\n",
    "\n",
    "    del _geom, bounds\n",
    "    return coords\n",
    "    \n",
    "\n",
    "print(\"Function to process VIIRS NetCDF files is ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54bce8bb-50a9-4d94-929a-a32dbd80fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VJ103MODLL/VJ103MODLL.A2021243.1000.021.2021243163653.h5\n",
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VNP14IMG/VNP14IMG.A2021242.2048.002.2024074102039.nc\n",
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VJ114IMG/VJ114IMG.A2021239.0936.002.2024081210828.nc\n"
     ]
    }
   ],
   "source": [
    "# Testing for one fire\n",
    "testDir = os.path.join(datadir,'FIRED_3518')\n",
    "    \n",
    "# Get a list of geo files\n",
    "geo_files = list_files(testDir,\"*.h5\",recursive=True)\n",
    "print(geo_files[0])\n",
    "\n",
    "# Get list of fire data files\n",
    "vnp_files = list_files(testDir,\"VNP*.nc\",recursive=True)\n",
    "vj1_files = list_files(testDir,\"VJ1*.nc\",recursive=True)\n",
    "print(vnp_files[0])\n",
    "print(vj1_files[0])\n",
    "\n",
    "# Create a dictionary to store the file paths\n",
    "datadict = {\n",
    "    'VNP14IMG': vnp_files,\n",
    "    'VJ114IMG': vj1_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c8b8e6-6cdf-486e-ae63-6cdb78b2b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fired_id', 'ig_date', 'ig_day', 'ig_month', 'ig_year', 'last_date',\n",
      "       'event_dur', 'tot_pix', 'tot_ar_km2', 'fsr_px_dy', 'fsr_km2_dy',\n",
      "       'mx_grw_px', 'mn_grw_px', 'mu_grw_px', 'mx_grw_km2', 'mn_grw_km2',\n",
      "       'mu_grw_km2', 'mx_grw_dte', 'x', 'y', 'ig_utm_x', 'ig_utm_y', 'lc_code',\n",
      "       'lc_mode', 'lc_name', 'lc_desc', 'lc_type', 'eco_mode', 'eco_name',\n",
      "       'eco_type', 'tot_perim', 'pct_aspen', 'geometry'],\n",
      "      dtype='object')\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Load fire data and create a dictionary with bounding coordinates\n",
    "fires_path = os.path.join(maindir,'Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215e769d-bd0a-4fdf-b209-256add7d6618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRED_ID: 3518, \n",
      "Bounding Coordinates: \n",
      "[(-113.4870457742665, 37.31747928447832), (-113.45119936806327, 37.31747928447832), (-113.45119936806327, 37.336690972515356), (-113.4870457742665, 37.336690972515356), (-113.4870457742665, 37.31747928447832)]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store fire bounding coordinates\n",
    "coords_dict = {}\n",
    "buffer = 375 \n",
    "\n",
    "for index, row in fires.iterrows():\n",
    "    fire_id = row['fired_id']\n",
    "    perim = fires.loc[fires['fired_id'] == fire_id]\n",
    "    coords = get_coords(perim, buffer)\n",
    "    coords_dict[fire_id] = coords\n",
    "\n",
    "# Print the dictionary to verify\n",
    "first = next(iter(coords_dict.items()))\n",
    "print(f\"FIRED_ID: {first[0]}, \\nBounding Coordinates: \\n{first[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db720c6c-ed34-4b2e-8076-e3914d3eadcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NetCDF files for VNP14IMG\n",
      "There are 34 associated geolocation files ...\n",
      "VNP14IMG.A2021242.2048.002.2024074102039\n",
      "['/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VNP03MODLL/VNP03MODLL.A2021242.2048.002.2024017150503.h5']\n",
      "latGEO shape: (3232, 3200)\n",
      "lonGEO shape: (3232, 3200)\n",
      "Data Type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'utm_zone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(geo)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m###################################\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Now apply our processing function\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mviirs_swath2grid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfireDA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeoDA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshortName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshort_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43msdsName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mecoSDS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecoSDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeomCoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_dir\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# # Update the maximum FRP array\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# if daynight == \"Day\":\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     # Update the maximum FRP grid\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     else:\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#         max_frp_night = np.maximum(max_frp_night, maxFRP)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime to complete granule:\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0)\n",
      "Cell \u001b[0;32mIn[2], line 93\u001b[0m, in \u001b[0;36mviirs_swath2grid\u001b[0;34m(fireDA, geoDA, shortName, sdsName, ecoSDS, geomCoords, out_dir)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Identify the UTM Zone of the middle swath\u001b[39;00m\n\u001b[1;32m     92\u001b[0m utm_zome \u001b[38;5;241m=\u001b[39m utmLookup(midLat, midLon)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTM Zone of middle swath: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mutm_zone\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Load data from NetCDF file\u001b[39;00m\n\u001b[1;32m     97\u001b[0m ds \u001b[38;5;241m=\u001b[39m Dataset(fireDA, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utm_zone' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "dat = 'FP_power' # the SDS we are extracting ...\n",
    "\n",
    "fired_id = '3518'\n",
    "coords_ = coords_dict[fired_id]\n",
    "\n",
    "out_dir = testDir\n",
    "\n",
    "# max_frp_day = None # empty array to store the maximum FRP daily arrays (daytime obs.)\n",
    "# max_frp_night = None # empty array to store the maximum FRP daily arrays (nighttime obs.)\n",
    "\n",
    "for short_name, fpaths in datadict.items():\n",
    "    print(f\"Processing NetCDF files for {short_name}\")\n",
    "    # Retrieve the geolocations files corresponding to the short name\n",
    "    sh_code = short_name[:3] # the platform code (e.g., 'VNP')\n",
    "    _geo_files = [gf for gf in geo_files if sh_code in os.path.basename(gf)]\n",
    "    print(f\"There are {len(_geo_files)} associated geolocation files ...\")\n",
    "    for fp in fpaths:\n",
    "        identifier = os.path.basename(fp)[:-3]\n",
    "        print(identifier)\n",
    "\n",
    "        # Open the NetCDF file\n",
    "        ds = Dataset(fp, 'r', format='NETCDF4')  # Read in VIIRS AFD file\n",
    "\n",
    "        # Create a list of all SDS inside of the .nc file\n",
    "        ecoSDS = list(ds.variables.keys())\n",
    "\n",
    "        del ds # clean up !\n",
    "\n",
    "        # Find the matching ECO1BGEO file from the file list\n",
    "        parts = identifier.split('.')\n",
    "        if short_name == 'VNP14IMG':\n",
    "            date_time_part = '.'.join(parts[1:4])  # Extract date-time parts for the VNP Version 002\n",
    "        else:\n",
    "            date_time_part = '.'.join(parts[1:3])  \n",
    "        geo_identifier = sh_code + '03MODLL' + '.' + date_time_part\n",
    "        geo = [geo_link for geo_link in _geo_files if geo_identifier in os.path.basename(geo_link)]        \n",
    "        print(geo)\n",
    "\n",
    "        ###################################\n",
    "        # Now apply our processing function\n",
    "        viirs_swath2grid(\n",
    "            fireDA=fp, \n",
    "            geoDA=geo[0], \n",
    "            shortName=short_name, \n",
    "            sdsName=dat, \n",
    "            ecoSDS=ecoSDS, \n",
    "            geomCoords=coords_, \n",
    "            out_dir=out_dir\n",
    "        )\n",
    "\n",
    "        # # Update the maximum FRP array\n",
    "        # if daynight == \"Day\":\n",
    "        #     # Update the maximum FRP grid\n",
    "        #     if max_frp_day is None:\n",
    "        #         max_frp_day = maxFRP\n",
    "        #     else:\n",
    "        #         max_frp_day = np.maximum(max_frp_day, maxFRP)\n",
    "        # else:\n",
    "        #     # Update the maximum FRP grid\n",
    "        #     if max_frp_night is None:\n",
    "        #         max_frp_night = maxFRP\n",
    "        #     else:\n",
    "        #         max_frp_night = np.maximum(max_frp_night, maxFRP)\n",
    "        \n",
    "        print('Time to complete granule:', time.time() - t0)\n",
    "        print(\"\\n\")\n",
    "        print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffee50-31a9-4e7f-b0be-80b51c2d6e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c207a-70a6-423c-b516-e9efd687251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233a9a-2faf-4ce8-88cc-007bea1e7051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b334ad-13be-4e2c-9618-3a28388ecb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

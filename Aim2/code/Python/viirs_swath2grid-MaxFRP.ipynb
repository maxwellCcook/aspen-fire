{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652e9667-ea08-4b6a-97d0-dec73a5242b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reads VIIRS NetCDF files (active fire and geolocation data)\n",
    "Converts the swath to grid using geolocation information\n",
    "Creates a geolocated active fire product representing maximum FRP for the duration of a fire event\n",
    "\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "# Import packages\n",
    "\n",
    "import os, shutil, time, glob, warnings, math\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "import h5py\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from affine import Affine\n",
    "from pyresample import geometry as geom\n",
    "from pyresample import kd_tree as kdt\n",
    "from os.path import join\n",
    "from osgeo import gdal, gdal_array, gdalconst, osr\n",
    "\n",
    "# Explicitly use GDAL exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# Projection information\n",
    "geog_crs = 'EPSG:4326'  # Geographic projection\n",
    "prj_crs = 'EPSG:5070'  # Projected coordinate system- WGS 84 NAD83 UTM Zone 13N\n",
    "\n",
    "# File path information\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "datadir = os.path.join(maindir,'Aim2/data/spatial/raw/VIIRS/')\n",
    "dataoutdir = os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/')\n",
    "\n",
    "# File path information\n",
    "print(\"Success !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3a3566-b1cd-4ca3-8c29-4c157fbcd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to process VIIRS NetCDF files is ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Function to convert swath to grid\n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "def utmLookup(lat, lon):\n",
    "    utm = str((math.floor((lon + 180) / 6) % 60) + 1)\n",
    "    if len(utm) == 1:\n",
    "        utm = '0' + utm\n",
    "    if lat >= 0:\n",
    "        epsg_code = '326' + utm\n",
    "    else:\n",
    "        epsg_code = '327' + utm\n",
    "    return epsg_code\n",
    "\n",
    "\n",
    "def subset_array(array, areaDef, boundingCoords):\n",
    "    \"\"\" Subset the array using the fire perimeter coordinates \"\"\"\n",
    "    min_lon, min_lat = np.min(boundingCoords[:, 0]), np.min(boundingCoords[:, 1])\n",
    "    max_lon, max_lat = np.max(boundingCoords[:, 0]), np.max(boundingCoords[:, 1])\n",
    "    \n",
    "    # Transform the coordinates to array indices\n",
    "    col_start = int((min_lon - areaDef.area_extent[0]) / areaDef.pixel_size_x)\n",
    "    col_end = int((max_lon - areaDef.area_extent[0]) / areaDef.pixel_size_x)\n",
    "    row_start = int((areaDef.area_extent[3] - max_lat) / areaDef.pixel_size_y)\n",
    "    row_end = int((areaDef.area_extent[3] - min_lat) / areaDef.pixel_size_y)\n",
    "\n",
    "    return array[row_start:row_end, col_start:col_end]\n",
    "\n",
    "\n",
    "def create_global_grid(resolution=375):\n",
    "    \"\"\" Creates a global sinusoidal grid at the given resolution \"\"\"\n",
    "    # Sinusoidal projection parameters\n",
    "    radius = 6371007.181  # Radius of Earth in meters\n",
    "    pixel_size = resolution  # Pixel size in meters\n",
    "\n",
    "    # Calculate the number of columns and rows\n",
    "    cols = int((2 * np.pi * radius) / pixel_size)\n",
    "    rows = int((np.pi * radius) / pixel_size)\n",
    "\n",
    "    # Define the area extent in meters for the sinusoidal projection\n",
    "    area_extent = (-radius * np.pi, -radius * 0.5 * np.pi, radius * np.pi, radius * 0.5 * np.pi)\n",
    "\n",
    "    # Create the sinusoidal projection string\n",
    "    proj_str = (\n",
    "        'PROJCS[\"unnamed\",'\n",
    "        'GEOGCS[\"Unknown datum based upon the custom spheroid\", '\n",
    "        'DATUM[\"Not specified (based on custom spheroid)\", '\n",
    "        'SPHEROID[\"Custom spheroid\",6371007.181,0]], '\n",
    "        'PRIMEM[\"Greenwich\",0],'\n",
    "        'UNIT[\"degree\",0.0174532925199433]],'\n",
    "        'PROJECTION[\"Sinusoidal\"], '\n",
    "        'PARAMETER[\"longitude_of_center\",0], '\n",
    "        'PARAMETER[\"false_easting\",0], '\n",
    "        'PARAMETER[\"false_northing\",0], '\n",
    "        'UNIT[\"Meter\",1]]'\n",
    "    )\n",
    "\n",
    "    # Create the area definition using pyresample\n",
    "    area_def = geom.AreaDefinition(\n",
    "        'sinusoidal', 'Global Sinusoidal', proj_str,\n",
    "        {\n",
    "            'proj': 'sinu',\n",
    "            'lon_0': 0,\n",
    "            'x_0': 0,\n",
    "            'y_0': 0,\n",
    "            'a': radius,\n",
    "            'b': radius,\n",
    "            'units': 'm'\n",
    "        },\n",
    "        cols, rows, area_extent\n",
    "    )\n",
    "\n",
    "    return area_def\n",
    "    \n",
    "\n",
    "def export_geotiff(da_array, out_file_name, geotransform, epsg, na_data_val):\n",
    "    \"\"\" Exports a data array as GeoTIFF with specified paramters \"\"\"\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - da_array: data array to be exported as a geotiff\n",
    "        - out_file_name: the file path (full) for the exported geotiff\n",
    "        - geotransform: the defined geotransformation to be applied\n",
    "        - epsg: output coordinate reference system\n",
    "        - no_data_val: no data value to write \n",
    "    Returns:\n",
    "        - Exported GeoTIFF\n",
    "    \"\"\"\n",
    "    height, width = da_array.shape  # Define array dimensions\n",
    "    # Set up the driver and output file\n",
    "    driv = gdal.GetDriverByName('GTiff')\n",
    "    dataType = gdal_array.NumericTypeCodeToGDALTypeCode(da_array.dtype)\n",
    "    d = driv.Create(out_file_name, width, height, 1, dataType)\n",
    "    d.SetGeoTransform(geotransform)\n",
    "    # Define spatial reference system\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(int(epsg))\n",
    "    d.SetProjection(srs.ExportToWkt())\n",
    "    band = d.GetRasterBand(1)\n",
    "    band.WriteArray(da_array)\n",
    "    # Define fill value if it exists, if not, set to mask fill value\n",
    "    if na_data_val is not None and na_data_val != 'NaN':\n",
    "        band.SetNoDataValue(na_data_val)\n",
    "    else:\n",
    "        band.SetNoDataValue(np.nan)\n",
    "    # Flush the cash\n",
    "    band.FlushCache()\n",
    "    d, band = None, None\n",
    "    \n",
    "\n",
    "def viirs_swath2grid(fireDA, geoDA, shortName, sdsName, boundingCoords, out_dir):\n",
    "    \"\"\" Converts VIIRS AFD NetCDF SDS to grid and exports as GeoTIFF \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - fireDA: The NetCDF file containing the fire information (*.nc)\n",
    "        - geoDA: The corresponding geolocation file (*.h5)\n",
    "        - shortName: The short name for the data product (e.g., VNP14IMG, VJ114IMG)\n",
    "        - sdsName: The name for the Science Dataset (SDS) (e.g., FP_power)\n",
    "        - geomBounds: the bounding geometry to create the output spatial array\n",
    "        - geomCoords: list of coordinate pairs, used to filter the data array\n",
    "    Returns:\n",
    "        - Spatial (projected) array for the given SDS and bounding geometry\n",
    "    \"\"\"\n",
    "\n",
    "    #############################################################\n",
    "    # Open the geolocation data and read contents (lat/lon SDS) #\n",
    "\n",
    "    # Get the original file name \n",
    "    geoName = os.path.basename(geoDA).split('.nc')[0]\n",
    "\n",
    "    # Read the geolocation datasets (lat/lon)\n",
    "    geo_ds = Dataset(geoDA, 'r')\n",
    "    geoloc_da = geo_ds.groups['geolocation_data'] # where the geolocation data is stored\n",
    "    # Retrieve the coordinate SDS\n",
    "    lat = np.array(geoloc_da.variables['latitude'][:]).astype(np.float32)\n",
    "    lon = np.array(geoloc_da.variables['longitude'][:]).astype(np.float32)\n",
    "    print(f\"latGEO shape: {lat.shape}\\nlonGEO shape: {lon.shape}\\nData Type: {type(lat)}\")\n",
    "    # Store the dimensions for later\n",
    "    dims = lat.shape # shape of the swath coordinate array\n",
    "    \n",
    "    # Get the middle swath latlon\n",
    "    midLat, midLon = np.mean(lat), np.mean(lon) \n",
    "\n",
    "    # Identify the UTM Zone of the middle swath (NOT IMPLEMENTED YET)\n",
    "    utm_zone = utmLookup(midLat, midLon)\n",
    "    print(f\"UTM Zone of middle swath: {utm_zone}\")\n",
    "    \n",
    "    #####################################################\n",
    "    # Load data from NetCDF file (VNP14IMG or VJ114IMG) #\n",
    "    \n",
    "    afd_ds = Dataset(fireDA, 'r')\n",
    "\n",
    "    # Check if it is day or night\n",
    "    daynight = afd_ds.getncattr('DayNightFlag')\n",
    "\n",
    "    # Grab the fire mask (full array)\n",
    "    fire_mask = afd_ds.variables['fire mask'][:]\n",
    "    # Grab the Fire Pixel (FP) sparse data arrays \n",
    "    FP_power = afd_ds.variables['FP_power'][:]\n",
    "    FP_latitude = afd_ds.variables['FP_latitude'][:]\n",
    "    FP_longitude = afd_ds.variables['FP_longitude'][:]\n",
    "\n",
    "    del afd_ds # clean up, we have the arrays we need\n",
    "\n",
    "    # Debugging prints\n",
    "    print(f\"FP_power shape: {FP_power.shape}\") # see the sparse array\n",
    "    print(f\"FP_latitude shape: {FP_latitude.shape}\")\n",
    "    print(f\"FP_longitude shape: {FP_longitude.shape}\")\n",
    "    print(f\"Fire Mask shape: {fire_mask.shape}\") # see the full array\n",
    "\n",
    "    ##################################################################\n",
    "    # Create the swath definition, area definition, and geotransform #\n",
    "    \n",
    "    # Swath Definition from latlon arrays\n",
    "    swathDef = geom.SwathDefinition(lons=lon, lats=lat) # from 'pyresample' geom\n",
    "\n",
    "    # Create area definition using coordinate arrays and projection information\n",
    "    # Use info from aeqd bbox to calculate output cols/rows/pixel size\n",
    "    epsgConvert = pyproj.Proj(\"+proj=aeqd +lat_0={} +lon_0={}\".format(midLat, midLon))\n",
    "    llLon, llLat = epsgConvert(np.min(lon), np.min(lat), inverse=False)\n",
    "    urLon, urLat = epsgConvert(np.max(lon), np.max(lat), inverse=False)\n",
    "    areaExtent = (llLon, llLat, urLon, urLat)\n",
    "    cols = int(round((areaExtent[2] - areaExtent[0])/375))  # 375 m pixel size\n",
    "    rows = int(round((areaExtent[3] - areaExtent[1])/375))\n",
    "    '''Use no. rows and columns generated above from the aeqd projection\n",
    "                to set a representative number of rows and columns, which will then be translated\n",
    "                to degrees below, then take the smaller of the two pixel dims to determine output size'''\n",
    "    epsg, proj, pName = '4326', 'longlat', 'Geographic'\n",
    "    llLon, llLat, urLon, urLat = np.min(lon), np.min(lat), np.max(lon), np.max(lat)\n",
    "    areaExtent = (llLon, llLat, urLon, urLat)\n",
    "    projDict = pyproj.CRS(\"epsg:4326\") # geographic coordinate projection\n",
    "    areaDef = geom.AreaDefinition(epsg, pName, proj, projDict, cols, rows, areaExtent)\n",
    "    ps = np.min([areaDef.pixel_size_x, areaDef.pixel_size_y])  # Square pixels\n",
    "\n",
    "    # Now, recalculate the cols, rows, and area definition based on the pixel dimensions in degrees\n",
    "    cols = int(round((areaExtent[2] - areaExtent[0])/ps))  # Calculate the output cols\n",
    "    rows = int(round((areaExtent[3] - areaExtent[1])/ps))  # Calculate the output rows\n",
    "    areaDef = geom.AreaDefinition(epsg, pName, proj, projDict, cols, rows, areaExtent)\n",
    "    print(f\"Pixel Dims: {ps};\\nNumber of columns: {cols};\\nNumber of rows: {rows}\\nArea definition shape: {areaDef.shape}\")\n",
    "\n",
    "    # Gather the geotransform definition\n",
    "    gt = [areaDef.area_extent[0], ps, 0, areaDef.area_extent[3], 0, -ps]\n",
    "    \n",
    "    #####################################################\n",
    "    # Perform nearest neighbor sampling (SWATH to GRID) #\n",
    "    \n",
    "    # Get the neighbor info using radius of influence 3x pixel dims\n",
    "    index, outdex, indexArr, distArr = kdt.get_neighbour_info(swathDef, areaDef, 375, neighbours=1)\n",
    "    # Perform kdtree resampling (swath 2 grid conversion) --- for the fire mask\n",
    "    fv = -9999 # for the uint8 data type of the fire mask\n",
    "    sdGEO = kdt.get_sample_from_neighbour_info('nn', areaDef.shape, fire_mask, index, outdex, indexArr, fill_value=fv)\n",
    "\n",
    "    # Create a full grid for FP_power based on the fire mask grid using pyresample's kd_tree.resample_nearest\n",
    "    fv = np.nan\n",
    "    # Create a new swath definition\n",
    "    swathDef_fire = geom.SwathDefinition(lons=FP_longitude, lats=FP_latitude) # fll is within the geometry bounds\n",
    "    index, outdex, indexArr, distArr = kdt.get_neighbour_info(swathDef_fire, areaDef, 375, neighbours=1)\n",
    "    FP_power_grid = kdt.get_sample_from_neighbour_info('nn', areaDef.shape, FP_power, index, outdex, indexArr, fill_value=fv)\n",
    "\n",
    "    ###################################################################################\n",
    "    # Mask the FRP grid to include only active fire pixels (nominal or high confidence)\n",
    "    fire_pixels = (sdGEO == 8) | (sdGEO == 9)\n",
    "    FP_power_grid[~fire_pixels] = np.nan # Set areas outside the active fire detections as NaN\n",
    "    # Further mask the array by a bounding geometry\n",
    "\n",
    "    ########################################################################\n",
    "    # Define a global sinusoidal grid and resample the swath grid to it    #\n",
    "\n",
    "    index, outdex, indexArr, distArr = kdt.get_neighbour_info(areaDef, global_area_def, 375, neighbours=1)\n",
    "    sdGEO_res = kdt.get_sample_from_neighbour_info('nn', global_area_def.shape, sdGEO, index, outdex, indexArr, fill_value=fv)\n",
    "    # FP_power_grid_res = kdt.get_sample_from_neighbour_info('nn', global_area_def.shape, FP_power_grid, index, outdex, indexArr, fill_value=np.nan)\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    # Set up the GeoTIFF export for day or night\n",
    "    outDir = os.path.join(out_dir, f'georeferenced/{shortName}/{daynight}')\n",
    "    # Check the directory exists, make it if not\n",
    "    if not os.path.exists(outDir):\n",
    "        os.makedirs(outDir)\n",
    "\n",
    "    # Set up output name\n",
    "    identifier_ = identifier.replace(\".\", \"_\")\n",
    "    sdsName = sdsName.replace(\" \", \"_\")\n",
    "    platform_datetime = identifier_.split('_')[0] + \"_\" + identifier_.split('_')[1] + \"_\" + identifier_.split('_')[2]\n",
    "    outName = os.path.join(outDir, sdsName + '_' + platform_datetime + '.tif')\n",
    "    print(f\"\\noutput file:\\n{outName}\\n\")\n",
    "\n",
    "    # Export the GeoTIFF !!!\n",
    "    export_geotiff(FP_power_grid, outName, gt, epsg, fv)\n",
    "\n",
    "    outName = outName.replace(\"FP_power\", \"fire_mask\")\n",
    "    export_geotiff(sdGEO_res, outName, gt, epsg, fv)\n",
    "\n",
    "\n",
    "def get_coords(geom, buffer):\n",
    "    \"\"\" Returns the bounding box coordinates for a given geometry(ies) and buffer \"\"\"\n",
    "    _geom = geom.copy()\n",
    "    _geom['geometry'] = _geom.geometry.buffer(buffer)\n",
    "    bounds = _geom.to_crs(geog_crs).unary_union.envelope # make sure it is in geographic coordinates\n",
    "    coords = list(bounds.exterior.coords)\n",
    "\n",
    "    del _geom, bounds\n",
    "    return coords\n",
    "\n",
    "\n",
    "def calculate_max_frp(frp_stack, common_area_def):\n",
    "    dates = sorted(frp_stack.keys())\n",
    "    frp_data_arrays = [frp_stack[date] for date in dates]\n",
    "    # Convert the list of arrays to an xarray DataArray\n",
    "    frp_stack_da = xr.DataArray(frp_data_arrays, dims=['time', 'y', 'x'])\n",
    "    # Resample to a common pixel alignment\n",
    "    common_frp_stack = frp_stack_da.resample({'time': '1D'}).max(dim='time', skipna=True)\n",
    "    # Calculate the maximum FRP across the time series\n",
    "    max_frp = common_frp_stack.max(dim='time', skipna=True)\n",
    "    return max_frp\n",
    "\n",
    "print(\"Function to process VIIRS NetCDF files is ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54bce8bb-50a9-4d94-929a-a32dbd80fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of VNP14IMG: 17\n",
      "Length of VJ114IMG: 16\n",
      "Length of Geolocation files: 33\n",
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VNP14IMG/VNP14IMG.A2021242.2048.002.2024074102039.nc\n",
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VJ114IMG/VJ114IMG.A2021239.0936.002.2024081210828.nc\n",
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VNP03IMG/VNP03IMG.A2021240.2130.002.2021264132733.nc\n"
     ]
    }
   ],
   "source": [
    "# Testing for one fire\n",
    "testDir = os.path.join(datadir,'FIRED_3518')\n",
    "\n",
    "# Get list of fire data files\n",
    "vnp_files = list_files(testDir,\"VNP14*.nc\",recursive=True)\n",
    "vj1_files = list_files(testDir,\"VJ114*.nc\",recursive=True)\n",
    "\n",
    "# Grab the geolocation data\n",
    "geo_files = list_files(testDir,\"*03IMG*.nc\",recursive=True)\n",
    "\n",
    "print(f\"Length of VNP14IMG: {len(vnp_files)}\\nLength of VJ114IMG: {len(vj1_files)}\\nLength of Geolocation files: {len(geo_files)}\")\n",
    "\n",
    "print(vnp_files[0])\n",
    "print(vj1_files[0])\n",
    "print(geo_files[0])\n",
    "\n",
    "# Create a dictionary to store the file paths\n",
    "datadict = {\n",
    "    'VNP14IMG': vnp_files,\n",
    "    'VJ114IMG': vj1_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c8b8e6-6cdf-486e-ae63-6cdb78b2b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fired_id', 'ig_date', 'ig_day', 'ig_month', 'ig_year', 'last_date',\n",
      "       'event_dur', 'tot_pix', 'tot_ar_km2', 'fsr_px_dy', 'fsr_km2_dy',\n",
      "       'mx_grw_px', 'mn_grw_px', 'mu_grw_px', 'mx_grw_km2', 'mn_grw_km2',\n",
      "       'mu_grw_km2', 'mx_grw_dte', 'x', 'y', 'ig_utm_x', 'ig_utm_y', 'lc_code',\n",
      "       'lc_mode', 'lc_name', 'lc_desc', 'lc_type', 'eco_mode', 'eco_name',\n",
      "       'eco_type', 'tot_perim', 'pct_aspen', 'geometry'],\n",
      "      dtype='object')\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Load fire data and create a dictionary with bounding coordinates\n",
    "fires_path = os.path.join(maindir,'Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215e769d-bd0a-4fdf-b209-256add7d6618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRED_ID: 3518, \n",
      "Bounding Coordinates: \n",
      "[(-113.4870457742665, 37.31747928447832), (-113.45119936806327, 37.31747928447832), (-113.45119936806327, 37.336690972515356), (-113.4870457742665, 37.336690972515356), (-113.4870457742665, 37.31747928447832)]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store fire bounding coordinates\n",
    "# These can be used to subset the arrays before exporting the data\n",
    "coords_dict = {}\n",
    "buffer = 375 \n",
    "\n",
    "for index, row in fires.iterrows():\n",
    "    fire_id = row['fired_id']\n",
    "    perim = fires.loc[fires['fired_id'] == fire_id]\n",
    "    coords = get_coords(perim, buffer)\n",
    "    coords_dict[fire_id] = coords\n",
    "\n",
    "# Print the dictionary to verify\n",
    "first = next(iter(coords_dict.items()))\n",
    "print(f\"FIRED_ID: {first[0]}, \\nBounding Coordinates: \\n{first[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef36fc5e-e207-46aa-ac30-4bba08f8111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53373, 106747)\n"
     ]
    }
   ],
   "source": [
    "# Create a the global sinusoidal grid\n",
    "global_area_def = create_global_grid()\n",
    "print(global_area_def.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db720c6c-ed34-4b2e-8076-e3914d3eadcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NetCDF files for VNP14IMG\n",
      "There are 17 associated geolocation files ...\n",
      "VNP14IMG.A2021242.2048.002.2024074102039\n",
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/FIRED_3518/VNP03IMG/VNP03IMG.A2021242.2048.002.2021264144156.nc\n",
      "latGEO shape: (6464, 6400)\n",
      "lonGEO shape: (6464, 6400)\n",
      "Data Type: <class 'numpy.ndarray'>\n",
      "UTM Zone of middle swath: 32611\n",
      "FP_power shape: (1659,)\n",
      "FP_latitude shape: (1659,)\n",
      "FP_longitude shape: (1659,)\n",
      "Fire Mask shape: (6464, 6400)\n",
      "Pixel Dims: 0.0034526084770449017;\n",
      "Number of columns: 11060;\n",
      "Number of rows: 7308\n",
      "Area definition shape: (7308, 11060)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "dat = 'FP_power' # the SDS we are extracting ...\n",
    "\n",
    "fired_id = '3518'\n",
    "coords_ = coords_dict[fired_id]\n",
    "\n",
    "out_dir = testDir\n",
    "\n",
    "for short_name, fpaths in datadict.items():\n",
    "    print(f\"Processing NetCDF files for {short_name}\")\n",
    "    # Retrieve the geolocations files corresponding to the short name\n",
    "    sh_code = short_name[:3] # the platform code (e.g., 'VNP')\n",
    "    _geo_files = [gf for gf in geo_files if sh_code in os.path.basename(gf)]\n",
    "    print(f\"There are {len(_geo_files)} associated geolocation files ...\")\n",
    "    for fp in fpaths:\n",
    "        identifier = os.path.basename(fp)[:-3]\n",
    "        print(identifier)\n",
    "\n",
    "        # Open the NetCDF file\n",
    "        ds = Dataset(fp, 'r', format='NETCDF4')  # Read in VIIRS AFD file\n",
    "\n",
    "        # Create a list of all SDS inside of the .nc file\n",
    "        ecoSDS = list(ds.variables.keys())\n",
    "\n",
    "        del ds # clean up !\n",
    "\n",
    "        # Find the matching geolocation file from the file list\n",
    "        parts = identifier.split('.')\n",
    "        date_time_part = '.'.join(parts[1:3])  # Extract date-time parts for the VNP Version 002\n",
    "        geo_identifier = sh_code + '03IMG' + '.' + date_time_part\n",
    "        geo = [geo_link for geo_link in _geo_files if geo_identifier in os.path.basename(geo_link)][0]        \n",
    "        print(geo)\n",
    "\n",
    "        ###################################\n",
    "        # Now apply our processing function\n",
    "\n",
    "        try:\n",
    "            viirs_swath2grid(\n",
    "                fireDA=fp, \n",
    "                geoDA=geo, \n",
    "                shortName=short_name, \n",
    "                sdsName=dat,\n",
    "                boundingCoords=coords_, \n",
    "                out_dir=out_dir\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping granule {identifier}\\n{e}\")\n",
    "            # traceback.print_exc()  # This will print the full traceback\n",
    "            continue  # continue to the next granule\n",
    "        \n",
    "        print('Time to complete granule:', time.time() - t0)\n",
    "        print(\"\\n\")\n",
    "        print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffee50-31a9-4e7f-b0be-80b51c2d6e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c207a-70a6-423c-b516-e9efd687251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233a9a-2faf-4ce8-88cc-007bea1e7051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b334ad-13be-4e2c-9618-3a28388ecb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e9667-ea08-4b6a-97d0-dec73a5242b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads VIIRS NetCDF files (active fire and geolocation data)\n",
    "Converts the swath to grid using geolocation information\n",
    "Creates a geolocated active fire product representing maximum FRP for the duration of a fire event\n",
    "\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "# Import packages\n",
    "\n",
    "import os, shutil, time, glob, warnings, math\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "import h5py\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from affine import Affine\n",
    "from pyresample import geometry as geom\n",
    "from pyresample import kd_tree as kdt\n",
    "from os.path import join\n",
    "from osgeo import gdal, gdal_array, gdalconst, osr\n",
    "from scipy.interpolate import RegularGridInterpolator as RGI\n",
    "\n",
    "# Explicitly use GDAL exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# Projection information\n",
    "geog_crs = 'EPSG:4326'  # Geographic projection\n",
    "prj_crs = 'EPSG:5070'  # Projected coordinate system- WGS 84 NAD83 UTM Zone 13N\n",
    "\n",
    "# File path information\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "datadir = os.path.join(maindir,'Aim2/data/spatial/raw/VIIRS/')\n",
    "dataoutdir = os.path.join(maindir,'Aim2/data/spatial/mod/VIIRS/')\n",
    "\n",
    "# File path information\n",
    "print(\"Success !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3a3566-b1cd-4ca3-8c29-4c157fbcd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to process VIIRS NetCDF files is ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Function to convert swath to grid\n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "def utmLookup(lat, lon):\n",
    "    utm = str((math.floor((lon + 180) / 6) % 60) + 1)\n",
    "    if len(utm) == 1:\n",
    "        utm = '0' + utm\n",
    "    if lat >= 0:\n",
    "        epsg_code = '326' + utm\n",
    "    else:\n",
    "        epsg_code = '327' + utm\n",
    "    return epsg_code\n",
    "\n",
    "\n",
    "def subset_array(array, areaDef, boundingCoords):\n",
    "    \"\"\" Subset the array using the fire perimeter coordinates \"\"\"\n",
    "    min_lon, min_lat = np.min(boundingCoords[:, 0]), np.min(boundingCoords[:, 1])\n",
    "    max_lon, max_lat = np.max(boundingCoords[:, 0]), np.max(boundingCoords[:, 1])\n",
    "    \n",
    "    # Transform the coordinates to array indices\n",
    "    col_start = int((min_lon - areaDef.area_extent[0]) / areaDef.pixel_size_x)\n",
    "    col_end = int((max_lon - areaDef.area_extent[0]) / areaDef.pixel_size_x)\n",
    "    row_start = int((areaDef.area_extent[3] - max_lat) / areaDef.pixel_size_y)\n",
    "    row_end = int((areaDef.area_extent[3] - min_lat) / areaDef.pixel_size_y)\n",
    "\n",
    "    return array[row_start:row_end, col_start:col_end]\n",
    "\n",
    "\n",
    "def viirs_swath2grid(fireDA, geoDA, shortName, sdsName, ecoSDS, geomCoords, out_dir):\n",
    "    \"\"\" Converts VIIRS AFD NetCDF SDS to grid and exports as GeoTIFF \"\"\"\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - fireDA: The NetCDF file containing the fire information (*.nc)\n",
    "        - geoDA: The corresponding geolocation file (*.h5)\n",
    "        - shortName: The short name for the data product (e.g., VNP14IMG, VJ114IMG)\n",
    "        - sdsName: The name for the Science Dataset (SDS) (e.g., FP_power)\n",
    "        - geomBounds: the bounding geometry to create the output spatial array\n",
    "        - geomCoords: list of coordinate pairs, used to filter the data array\n",
    "    Returns:\n",
    "        - Spatial (projected) array for the given SDS and bounding geometry\n",
    "    \"\"\"\n",
    "\n",
    "    #################################################################\n",
    "    # Open the geolocation file (.h5) and read contents (lat/lon SDS)\n",
    "    geo = h5py.File(geoDA)\n",
    "    geo_objs = []\n",
    "    geo.visit(geo_objs.append) # stores the SDS objects\n",
    "\n",
    "    # Get the file name \n",
    "    geoName = os.path.basename(geoDA).split('.h5')[0]\n",
    "\n",
    "    # Retrieve the coordinate SDS\n",
    "    latSD = [str(obj) for obj in geo_objs if isinstance(geo[obj], h5py.Dataset) and '/Latitude' in obj]\n",
    "    lonSD = [str(obj) for obj in geo_objs if isinstance(geo[obj], h5py.Dataset) and '/Longitude' in obj]\n",
    "    # Open coordinates as arrays\n",
    "    lat = geo[latSD[0]][()].astype(np.float32)\n",
    "    lon = geo[lonSD[0]][()].astype(np.float32)\n",
    "    print(f\"latGEO shape: {lat.shape}\\nlonGEO shape: {lon.shape}\\nData Type: {type(lat)}\")\n",
    "\n",
    "    dims = lat.shape # shape of the swath coordinate array\n",
    "    \n",
    "    # Get the middle swatch latlon\n",
    "    midLat, midLon = np.mean(lat), np.mean(lon) \n",
    "\n",
    "    # Identify the UTM Zone of the middle swath (NOT IMPLEMENTED YET)\n",
    "    utm_zone = utmLookup(midLat, midLon)\n",
    "    print(f\"UTM Zone of middle swath: {utm_zone}\")\n",
    "    \n",
    "    ###################################################\n",
    "    # Load data from NetCDF file (VNP14IMG or VJ114IMG)\n",
    "    ds = Dataset(fireDA, 'r')\n",
    "\n",
    "    # Check if it is day or night\n",
    "    daynight = ds.getncattr('DayNightFlag')\n",
    "\n",
    "    # Grab the fire mask (full array)\n",
    "    fire_mask = ds.variables['fire mask'][:]\n",
    "    \n",
    "    # Grab the Fire Pixel information (sparse arrays representing only pixel locations of active fire detections)\n",
    "    FP_power = ds.variables['FP_power'][:]\n",
    "    FP_latitude = ds.variables['FP_latitude'][:]\n",
    "    FP_longitude = ds.variables['FP_longitude'][:]\n",
    "\n",
    "    del ds # clean up, we have the arrays we need\n",
    "\n",
    "    # # Debugging prints\n",
    "    # print(f\"FP_power shape: {FP_power.shape}\") # see the sparse array\n",
    "    # print(f\"FP_latitude shape: {FP_latitude.shape}\")\n",
    "    # print(f\"FP_longitude shape: {FP_longitude.shape}\")\n",
    "    # print(f\"Fire Mask shape: {fire_mask.shape}\") # see the full array\n",
    "\n",
    "    ##########################################################################\n",
    "    # Create the swath definition, area definition, and projection information\n",
    "    \n",
    "    # create the swath definition from latlon arrays\n",
    "    swathDef = geom.SwathDefinition(lons=lon, lats=lat) # from 'pyresample' geom\n",
    "\n",
    "    # Create area definition using coordinate arrays and projection information\n",
    "    # Use info from aeqd bbox to calculate output cols/rows/pixel size\n",
    "    epsgConvert = pyproj.Proj(\"+proj=aeqd +lat_0={} +lon_0={}\".format(midLat_res, midLon_res))\n",
    "    llLon, llLat = epsgConvert(np.min(lon_res), np.min(lat_res), inverse=False)\n",
    "    urLon, urLat = epsgConvert(np.max(lon_res), np.max(lat_res), inverse=False)\n",
    "    areaExtent = (llLon, llLat, urLon, urLat)\n",
    "    cols = int(round((areaExtent[2] - areaExtent[0])/375))  # 375 m pixel size\n",
    "    rows = int(round((areaExtent[3] - areaExtent[1])/375))\n",
    "    '''Use no. rows and columns generated above from the aeqd projection\n",
    "                to set a representative number of rows and columns, which will then be translated\n",
    "                to degrees below, then take the smaller of the two pixel dims to determine output size'''\n",
    "    epsg, proj, pName = '4326', 'longlat', 'Geographic'\n",
    "    llLon, llLat, urLon, urLat = np.min(lon_res), np.min(lat_res), np.max(lon_res), np.max(lat_res)\n",
    "    areaExtent = (llLon, llLat, urLon, urLat)\n",
    "    projDict = pyproj.CRS(\"epsg:4326\")\n",
    "    areaDef = geom.AreaDefinition(epsg, pName, proj, projDict, cols, rows, areaExtent)\n",
    "    ps = np.min([areaDef.pixel_size_x, areaDef.pixel_size_y])  # Square pixels\n",
    "\n",
    "    # Now, recalculate the cols, rows, and area definition\n",
    "    cols = int(round((areaExtent[2] - areaExtent[0])/ps))  # Calculate the output cols\n",
    "    rows = int(round((areaExtent[3] - areaExtent[1])/ps))  # Calculate the output rows\n",
    "    areaDef = geom.AreaDefinition(epsg, pName, proj, projDict, cols, rows, areaExtent)\n",
    "    \n",
    "    # epsg, proj, pName = '4326', 'latlong', 'Geographic'  # Set output projection to Geographic CRS\n",
    "    # llLon, llLat, urLon, urLat = np.nanmin(lon_res), np.nanmin(lat_res), np.nanmax(lon_res), np.nanmax(lat_res)\n",
    "    # areaExtent = (llLon, llLat, urLon, urLat)\n",
    "    # projDict = {'proj': proj, 'datum': 'WGS84'}\n",
    "    # # Calculate the pixel dimensions, cols, and rows\n",
    "    # ps = np.min([abs(areaExtent[2] - areaExtent[0]) / fire_mask.shape[1],\n",
    "    #              abs(areaExtent[3] - areaExtent[1]) / fire_mask.shape[0]]) \n",
    "    # # ps = 0.00333663072035137202  # Hard-coded estimate of pixel size in degrees\n",
    "    # cols = int(round((areaExtent[2] - areaExtent[0]) / ps))  # Calculate the output cols\n",
    "    # rows = int(round((areaExtent[3] - areaExtent[1]) / ps))  # Calculate the output rows\n",
    "    # # Create the area definition\n",
    "    # areaDef = geom.AreaDefinition(epsg, pName, epsg, projDict, cols, rows, areaExtent) \n",
    "    \n",
    "    print(f\"Pixel Dims: {ps};\\nNumber of columns: {cols};\\nNumber of rows: {rows}\\nArea definition shape: {areaDef.shape}\")\n",
    "\n",
    "    ###################################################\n",
    "    # Perform nearest neighbor sampling (SWATH to GRID)\n",
    "    \n",
    "    # Get the neighbor info using radius of influence 3x pixel dims\n",
    "    index, outdex, indexArr, distArr = kdt.get_neighbour_info(swathDef, areaDef, 1125, neighbours=1)\n",
    "    \n",
    "    # Perform kdtree resampling (swath 2 grid conversion) --- for the fire mask\n",
    "    fv = -9999 # for the uint data type of the fire mask\n",
    "    sdGEO = kdt.get_sample_from_neighbour_info('nn', areaDef.shape, fire_mask, index, outdex, indexArr, fill_value=fv)\n",
    "\n",
    "    # Create a full grid for FP_power based on the fire mask grid using pyresample's kd_tree.resample_nearest\n",
    "    fv = np.nan\n",
    "    # Create a new swath definition\n",
    "    swathDef_fire = geom.SwathDefinition(lons=FP_longitude, lats=FP_latitude) # fll is within the geometry bounds\n",
    "    FP_power_grid = kdt.resample_nearest(swathDef_fire, FP_power, areaDef, radius_of_influence=1, fill_value=fv)\n",
    "    \n",
    "    # # Subset the FRP grid using the fire perimeter coordinates\n",
    "    # coords_array = np.array(geomCoords)\n",
    "    # FP_power_grid_s = subset_array(FP_power_grid, areaDef, coords_array)\n",
    "\n",
    "    del sdGEO # clean up\n",
    "    \n",
    "    # Gather the geotransform definition\n",
    "    gt = [areaDef.area_extent[0], ps, 0, areaDef.area_extent[3], 0, -ps]\n",
    "    \n",
    "    # Set up the GeoTIFF export for day or night\n",
    "    outDir = os.path.join(out_dir, f'georeferenced/{shortName}/{daynight}')\n",
    "    # Check the directory exists, make it if not\n",
    "    if not os.path.exists(outDir):\n",
    "        os.makedirs(outDir)\n",
    "\n",
    "    # Set up output name\n",
    "    identifier_ = identifier.replace(\".\", \"_\")\n",
    "    platform_datetime = identifier_.split('_')[0] + \"_\" + identifier_.split('_')[1] + \"_\" + identifier_.split('_')[2]\n",
    "    outName = os.path.join(outDir, sdsName + '_' + platform_datetime + '.tif')\n",
    "    print(\"output file:\\n{}\\n\".format(outName))\n",
    "    \n",
    "    # Get driver, specify dimensions, define and set output geotransform\n",
    "    height, width = FP_power_grid.shape  # Define geotiff dimensions\n",
    "    driv = gdal.GetDriverByName('GTiff')\n",
    "    dataType = gdal_array.NumericTypeCodeToGDALTypeCode(FP_power_grid.dtype)\n",
    "    d = driv.Create(outName, width, height, 1, dataType)\n",
    "    d.SetGeoTransform(gt)\n",
    "\n",
    "    # Create and set output projection, write output array data\n",
    "    # Define target SRS\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(int(epsg))\n",
    "    d.SetProjection(srs.ExportToWkt())\n",
    "    band = d.GetRasterBand(1)\n",
    "    band.WriteArray(FP_power_grid)\n",
    "\n",
    "    # Define fill value if it exists, if not, set to mask fill value\n",
    "    if fv is not None and fv != 'NaN':\n",
    "        band.SetNoDataValue(fv)\n",
    "    else:\n",
    "        try:\n",
    "            band.SetNoDataValue(FP_power_grid.fill_value)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        except TypeError:\n",
    "            pass\n",
    "    \n",
    "    band.FlushCache()\n",
    "    d, band = None, None\n",
    "    \n",
    "\n",
    "def get_coords(geom, buffer):\n",
    "    \"\"\" Returns the bounding box coordinates for a given geometry(ies) and buffer \"\"\"\n",
    "    _geom = geom.copy()\n",
    "    _geom['geometry'] = _geom.geometry.buffer(buffer)\n",
    "    bounds = _geom.to_crs(geog_crs).unary_union.envelope # make sure it is in geographic coordinates\n",
    "    coords = list(bounds.exterior.coords)\n",
    "\n",
    "    del _geom, bounds\n",
    "    return coords\n",
    "    \n",
    "\n",
    "print(\"Function to process VIIRS NetCDF files is ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bce8bb-50a9-4d94-929a-a32dbd80fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for one fire\n",
    "testDir = os.path.join(datadir,'FIRED_3518')\n",
    "    \n",
    "# Get a list of geo files\n",
    "geo_files = list_files(testDir,\"*.h5\",recursive=True)\n",
    "print(geo_files[0])\n",
    "\n",
    "# Get list of fire data files\n",
    "vnp_files = list_files(testDir,\"VNP*.nc\",recursive=True)\n",
    "vj1_files = list_files(testDir,\"VJ1*.nc\",recursive=True)\n",
    "print(vnp_files[0])\n",
    "print(vj1_files[0])\n",
    "\n",
    "# Create a dictionary to store the file paths\n",
    "datadict = {\n",
    "    'VNP14IMG': vnp_files,\n",
    "    'VJ114IMG': vj1_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c8b8e6-6cdf-486e-ae63-6cdb78b2b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fire data and create a dictionary with bounding coordinates\n",
    "fires_path = os.path.join(maindir,'Aim2/data/spatial/mod/FIRED/fired_events_west_aspen.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e769d-bd0a-4fdf-b209-256add7d6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store fire bounding coordinates\n",
    "coords_dict = {}\n",
    "buffer = 375 \n",
    "\n",
    "for index, row in fires.iterrows():\n",
    "    fire_id = row['fired_id']\n",
    "    perim = fires.loc[fires['fired_id'] == fire_id]\n",
    "    coords = get_coords(perim, buffer)\n",
    "    coords_dict[fire_id] = coords\n",
    "\n",
    "# Print the dictionary to verify\n",
    "first = next(iter(coords_dict.items()))\n",
    "print(f\"FIRED_ID: {first[0]}, \\nBounding Coordinates: \\n{first[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db720c6c-ed34-4b2e-8076-e3914d3eadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "dat = 'FP_power' # the SDS we are extracting ...\n",
    "\n",
    "fired_id = '3518'\n",
    "coords_ = coords_dict[fired_id]\n",
    "\n",
    "out_dir = testDir\n",
    "\n",
    "# max_frp_day = None # empty array to store the maximum FRP daily arrays (daytime obs.)\n",
    "# max_frp_night = None # empty array to store the maximum FRP daily arrays (nighttime obs.)\n",
    "\n",
    "for short_name, fpaths in datadict.items():\n",
    "    print(f\"Processing NetCDF files for {short_name}\")\n",
    "    # Retrieve the geolocations files corresponding to the short name\n",
    "    sh_code = short_name[:3] # the platform code (e.g., 'VNP')\n",
    "    _geo_files = [gf for gf in geo_files if sh_code in os.path.basename(gf)]\n",
    "    print(f\"There are {len(_geo_files)} associated geolocation files ...\")\n",
    "    for fp in fpaths:\n",
    "        identifier = os.path.basename(fp)[:-3]\n",
    "        print(identifier)\n",
    "\n",
    "        # Open the NetCDF file\n",
    "        ds = Dataset(fp, 'r', format='NETCDF4')  # Read in VIIRS AFD file\n",
    "\n",
    "        # Create a list of all SDS inside of the .nc file\n",
    "        ecoSDS = list(ds.variables.keys())\n",
    "\n",
    "        del ds # clean up !\n",
    "\n",
    "        # Find the matching ECO1BGEO file from the file list\n",
    "        parts = identifier.split('.')\n",
    "        if short_name == 'VNP14IMG':\n",
    "            date_time_part = '.'.join(parts[1:4])  # Extract date-time parts for the VNP Version 002\n",
    "        else:\n",
    "            date_time_part = '.'.join(parts[1:3])  \n",
    "        geo_identifier = sh_code + '03MODLL' + '.' + date_time_part\n",
    "        geo = [geo_link for geo_link in _geo_files if geo_identifier in os.path.basename(geo_link)]        \n",
    "        print(geo)\n",
    "\n",
    "        ###################################\n",
    "        # Now apply our processing function\n",
    "        viirs_swath2grid(\n",
    "            fireDA=fp, \n",
    "            geoDA=geo[0], \n",
    "            shortName=short_name, \n",
    "            sdsName=dat, \n",
    "            ecoSDS=ecoSDS, \n",
    "            geomCoords=coords_, \n",
    "            out_dir=out_dir\n",
    "        )\n",
    "\n",
    "        # # Update the maximum FRP array\n",
    "        # if daynight == \"Day\":\n",
    "        #     # Update the maximum FRP grid\n",
    "        #     if max_frp_day is None:\n",
    "        #         max_frp_day = maxFRP\n",
    "        #     else:\n",
    "        #         max_frp_day = np.maximum(max_frp_day, maxFRP)\n",
    "        # else:\n",
    "        #     # Update the maximum FRP grid\n",
    "        #     if max_frp_night is None:\n",
    "        #         max_frp_night = maxFRP\n",
    "        #     else:\n",
    "        #         max_frp_night = np.maximum(max_frp_night, maxFRP)\n",
    "        \n",
    "        print('Time to complete granule:', time.time() - t0)\n",
    "        print(\"\\n\")\n",
    "        print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffee50-31a9-4e7f-b0be-80b51c2d6e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c207a-70a6-423c-b516-e9efd687251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233a9a-2faf-4ce8-88cc-007bea1e7051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b334ad-13be-4e2c-9618-3a28388ecb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

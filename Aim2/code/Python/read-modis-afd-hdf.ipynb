{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2519d5-19a7-485f-bde5-ca224d4bf5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/test/MOD14A2.A2023033.h09v05.006.2023041233546.hdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire'\n",
    "\n",
    "# Path to the HDF file\n",
    "hdf_file = os.path.join(maindir,'Aim2/data/spatial/raw/test/MOD14A2.A2023033.h09v05.006.2023041233546.hdf')\n",
    "print(hdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79632947-9c28-46a1-8d72-bdf77d1d2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/osgeo/gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF file using gdal\n",
    "hdf_ds = gdal.Open(hdf_file, gdal.GA_ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43129e6-7fa1-4133-88a0-f635a6a99df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdatasets in the HDF file:\n",
      "0: HDF4_EOS:EOS_GRID:\"/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/test/MOD14A2.A2023033.h09v05.006.2023041233546.hdf\":MODIS_Grid_8Day_Fire:FireMask\n",
      "1: HDF4_EOS:EOS_GRID:\"/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/test/MOD14A2.A2023033.h09v05.006.2023041233546.hdf\":MODIS_Grid_8Day_Fire:QA\n"
     ]
    }
   ],
   "source": [
    "# List all subdatasets in the HDF file\n",
    "subdatasets = hdf_ds.GetSubDatasets()\n",
    "print(\"Subdatasets in the HDF file:\")\n",
    "for i, subdataset in enumerate(subdatasets):\n",
    "    print(f\"{i}: {subdataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2528d91c-d31b-48a0-96fd-a57dc14484b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF file saved as /Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/test/output_fire_data.tif\n"
     ]
    }
   ],
   "source": [
    "# Select the subdataset you want to read (example: 'FireMask')\n",
    "subdataset_name = subdatasets[0][0]\n",
    "subdataset = gdal.Open(subdataset_name)\n",
    "\n",
    "# Read the data into a numpy array\n",
    "data = subdataset.ReadAsArray()\n",
    "\n",
    "# Get geo-information from the subdataset\n",
    "geo_transform = subdataset.GetGeoTransform()\n",
    "projection = subdataset.GetProjection()\n",
    "\n",
    "# Get dimensions of the dataset\n",
    "rows, cols = data.shape\n",
    "\n",
    "# Create a GeoTIFF file\n",
    "output_tiff = os.path.join(maindir,'Aim2/data/spatial/raw/test/output_fire_data.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "out_raster = driver.Create(output_tiff, cols, rows, 1, gdal.GDT_Int16)\n",
    "\n",
    "# Set the geo-transform and projection\n",
    "out_raster.SetGeoTransform(geo_transform)\n",
    "out_raster.SetProjection(projection)\n",
    "\n",
    "# Write the data to the GeoTIFF\n",
    "out_band = out_raster.GetRasterBand(1)\n",
    "out_band.WriteArray(data)\n",
    "\n",
    "# Flush data to disk and close the file\n",
    "out_band.FlushCache()\n",
    "out_raster = None\n",
    "\n",
    "print(f\"GeoTIFF file saved as {output_tiff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bbd7a3f-773b-40be-ad40-33c964176781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in the HDF5 file:\n",
      "HDFEOS\n",
      "HDFEOS/ADDITIONAL\n",
      "HDFEOS/ADDITIONAL/FILE_ATTRIBUTES\n",
      "HDFEOS/GRIDS\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields/Algorithm_bit_flags_QA\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields/Basic_QA\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields/NDSI\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields/NDSI_Snow_Cover\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields/Projection\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields/granule_pnt\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/XDim\n",
      "HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/YDim\n",
      "HDFEOS INFORMATION\n",
      "HDFEOS INFORMATION/StructMetadata.0\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "# Path to the HDF5 file\n",
    "hdf5_file = os.path.join(maindir,'Aim2/data/spatial/raw/test/VNP10A1.A2024069.h16v07.002.2024070100852.h5')\n",
    "\n",
    "# Open the HDF5 file using h5py\n",
    "hdf5 = h5py.File(hdf5_file, 'r')\n",
    "\n",
    "# List all datasets in the HDF5 file\n",
    "print(\"Datasets in the HDF5 file:\")\n",
    "# Function to recursively print the structure of the HDF5 file\n",
    "def print_structure(name, obj):\n",
    "    print(name)\n",
    "# Print the structure of the HDF5 file\n",
    "hdf5.visititems(print_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37a4e20b-64c9-4ebb-95b3-3265934af252",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'END_GROUP=SwathStructure\\nGROUP=GridStructure\\n\\tGROUP=GRID_1\\n\\t\\tGridName=\"VIIRS_Grid_IMG_2D\"\\n\\t\\tXDim=3000\\n\\t\\tYDim=3000\\n\\t\\tUpperLeftPointMtrs=(-2223901.039333'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m ulc_str \u001b[38;5;241m=\u001b[39m find_coords(gridmeta, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpperLeftPointMtrs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m lrc_str \u001b[38;5;241m=\u001b[39m find_coords(gridmeta, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLowerRightMtrs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m x_start, y_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, ulc_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m x_end, y_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, lrc_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate pixel size\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'END_GROUP=SwathStructure\\nGROUP=GridStructure\\n\\tGROUP=GRID_1\\n\\t\\tGridName=\"VIIRS_Grid_IMG_2D\"\\n\\t\\tXDim=3000\\n\\t\\tYDim=3000\\n\\t\\tUpperLeftPointMtrs=(-2223901.039333'"
     ]
    }
   ],
   "source": [
    "# Select the dataset you want to read\n",
    "dataset_name = 'HDFEOS/GRIDS/VIIRS_Grid_IMG_2D/Data Fields/NDSI_Snow_Cover'\n",
    "data = hdf5[dataset_name][()]\n",
    "\n",
    "# Extract the StructMetadata.0 attribute\n",
    "gridmeta = hdf5['HDFEOS INFORMATION/StructMetadata.0'][()].decode('utf-8')\n",
    "\n",
    "# Improved parsing for the StructMetadata.0 attribute\n",
    "def find_coords(metadata, corner):\n",
    "    start = metadata.find(corner + ' = (') + len(corner) + 4\n",
    "    end = metadata.find(')', start)\n",
    "    return metadata[start:end]\n",
    "\n",
    "ulc_str = find_coords(gridmeta, 'UpperLeftPointMtrs')\n",
    "lrc_str = find_coords(gridmeta, 'LowerRightMtrs')\n",
    "x_start, y_start = map(float, ulc_str.split(','))\n",
    "x_end, y_end = map(float, lrc_str.split(','))\n",
    "\n",
    "# Calculate pixel size\n",
    "rows, cols = data.shape\n",
    "pixel_size_x = (x_end - x_start) / cols\n",
    "pixel_size_y = (y_start - y_end) / rows  # note y_start > y_end for North-Up images\n",
    "\n",
    "# Define the geo-transform\n",
    "geo_transform = [x_start, pixel_size_x, 0, y_start, 0, -pixel_size_y]\n",
    "\n",
    "# Get the projection information (assuming WGS84, EPSG:4326)\n",
    "projection = 'EPSG:4326'\n",
    "\n",
    "# Create a GeoTIFF file\n",
    "output_tiff = os.path.join(maindir,'Aim2/data/spatial/raw/test/output_snow_cover.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "out_raster = driver.Create(output_tiff, cols, rows, 1, gdal.GDT_Int16)\n",
    "\n",
    "# Set the geo-transform and projection\n",
    "out_raster.SetGeoTransform(geo_transform)\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(int(projection.split(':')[1]))\n",
    "out_raster.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "# Write the data to the GeoTIFF\n",
    "out_band = out_raster.GetRasterBand(1)\n",
    "out_band.WriteArray(data)\n",
    "\n",
    "# Flush data to disk and close the file\n",
    "out_band.FlushCache()\n",
    "out_raster = None\n",
    "\n",
    "print(f\"GeoTIFF file saved as {output_tiff}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

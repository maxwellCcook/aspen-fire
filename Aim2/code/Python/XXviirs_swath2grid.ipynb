{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652e9667-ea08-4b6a-97d0-dec73a5242b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success !\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os, sys\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "import h5py\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from affine import Affine\n",
    "from pyresample import geometry as geom\n",
    "from pyresample import kd_tree as kdt\n",
    "\n",
    "from osgeo import gdal, gdal_array, gdalconst, osr\n",
    "from scipy.interpolate import RegularGridInterpolator as RGI\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "# Explicitly use GDAL exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# Projection information\n",
    "geog_crs = 'EPSG:4326'  # Geographic projection\n",
    "prj_crs = 'EPSG:5070'  # Projected coordinate system- WGS 84 NAD83 UTM Zone 13N\n",
    "\n",
    "# File path information\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/'\n",
    "projdir = os.path.join(maindir, 'aspen-fire/Aim2/')\n",
    "# Output directories\n",
    "dataraw = os.path.join(projdir,'data/spatial/raw/VIIRS/')\n",
    "datamod = os.path.join(maindir,'data/spatial/mod/VIIRS/')\n",
    "\n",
    "# File path information\n",
    "print(\"Success !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3a3566-b1cd-4ca3-8c29-4c157fbcd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to process VIIRS NetCDF files is ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Function to convert swath to grid\n",
    "\n",
    "def list_files(path, ext, recursive):\n",
    "    \"\"\"\n",
    "    List files of a specific type in a directory or subdirectories\n",
    "    \"\"\"\n",
    "    if recursive is True:\n",
    "        return glob.glob(os.path.join(path, '**', '*{}'.format(ext)), recursive=True)\n",
    "    else:\n",
    "        return glob.glob(os.path.join(path, '*{}'.format(ext)), recursive=False)\n",
    "\n",
    "\n",
    "def interpolate_geolocation(lat, lon, target_shape):\n",
    "    \"\"\" Interpolate the geolocation data to the target shape \"\"\"\n",
    "    lat_int = RGI((np.arange(lat.shape[0]), np.arange(lat.shape[1])), lat)\n",
    "    lon_int = RGI((np.arange(lon.shape[0]), np.arange(lon.shape[1])), lon)\n",
    "    target_coords = np.meshgrid(\n",
    "        np.linspace(0, lat.shape[0] - 1, target_shape[0]), \n",
    "        np.linspace(0, lon.shape[1] - 1, target_shape[1]), \n",
    "        indexing='ij')\n",
    "    target_coords = np.stack(target_coords, axis=-1)\n",
    "    lat_res = lat_int(target_coords)\n",
    "    lon_res = lon_int(target_coords)\n",
    "    return lat_res, lon_res\n",
    "\n",
    "\n",
    "def viirs_swath2grid(fireDA, geoDA, shortName, sdsName, ecoSDS, geomCoords, out_dir):\n",
    "    \"\"\" Converts VIIRS AFD NetCDF SDS to grid and exports as GeoTIFF \"\"\"\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - fireDA: The NetCDF file containing the fire information (*.nc)\n",
    "        - geoDA: The corresponding geolocation file (*.h5)\n",
    "        - shortName: The short name for the data product (e.g., VNP14IMG, VJ114IMG)\n",
    "        - sdsName: The name for the Science Dataset (SDS) (e.g., FP_power)\n",
    "        - geomBounds: the bounding geometry to create the output spatial array\n",
    "        - geomCoords: list of coordinate pairs, used to filter the data array\n",
    "    Returns:\n",
    "        - Spatial (projected) array for the given SDS and bounding geometry\n",
    "    \"\"\"\n",
    "\n",
    "    #################################################################\n",
    "    # Open the geolocation file (.h5) and read contents (lat/lon SDS)\n",
    "    \n",
    "    geo = h5py.File(geoDA)\n",
    "    geo_objs = []\n",
    "    geo.visit(geo_objs.append) # stores the SDS objects\n",
    "\n",
    "    # Get the file name \n",
    "    geoName = os.path.basename(geoDA).split('.h5')[0]\n",
    "\n",
    "    # Retrieve the coordinate SDS\n",
    "    latSD = [str(obj) for obj in geo_objs if isinstance(geo[obj], h5py.Dataset) and '/Latitude' in obj]\n",
    "    lonSD = [str(obj) for obj in geo_objs if isinstance(geo[obj], h5py.Dataset) and '/Longitude' in obj]\n",
    "    # Open coordinates as arrays\n",
    "    lat = geo[latSD[0]][()].astype(np.float32)\n",
    "    lon = geo[lonSD[0]][()].astype(np.float32)\n",
    "    print(f\"latGEO shape: {lat.shape}\\nlonGEO shape: {lon.shape}\\nData Type: {type(lat)}\")\n",
    "\n",
    "    dims = lat.shape # shape of the swath coordinate array\n",
    "\n",
    "    lat[lat == geo[latSD[0]].attrs['_FillValue']] = np.nan\n",
    "    lon[lon == geo[lonSD[0]].attrs['_FillValue']] = np.nan\n",
    "    \n",
    "    ############################\n",
    "    # Load data from NetCDF file\n",
    "    ds = Dataset(fireDA, 'r')\n",
    "    \n",
    "    # Grab the Fire Pixel information (sparse arrays representing only pixel locations of active fire detections)\n",
    "    FP_power = ds.variables['FP_power'][:]\n",
    "    FP_latitude = ds.variables['FP_latitude'][:]\n",
    "    FP_longitude = ds.variables['FP_longitude'][:]\n",
    "\n",
    "    # Grab the fire mask (full array)\n",
    "    fire_mask = ds.variables['fire mask'][:]\n",
    "\n",
    "    # Debugging prints\n",
    "    print(f\"FP_power shape: {FP_power.shape}\") # see the sparse array\n",
    "    print(f\"FP_latitude shape: {FP_latitude.shape}\")\n",
    "    print(f\"FP_longitude shape: {FP_longitude.shape}\")\n",
    "    print(f\"Fire Mask shape: {fire_mask.shape}\") # see the full array\n",
    "\n",
    "    # Resample the latlon SDS shape to match the fire mask (750m geolocation to 375m)\n",
    "    lat_res, lon_res = interpolate_geolocation(lat, lon, fire_mask.shape)\n",
    "    print(f\"Resampled lat shape: {lat_res.shape}, Resampled lon shape: {lon_res.shape}\")\n",
    "    \n",
    "    # Create swath and area definition using coordinate arrays and projection information\n",
    "    swathDef = geom.SwathDefinition(lons=lon_res, lats=lat_res) # from 'pyresample' geom\n",
    "    epsg, proj, pName = '4326', 'latlong', 'Geographic'  # Set output projection to Geographic CRS\n",
    "    llLon, llLat, urLon, urLat = np.nanmin(lon_res), np.nanmin(lat_res), np.nanmax(lon_res), np.nanmax(lat_res)\n",
    "    areaExtent = (llLon, llLat, urLon, urLat)\n",
    "    projDict = {'proj': proj, 'datum': 'WGS84'}\n",
    "\n",
    "    # Calculate the pixel dimensions, cols, and rows\n",
    "    ps = np.min([abs(areaExtent[2] - areaExtent[0]) / fire_mask.shape[1],\n",
    "                 abs(areaExtent[3] - areaExtent[1]) / fire_mask.shape[0]]) \n",
    "    # ps = 0.00333663072035137202  # Hard-coded estimate of pixel size in degrees\n",
    "    cols = int(round((areaExtent[2] - areaExtent[0]) / ps))  # Calculate the output cols\n",
    "    rows = int(round((areaExtent[3] - areaExtent[1]) / ps))  # Calculate the output rows\n",
    "\n",
    "    print(f\"Pixel Dims: {ps};\\nNumber of columns: {cols};\\nNumber of rows: {rows}\")\n",
    "\n",
    "    # Define output geometry and set up resampling\n",
    "    areaDef = geom.AreaDefinition(epsg, pName, epsg, projDict, cols, rows, areaExtent) \n",
    "    index, outdex, indexArr, distArr = kdt.get_neighbour_info(swathDef, areaDef, 3750, neighbours=1)\n",
    "\n",
    "    print(f'Area Definition Shape: {areaDef.shape}')\n",
    "\n",
    "    # Perform kdtree resampling (swath 2 grid conversion) --- for the fire mask\n",
    "    fv = -9999\n",
    "    sdGEO = kdt.get_sample_from_neighbour_info('nn', areaDef.shape, fire_mask, index, outdex, indexArr, fill_value=fv)\n",
    "    \n",
    "    # Gather the geotransform definition\n",
    "    gt = [areaDef.area_extent[0], ps, 0, areaDef.area_extent[3], 0, -ps]\n",
    "\n",
    "    # Set up the GeoTIFF export\n",
    "    outDir = os.path.join(out_dir, f'georeferenced/{shortName}')\n",
    "    # Check the directory exists, make it if not\n",
    "    if not os.path.exists(outDir):\n",
    "        os.makedirs(outDir)\n",
    "\n",
    "    # Set up output name\n",
    "    identifier_ = identifier.replace(\".\", \"_\")\n",
    "    outName = os.path.join(outDir, sdsName + '_' + identifier_ + '.tif')\n",
    "    print(\"output file:\\n{}\\n\".format(outName))\n",
    "    \n",
    "    # Get driver, specify dimensions, define and set output geotransform\n",
    "    height, width = sdGEO.shape  # Define geotiff dimensions\n",
    "    driv = gdal.GetDriverByName('GTiff')\n",
    "    dataType = gdal_array.NumericTypeCodeToGDALTypeCode(sdGEO.dtype)\n",
    "    d = driv.Create(outName, width, height, 1, dataType)\n",
    "    d.SetGeoTransform(gt)\n",
    "\n",
    "    # Create and set output projection, write output array data\n",
    "    # Define target SRS\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(int(epsg))\n",
    "    d.SetProjection(srs.ExportToWkt())\n",
    "    band = d.GetRasterBand(1)\n",
    "    band.WriteArray(sdGEO)\n",
    "\n",
    "    # Define fill value if it exists, if not, set to mask fill value\n",
    "    if fv is not None and fv != 'NaN':\n",
    "        band.SetNoDataValue(fv)\n",
    "    else:\n",
    "        try:\n",
    "            band.SetNoDataValue(sdGEO.fill_value)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        except TypeError:\n",
    "            pass\n",
    "    \n",
    "    band.FlushCache()\n",
    "    d, band = None, None\n",
    "    \n",
    "\n",
    "def get_coords(geom, buffer):\n",
    "    \"\"\" Returns the bounding box coordinates for a given geometry(ies) and buffer \"\"\"\n",
    "    _geom = geom.copy()\n",
    "    _geom['geometry'] = _geom.geometry.buffer(buffer)\n",
    "    bounds = _geom.to_crs(geog_crs).unary_union.envelope # make sure it is in geographic coordinates\n",
    "    coords = list(bounds.exterior.coords)\n",
    "\n",
    "    del _geom, bounds\n",
    "    return coords\n",
    "    \n",
    "\n",
    "print(\"Function to process VIIRS NetCDF files is ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bce8bb-50a9-4d94-929a-a32dbd80fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/416/VNP14IMG/VNP14IMG.A2018179.1000.002.2024080183012.nc\n",
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/aspen-fire/Aim2/data/spatial/raw/VIIRS/416/VNP03IMG/VNP03IMG.A2018155.0906.002.2021082151024.nc\n"
     ]
    }
   ],
   "source": [
    "nc_files = list_files(os.path.join(projdir, f'data/spatial/raw/VIIRS/'), \"*.nc\", recursive=True)\n",
    "\n",
    "vnp = [f for f in nc_files if 'VNP14' in os.path.basename(f)] # VNP14IMG (active fire)\n",
    "vnp03 = [f for f in nc_files if 'VNP03' in os.path.basename(f)] # VNP03IMG (geolocation)\n",
    "\n",
    "print(vnp[0])\n",
    "print(vnp03[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c8b8e6-6cdf-486e-ae63-6cdb78b2b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fire_ID', 'NIFC_NAME', 'NIFC_ACRES', 'FINAL_ACRES', 'pct_aspen',\n",
      "       'INCIDENT_ID', 'INCIDENT_NAME', 'START_YEAR', 'CAUSE', 'DISCOVERY_DATE',\n",
      "       'DISCOVERY_DOY', 'WF_CESSATION_DATE', 'WF_CESSATION_DOY',\n",
      "       'STR_DESTROYED_TOTAL', 'STR_DAMAGED_TOTAL', 'STR_THREATENED_MAX',\n",
      "       'EVACUATION_REPORTED', 'PEAK_EVACUATIONS', 'WF_PEAK_AERIAL',\n",
      "       'WF_PEAK_PERSONNEL', 'na_l3name', 'geometry'],\n",
      "      dtype='object')\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# Load the fire dataset\n",
    "fires_path = os.path.join(projdir,'data/spatial/mod/NIFC/nifc-ics_2018_to_2023-aspen_SRM.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "fires.rename(columns={'NIFC_ID': 'Fire_ID'}, inplace=True)\n",
    "print(fires.columns)\n",
    "print(len(fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215e769d-bd0a-4fdf-b209-256add7d6618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRED_ID: 14, \n",
      "Bounding Coordinates: \n",
      "[(-108.0032864406339, 37.382946754600226), (-107.80141845568734, 37.382946754600226), (-107.80141845568734, 37.60341937952868), (-108.0032864406339, 37.60341937952868), (-108.0032864406339, 37.382946754600226)]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store fire bounding coordinates\n",
    "coords_dict = {}\n",
    "buffer = 375 \n",
    "\n",
    "for index, row in fires.iterrows():\n",
    "    fire_id = row['Fire_ID']\n",
    "    perim = fires.loc[fires['Fire_ID'] == fire_id]\n",
    "    coords = get_coords(perim, buffer)\n",
    "    coords_dict[fire_id] = coords\n",
    "\n",
    "# Print the dictionary to verify\n",
    "first = next(iter(coords_dict.items()))\n",
    "print(f\"FIRED_ID: {first[0]}, \\nBounding Coordinates: \\n{first[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db720c6c-ed34-4b2e-8076-e3914d3eadcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NetCDF files for VNP14IMG\n",
      "\tThere are 94 associated geolocation files ...\n",
      "VNP14IMG.A2018179.1000.002.2024080183012\n",
      "VNP03IMG.A2018179.1000.002.2021084153603.nc\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Unable to synchronously open file (file read failed: time = Wed Oct 30 11:45:40 2024\n, filename = '/', file descriptor = 78, errno = 21, error message = 'Is a directory', buf = 0x16b1652e0, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(geo))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m###################################\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Now apply our processing function\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mviirs_swath2grid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfireDA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeoDA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshortName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshort_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43msdsName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mecoSDS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecoSDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeomCoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_dir\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime to complete granule:\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m, in \u001b[0;36mviirs_swath2grid\u001b[0;34m(fireDA, geoDA, shortName, sdsName, ecoSDS, geomCoords, out_dir)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    - fireDA: The NetCDF file containing the fire information (*.nc)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    - Spatial (projected) array for the given SDS and bounding geometry\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Open the geolocation file (.h5) and read contents (lat/lon SDS)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m geo \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeoDA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m geo_objs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     46\u001b[0m geo\u001b[38;5;241m.\u001b[39mvisit(geo_objs\u001b[38;5;241m.\u001b[39mappend) \u001b[38;5;66;03m# stores the SDS objects\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aspen-fire/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Unable to synchronously open file (file read failed: time = Wed Oct 30 11:45:40 2024\n, filename = '/', file descriptor = 78, errno = 21, error message = 'Is a directory', buf = 0x16b1652e0, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "dat = 'fire mask' # the SDS we are extracting ...\n",
    "\n",
    "fired_id = '14'\n",
    "coords_ = coords_dict[fired_id]\n",
    "\n",
    "short_name = 'VNP14IMG'\n",
    "print(f\"Processing NetCDF files for {short_name}\")\n",
    "\n",
    "# Retrieve the geolocations files corresponding to the short name\n",
    "sh_code = short_name[:3] # the platform code (e.g., 'VNP')\n",
    "_geo_files = [gf for gf in vnp03 if sh_code in os.path.basename(gf)]\n",
    "print(f\"\\tThere are {len(_geo_files)} associated geolocation files ...\")\n",
    "\n",
    "for fp in vnp[0:3]:\n",
    "    identifier = os.path.basename(fp)[:-3]\n",
    "    print(identifier)\n",
    "\n",
    "    # Open the NetCDF file\n",
    "    ds = Dataset(fp, 'r', format='NETCDF4')  # Read in VIIRS AFD file\n",
    "\n",
    "    # Create a list of all SDS inside of the .nc file\n",
    "    ecoSDS = list(ds.variables.keys())\n",
    "\n",
    "    del ds # clean up !\n",
    "\n",
    "    # Find the matching ECO1BGEO file from the file list\n",
    "    parts = identifier.split('.')\n",
    "    if short_name == 'VNP14IMG':\n",
    "        date_time_part = '.'.join(parts[1:4])  # Extract date-time parts for the VNP Version 002\n",
    "    else:\n",
    "        date_time_part = '.'.join(parts[1:3])  \n",
    "    geo_identifier = sh_code + '03IMG' + '.' + date_time_part\n",
    "    geo = [geo_link for geo_link in _geo_files if geo_identifier in os.path.basename(geo_link)][0]        \n",
    "    print(os.path.basename(geo))\n",
    "\n",
    "    ###################################\n",
    "    # Now apply our processing function\n",
    "    viirs_swath2grid(\n",
    "        fireDA=fp, \n",
    "        geoDA=geo[0], \n",
    "        shortName=short_name, \n",
    "        sdsName=dat, \n",
    "        ecoSDS=ecoSDS, \n",
    "        geomCoords=coords_, \n",
    "        out_dir=out_dir\n",
    "    )\n",
    "    \n",
    "    print('Time to complete granule:', time.time() - t0)\n",
    "    print(\"\\n\")\n",
    "    print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffee50-31a9-4e7f-b0be-80b51c2d6e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c207a-70a6-423c-b516-e9efd687251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233a9a-2faf-4ce8-88cc-007bea1e7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create FRP grid from daily granules\n",
    "def create_frp_grid(datadict, geo_files, coords_dict, out_dir):\n",
    "    \"\"\"\n",
    "    Create FRP grid from daily granules and eventually generate a maximum FRP grid for fire events.\n",
    "    \"\"\"\n",
    "    for fired_id, coords_ in coords_dict.items():\n",
    "        print(f\"Processing fire event {fired_id}\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Initialize an empty array to store the maximum FRP values\n",
    "        max_frp = None\n",
    "\n",
    "        for short_name, fpaths in datadict.items():\n",
    "            print(f\"Processing NetCDF files for {short_name}\")\n",
    "            sh_code = short_name[:3]  # the platform code (e.g., 'VNP')\n",
    "            _geo_files = [gf for gf in geo_files if sh_code in os.path.basename(gf)]\n",
    "            print(f\"There are {len(_geo_files)} associated geolocation files ...\")\n",
    "\n",
    "            for fp in fpaths:\n",
    "                identifier = os.path.basename(fp)[:-3]\n",
    "                print(identifier)\n",
    "\n",
    "                # Open the NetCDF file\n",
    "                ds = Dataset(fp, 'r', format='NETCDF4')  # Read in VIIRS AFD file\n",
    "\n",
    "                # Extract the FP_power SDS\n",
    "                FP_power = ds.variables['FP_power'][:]\n",
    "                fire_mask = ds.variables['fire mask'][:]\n",
    "\n",
    "                # Find the matching GEO file\n",
    "                parts = identifier.split('.')\n",
    "                if short_name == 'VNP14IMG':\n",
    "                    date_time_part = '.'.join(parts[1:4])  # Extract date-time parts for the VNP Version 002\n",
    "                else:\n",
    "                    date_time_part = '.'.join(parts[1:3])  \n",
    "                geo_identifier = sh_code + '03MODLL' + '.' + date_time_part\n",
    "                geo = [geo_link for geo_link in _geo_files if geo_identifier in os.path.basename(geo_link)]        \n",
    "                print(geo)\n",
    "\n",
    "                # Convert swath to grid\n",
    "                frp_grid = viirs_swath2grid(fp, geo[0], short_name, 'FP_power', ecoSDS=None, geomCoords=coords_, out_dir=out_dir)\n",
    "                \n",
    "                # Update the maximum FRP grid\n",
    "                if max_frp is None:\n",
    "                    max_frp = frp_grid\n",
    "                else:\n",
    "                    max_frp = np.maximum(max_frp, frp_grid)\n",
    "\n",
    "                print('Time to complete granule:', time.time() - t0)\n",
    "                print(\"\\n\")\n",
    "                print(\"---------------------------------------------\")\n",
    "\n",
    "        # Save the maximum FRP grid as a GeoTIFF\n",
    "        outName = os.path.join(out_dir, f'max_FRP_{fired_id}.tif')\n",
    "        save_geotiff(max_frp, outName, geo[0])\n",
    "\n",
    "        print(f\"Completed processing for fire event {fired_id} in {time.time() - t0} seconds\")\n",
    "\n",
    "# Function to save the FRP grid as a GeoTIFF\n",
    "def save_geotiff(array, out_name, geo_file):\n",
    "    \"\"\"\n",
    "    Save the FRP grid as a GeoTIFF file.\n",
    "    \"\"\"\n",
    "    geo = h5py.File(geo_file)\n",
    "    lat = geo['/Latitude'][()].astype(np.float32)\n",
    "    lon = geo['/Longitude'][()].astype(np.float32)\n",
    "    \n",
    "    ps = np.min([np.abs(lon[1] - lon[0]), np.abs(lat[1] - lat[0])])\n",
    "    gt = [np.min(lon), ps, 0, np.max(lat), 0, -ps]\n",
    "\n",
    "    # Get driver, specify dimensions, define and set output geotransform\n",
    "    height, width = array.shape  # Define geotiff dimensions\n",
    "    driv = gdal.GetDriverByName('GTiff')\n",
    "    dataType = gdal_array.NumericTypeCodeToGDALTypeCode(array.dtype)\n",
    "    d = driv.Create(out_name, width, height, 1, dataType)\n",
    "    d.SetGeoTransform(gt)\n",
    "\n",
    "    # Create and set output projection, write output array data\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)\n",
    "    d.SetProjection(srs.ExportToWkt())\n",
    "    band = d.GetRasterBand(1)\n",
    "    band.WriteArray(array)\n",
    "\n",
    "    band.FlushCache()\n",
    "    d, band = None, None\n",
    "    print(f\"Saved GeoTIFF: {out_name}\")\n",
    "\n",
    "# Test the function\n",
    "create_frp_grid(datadict, geo_files, coords_dict, testDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b334ad-13be-4e2c-9618-3a28388ecb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

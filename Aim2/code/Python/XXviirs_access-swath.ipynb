{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec03ae-2946-4baf-a5f7-f722a615f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Downloading VIIRS Active Fire Detections (AFD) with 'earthaccess' python API\n",
    "\n",
    "For a given geometry (in this case, fire perimeters), download data granules for:\n",
    "\n",
    "VIIRS/NPP Active Fires 6-Min L2 Swath 375m V002 (VNP14IMG)\n",
    "VIIRS/NPP Imagery Resolution Terrain Corrected Geolocation 6-Min L1 Swath 375 m (VNP03IMG)\n",
    "\n",
    "Return: \n",
    "    - Downloaded NetCDF granules for the above products\n",
    "    - GeoDataFrame representing active fire pixel locations and attributes (before geolocation)\n",
    "    - Geolocation grid representing pixel locations and overlap of adjacent orbits\n",
    "\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import sys, os\n",
    "import earthaccess\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import math\n",
    "import contextlib\n",
    "import traceback\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "import pyproj\n",
    "\n",
    "from netCDF4 import Dataset \n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "from affine import Affine\n",
    "from osgeo import gdal, gdal_array, gdalconst, osr\n",
    "from rasterio.transform import from_bounds\n",
    "from scipy.spatial import cKDTree\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger('earthaccess').setLevel(logging.ERROR)\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "        \n",
    "# Directories\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/'\n",
    "projdir = os.path.join(maindir, 'aspen-fire/Aim2/')\n",
    "\n",
    "# Output directories\n",
    "dataraw = os.path.join(projdir,'data/spatial/raw/VIIRS/')\n",
    "datamod = os.path.join(projdir,'data/spatial/mod/VIIRS/')\n",
    "\n",
    "print(\"Ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7ebd1-d1ba-400d-8b65-d3b993c033ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Download_VIIRS_AFD:\n",
    "    \"\"\" Downloads VIIRS Active Fire Data (AFD) within a region for given date range \"\"\"\n",
    "    def __init__(self, start_date, last_date, geom = gpd.GeoDataFrame(),\n",
    "                 id_col='Fire_ID', name_col='Fire_Name',\n",
    "                 geog_crs = 'EPSG:4326', proj_crs = 'EPSG:5070',\n",
    "                 short_names = ['VNP14IMG', 'VNP03IMG'], # active fire data and associated geolocation\n",
    "                 buffer = None, out_directory=None, processed_granules=None,\n",
    "                 download = False, region=None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - start_date: the intial date for the granule search\n",
    "            - last_date: the final date for the granule search\n",
    "            - geom: GeoDataFrame for search request (fire perimeter)\n",
    "            - geog_crs: Geographic projection (to retrieve coordinate pairs in lat/lon)\n",
    "            - proj_crs: Projected coordinate system\n",
    "            - short_names: the granules to be downloaded\n",
    "            - buffer: Optional buffer for input geometry\n",
    "            - out_directory: output directory to store results\n",
    "            - download: If 'True', downloads the netcdf, otherwise processes in cloud\n",
    "        Returns:\n",
    "            - Downloaded files (VIIRS Active Fire Data NetCDF and Geolocation information)\n",
    "            - GeoDataFrame with non-geolocated (raw) fire detections\n",
    "        \"\"\"\n",
    "        # Extract coordinate bounds\n",
    "        if region is None:\n",
    "            # use the fire perimeter\n",
    "            self.coords, self.extent = get_coords(geom, buffer)\n",
    "            print(f\"Bounding extent for data search: \\n{self.extent}\\n\")\n",
    "        elif region is not None and isinstance(region, gpd.GeoDataFrame):\n",
    "            # use the region boundary for FP and fire for search\n",
    "            _, self.extent = get_coords(region, buffer) # for extracting FP\n",
    "            self.coords, _ = get_coords(geom, buffer) # for data search\n",
    "            print(f\"Bounding extent for data search: \\n{self.extent}\\n\")\n",
    "        else:\n",
    "            print(\"Input region is not a GeoDataFrame !!!\")\n",
    "            \n",
    "        # Extract class attributes\n",
    "        self.fire_id = geom[id_col].iloc[0]\n",
    "        self.fire_name = geom[name_col].iloc[0]\n",
    "        self.date_range = (str(start_date), str(last_date))\n",
    "        self.geog_crs = geog_crs\n",
    "        self.proj_crs = proj_crs\n",
    "        self.short_names = short_names\n",
    "        self.out_dir = out_directory\n",
    "        self.processed_granules = processed_granules\n",
    "        self.download = download\n",
    "  \n",
    "    def ea_search_request(self):\n",
    "        \"\"\" Generate an earthaccess search request with the given parameters \"\"\"\n",
    "\n",
    "        query = earthaccess.search_data(\n",
    "            short_name=self.short_names, \n",
    "            polygon=self.coords,\n",
    "            temporal=self.date_range, \n",
    "            cloud_hosted=True,\n",
    "            count=-1\n",
    "        )\n",
    "        \n",
    "        # Grab a list of granule IDs\n",
    "        granules = [g['meta']['native-id'] for g in query]\n",
    "\n",
    "        # Filter the query to only work with the \"new\" granules\n",
    "        new = [g for g in granules if g not in self.processed_granules]\n",
    "        query_ = [item for item in query if item['meta']['native-id'] in new]\n",
    "        granules_ = [g['meta']['native-id'] for g in query_] # update the granule list\n",
    "\n",
    "        if self.download is True:\n",
    "            # Download the \"new\" granules\n",
    "            earthaccess.download(query_, self.out_dir)\n",
    "\n",
    "        # return query results and list of granules\n",
    "        return query_, granules_\n",
    "             \n",
    "\n",
    "    def create_fire_gdf(self, search_result):\n",
    "        \"\"\" Creates a geodataframe with active fire detections from a directory with NetCDF files \"\"\"\n",
    "\n",
    "        out_fire_dfs = [] # to store the geolocated AFDs\n",
    "        \n",
    "        # Identify VNP14 vs. VNP03\n",
    "        if self.download is True:\n",
    "            # Query the downloaded files\n",
    "            vnp14_files = list_files(os.path.join(self.out_dir,'VNP14IMG'), \"*.nc\", recursive=True)\n",
    "            vnp03_files = list_files(os.path.join(self.out_dir,'VNP03IMG'), \"*.nc\", recursive=True)\n",
    "        else:\n",
    "            vnp14_files = [g.data_links()[0] for g in search_result if 'VNP14IMG' in g.data_links()[0]]\n",
    "            vnp03_files = [g.data_links()[0] for g in search_result if 'VNP03IMG' in g.data_links()[0]]\n",
    "        \n",
    "        nprint = round(len(vnp14_files) / 4) # print counter\n",
    "        for idx, fp in enumerate(sorted(vnp14_files)):\n",
    "\n",
    "            df = pd.DataFrame() # to store the active fire data\n",
    "                \n",
    "            # Gather some metadata information from the file name\n",
    "            url = urlparse(fp)\n",
    "            basename = os.path.basename(url.path)    \n",
    "            timestamp = basename.split('.')[1:3]\n",
    "            year = timestamp[0][1:5]\n",
    "            day = timestamp[0][5:8]\n",
    "            time = timestamp[1]\n",
    "            date = dt.datetime.strptime(year+day, '%Y%j').strftime('%b %d') \n",
    "            acq_date = dt.datetime.strptime(year+day, '%Y%j').strftime('%-m/%-d/%y') #match FIRMS\n",
    "            daytime = int(time) > 1500 #timestamps in the 1900h-2200h UTC range are afternoon for Western US\n",
    "            \n",
    "            # Identify the corresponding geolocation file\n",
    "            geo_id = 'VNP03IMG.' + \".\".join(timestamp)\n",
    "            \n",
    "            # geo_fp = [geo_link for geo_link in vnp03_files if geo_id in geo_link][0]\n",
    "            geo_fp = next((link for link in vnp03_files if geo_id in link), None)   \n",
    "            if geo_fp is None:\n",
    "                print(f\"!!! No geolocation file found for: {identifier}\")\n",
    "                continue\n",
    "\n",
    "            query_ = [item for item in search_result if \".\".join(timestamp) in item.data_links()[0]]\n",
    "            \n",
    "            # Open the VNP14IMG and gather the data\n",
    "            fileset = earthaccess.open(query_)         \n",
    "            \n",
    "            with xr.open_dataset(fileset[1], phony_dims='access') as vnp14ds:\n",
    "\n",
    "                # Check for fire pixels in the specified region\n",
    "                lonfp = vnp14ds.variables['FP_longitude'][:] # fire pixel longitude\n",
    "                latfp = vnp14ds.variables['FP_latitude'][:] # fire pixel latitude\n",
    "                fire_scene = ((lonfp > self.extent[0]) & (lonfp < self.extent[1]) & \n",
    "                              (latfp > self.extent[2]) & (latfp < self.extent[3]))\n",
    "                if not fire_scene.any():  # Check for any fire pixels in region\n",
    "                    print(f\"\\tNo active fires detected in {basename}. Skipping...\")\n",
    "                    continue # skip if no fire pixels in region\n",
    "\n",
    "                fire = vnp14ds['fire mask'] # the fire mask\n",
    "                daynight = vnp14ds.DayNightFlag #string Day or Night\n",
    "                granule_id = vnp14ds.LocalGranuleID\n",
    "                frp = vnp14ds.variables['FP_power'][:] # fire radiative power\n",
    "                t4 = vnp14ds.variables['FP_T4'][:] # I04 brightness temp (kelvins)\n",
    "                t5 = vnp14ds.variables['FP_T5'][:] # I05 brightness temp (kelvins)\n",
    "                tree = cKDTree(np.array([lonfp, latfp]).T) #search tree for finding nearest FRP\n",
    "\n",
    "                del fire_scene\n",
    "                \n",
    "            # Read the geolocation data \n",
    "            with xr.open_dataset(fileset[0], group='geolocation_data', phony_dims='access') as geo_ds:\n",
    "                i, j = np.indices(geo_ds.longitude.shape) #line and sample\n",
    "                # Crop to fire bounding extent\n",
    "                geo_scene = ((geo_ds.longitude > self.extent[0]) & (geo_ds.longitude < self.extent[1]) & \n",
    "                             (geo_ds.latitude > self.extent[2]) & (geo_ds.latitude < self.extent[3])).values\n",
    "            \n",
    "            # Populate the dataframe\n",
    "            df['longitude'] = list(geo_ds.longitude.values[geo_scene])\n",
    "            df['latitude'] = list(geo_ds.latitude.values[geo_scene])\n",
    "            df['fire_mask'] = list(fire.values[geo_scene])\n",
    "            # df['fire_mask'] = pd.Categorical(df['fire_mask'])\n",
    "            df['confidence'] = df.fire_mask\n",
    "            df.confidence = df.confidence.replace(\n",
    "                {0:'x', 1:'x', 2:'x', 3:'x', 4:'x', 5:'x', 6:'x', 7:'l', 8:'n', 9:'h'})\n",
    "            df['daynight'] = daynight[0]\n",
    "            df['acq_date'] = acq_date\n",
    "            df['acq_time'] = time\n",
    "            df['granule_id'] = granule_id[0]\n",
    "            df['j'] = list(j[geo_scene]) #sample number for pixel size lookup\n",
    "            \n",
    "            # Retain only low-high confidence fire points\n",
    "            df = df[df['fire_mask'] > 6]\n",
    "            known = df[df.confidence!='x'] # keep only low-high confidence fire pixels\n",
    "        \n",
    "            #gather frp, brightness temps\n",
    "            for k in known.index:\n",
    "                dist, nearest = tree.query([ known.loc[k, 'longitude'], known.loc[k, 'latitude'] ])\n",
    "                df.loc[k, 'frp'] = frp[nearest].item()\n",
    "                df.loc[k, 'iot4'] = t4[nearest].item()\n",
    "                df.loc[k, 'iot5'] = t5[nearest].item()\n",
    "        \n",
    "            # Join to pixel size info\n",
    "            df_ = pd.merge(df, lut, left_on='j', right_on='sample', how='left')\n",
    "            df_.drop(columns=['j'], inplace=True)\n",
    "            \n",
    "            out_fire_dfs.append(df_) # append the granule dataframe\n",
    "        \n",
    "            if idx % nprint == 0:\n",
    "                print(f\"\\n\\tProcessed {idx+1} observations.\\n\")\n",
    "\n",
    "            del df, i, j, geo_scene, fire, latfp, lonfp, frp, tree, df_\n",
    "    \n",
    "        # Concatenate the out dfs\n",
    "        fire_data = pd.concat(out_fire_dfs) # for the entire list of granules\n",
    "        # fire_data.to_csv(os.path.join(datamod,f'vnp14img_aspen-fires_geo.csv'))\n",
    "        \n",
    "        return fire_data\n",
    "\n",
    "print(\"Class and functions ready !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01fda4e-77aa-449d-a1f6-a2539419007a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ed65d-83b6-4892-8253-e4b4158beab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217be10-a50b-472b-ac0d-98a2ebc9069a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1db138-d9da-4606-a1fe-7154b40c17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fire dataset for the Southern Rockies\n",
    "fires_path = os.path.join(projdir,'data/spatial/mod/NIFC/nifc-ics_2018_to_2023-aspen_SRM.gpkg')\n",
    "fires = gpd.read_file(fires_path)\n",
    "\n",
    "# Tidy the columns\n",
    "fires.rename(columns={'NIFC_ID': 'Fire_ID', 'NIFC_NAME': 'Fire_Name'}, inplace=True)\n",
    "fires['DISCOVERY_DATE'] = fires['DISCOVERY_DATE'].dt.date\n",
    "fires['WF_CESSATION_DATE'] = fires['WF_CESSATION_DATE'].dt.date\n",
    "\n",
    "# # Adjust the start and end dates\n",
    "# fires['start_date'] = fires['DISCOVERY_DATE'] - timedelta(days=2)\n",
    "\n",
    "print(f\"Available attributes: \\n{fires.columns}\")\n",
    "print(f\"\\nThere are [{len(fires)}] fires.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af0edb-153d-45e8-9d84-35086aa3215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with individual dates for each fire\n",
    "date_counts = pd.DataFrame(\n",
    "    [(fire['Fire_ID'], single_date)\n",
    "     for _, fire in fires.iterrows()\n",
    "     for single_date in pd.date_range(fire['DISCOVERY_DATE'], fire['WF_CESSATION_DATE'])],\n",
    "    columns=['Fire_ID', 'Date']\n",
    ")['Date'].value_counts()\n",
    "print(date_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8949b-5ad5-4c30-9da8-b096f854e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SRM bounds\n",
    "fp = os.path.join(projdir,'data/spatial/raw/boundaries/na_cec_eco_l3_west.gpkg')\n",
    "ecol3 = gpd.read_file(fp)\n",
    "srm = ecol3[ecol3['NA_L3NAME'] == 'Southern Rockies']\n",
    "print(srm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c463498c-da6f-4d43-96a9-edda0954e924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07ad72-8fdf-4640-9f9f-45c3dea9c7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c3128-d09b-4523-a0e9-bf90a63b5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# load the lookup table for pixel sizes\n",
    "lut = pd.read_csv(os.path.join(projdir,'data/tabular/raw/pix_size_lut.csv'))\n",
    "\n",
    "# Get a list of fire IDs\n",
    "fire_ids = fires['Fire_ID'].unique()\n",
    "\n",
    "afd_dfs = [] # to store the output geodataframes\n",
    "granules_p = set()\n",
    "\n",
    "# Loop fire ids\n",
    "for fire_id in fire_ids:\n",
    "    t00 = time.time()\n",
    "\n",
    "    fire = fires[fires['Fire_ID'] == fire_id]\n",
    "    \n",
    "    downloader = Download_VIIRS_AFD(\n",
    "        start_date=fire['DISCOVERY_DATE'].iloc[0],\n",
    "        last_date=fire['WF_CESSATION_DATE'].iloc[0],\n",
    "        geom=fire,\n",
    "        buffer=1000,\n",
    "        short_names=['VNP14IMG','VNP03IMG'],\n",
    "        out_directory=dataraw,\n",
    "        processed_granules=granules_p,\n",
    "        download=False,\n",
    "        region=srm\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        query, granules = downloader.ea_search_request()\n",
    "        granules.append(granules)\n",
    "        \n",
    "        print(f\"\\n\\tGeolocating active fires ...\\n\")\n",
    "        afd_fire = downloader.create_fire_gdf(query)\n",
    "        afd_dfs.append(afd_fire)\n",
    "        \n",
    "        del afd_fire\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping fire id {fire_id}\\n{e}\")\n",
    "        traceback.print_exc()  # This will print the full traceback\n",
    "        continue # continue to the next fire id\n",
    "\n",
    "    t1 = (time.time() - t00) / 60\n",
    "    print(f\"\\nTotal elapsed time for {fire_id}: {t1:.2f} minutes.\")\n",
    "    print(\"\\n~~~~~~~~~~\\n\")\n",
    "\n",
    "# Concatenate the results and save out the geodataframe of latlon fire pixels (non-geolocated)\n",
    "afds = pd.concat(afd_dfs, ignore_index=True)\n",
    "print(f\"\\n{afds.head()}\")\n",
    "afds.to_csv(os.path.join(datamod,'vnp14img_aspen-fires-srm_2018_to_2023_geo.gpkg'))\n",
    "\n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time: {t2:.2f} minutes.\")\n",
    "print(\"\\n~~~~~~~~~~\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a7a51-6f33-42d0-93b7-a1dac0f7405e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspen-fire",
   "language": "python",
   "name": "aspen-fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

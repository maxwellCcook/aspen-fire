---
title: "frp-models"
output: html_document
date: "2023-07-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(sf)
library(car)

getwd()

proj <- st_crs("ESRI:102039")

# Tidy the model data frame (daily FRP observations)

# Spatial data
frp.sp <- st_read("../../data/spatial/mod/vnp14img_west_spatial_w_attr.gpkg") %>%
 filter(daynight == "D") %>% # keep only daily observations for now
 # tidy the frame, select model coefficients
 select(
  id,mtbs_id,acq_date,frp,
  aspen_pct,cbd_mn,cbh_mn,
  vs_max,bi_max,vpd_max,
  elev,slope,roughness,
  evi_mn,pct_tree,pct_notree_veg,pct_noveg,
  geom
 ) %>%
 # Convert back to centroid (points)
 st_centroid() %>%
 st_transform(proj)

# Tabular format
frp.df <- frp.sp %>% st_set_geometry(NULL)

```

Filter out events with too few observations:

```{r}
groups <- frp.df %>% 
 group_by(mtbs_id) %>% 
 summarize(total_obs = n()) %>%
 ungroup() %>%
 filter(total_obs >= 10)

frp.sp <- frp.sp %>% filter(mtbs_id %in% groups$mtbs_id)
frp.df <- frp.df %>% filter(mtbs_id %in% groups$mtbs_id)

rm(groups)
```

```{r}
glimpse(frp.df)
```

Grab some summaries of the data:

```{r}
print(paste0("Number of events: ",length(unique(frp.df$mtbs_id))))
```

## Setting up the models

```{r}
hist(log(frp.df$frp))
```

# Generate the Inverse Probability Weight (IPW) weights for aspen percent cover within FRP observations

Following methods of causal inference in ecology, we will generate Inverse Probability Weights (IPW) for the continuous treatment (aspen percentage). Because we are running the models for each fire individually, we need to generate the IPW values for individual fires.

```{r}

# Center and scale the variables
sc.ipw <- frp.df %>%       
  mutate_at(c("cbd_mn","cbh_mn","evi_mn",
              "vs_max","bi_max","vpd_max",
              "elev","slope","roughness",
              "pct_tree","pct_notree_veg","pct_noveg"), 
            ~(scale(.) %>% as.vector))

# Loop through wildfires, calculating the IPW
dfs <- list()
fires <- unique(sc.ipw$mtbs_id)
for (i in 1:length(fires)) {

 # Get the fire data frame, y and x variables
 df <- sc.ipw %>% filter(mtbs_id == fires[i]) %>% drop_na()

 num <- 0
 den <- 0
 
 # Calculate the IPW for the fire
 # Calculate the numerator (expected distribution of aspen %)
 model_num <- lm(aspen_pct ~ 1, data = df)
 num <- dnorm(df$aspen_pct, predict(model_num), sd(model_num$residuals))
 
 # Now calculate the denominator (exp. distribution regressed against confounders)
 model_den <- lm(
  aspen_pct ~ cbd_mn + cbh_mn + vs_max + bi_max + vpd_max + 
   elev + slope + roughness + evi_mn +
   pct_tree + pct_notree_veg + pct_noveg, data=df)
 den <- dnorm(df$aspen_pct, predict(model_den), sd(model_den$residuals))
 # Add the IPW column to the data frame
 df <- df %>% mutate(ipw = num / den)
 
 dfs[[i]] <- df
}

# Bind the rows back together
frp.df <- bind_rows(dfs)
glimpse(frp.df)

# Tidy up
rm(model_num,model_den,num,den,df,dfs,i,sc.ipw)

```

# Step 1: Simple Generalized Linear Model (GLM)

# Scale the data

```{r}
# Center and scale the variables (only need to scale aspen percent)
sc <- frp.df %>%       
  mutate_at(c("aspen_pct"), 
            ~(scale(.) %>% as.vector))
glimpse(sc)
```

```{r}

# Run the GLM without model selection
model.glm <- glm(log(frp) ~ 1 + #log-scaled Fire Radiative Power (FRP)
                 aspen_pct + cbd_mn + cbh_mn + vs_max + bi_max + vpd_max +
                 elev + slope + roughness + evi_mn + pct_notree_veg,
               data = frp.df, weights = ipw)
summary(model.glm)
```

```{r}
#calculate the VIF for each predictor variable in the model
print("Variance Inflation Factor (VIF) results: ")
car::vif(model.ols)
```

```{r}
#test for normality in the residuals
hist(model.glm$residuals, breaks = 20)
plot(model.glm)
```

```{r}

# Effect table/plot
library(sjPlot)
plot_model(
 model.glm, 
 show.values = TRUE, 
 value.offset = .3, 
 vline.color="grey60",
 title="") + 
 theme_bw(9)

```

Testing the SAR workflow on one fire (High Park):

```{r}
fire <- frp.sp %>% filter(mtbs_id == "CO4020310623920201014") %>%
 left_join(frp.df%>%select(id,ipw),by="id") %>%
 mutate_at(c("aspen_pct","cbd_mn","cbh_mn","evi_mn",
              "vs_max","bi_max","vpd_max",
              "elev","slope","roughness",
              "pct_tree","pct_notree_veg","pct_noveg"), 
            ~(scale(.) %>% as.vector))
 # Scale the variables
# Create the spatial weights matrix
df.sp <- as_Spatial(fire)
coords <- sp::coordinates(df.sp) # grab the coordinates
ids <- row.names(as(df.sp,"data.frame")) # grab the ids
list_nb <- spdep::tri2nb(coords, row.names=ids)
W <- spdep::nb2listw(list_nb, style="W", zero.policy=FALSE) # the weights matrix
# Run the SAR model
model.sar <- 
  spatialreg::spautolm(log(frp) ~ aspen_pct + cbd_mn + cbh_mn + evi_mn + elev + slope + roughness + 
            vs_max + bi_max + vpd_max + pct_tree + pct_notree_veg + pct_noveg, 
         data=df.sp@data, 
         listw = W, 
         family = "SAR", 
         method="MC")
summary(model.sar)

# Store the model effects as a data frame
model.effects <- data.frame(coef(model.sar)) %>%
 rename(effect = coef.model.sar.) %>%
 tibble::rownames_to_column(.)
head(model.effects)
```


Now we need to generate a weights matrix for each fire event. We can do this in parallel ...

```{r}
# Set up the parallel computing
n_cores <- parallel::detectCores()
cl <- parallel::makeCluster(n_cores-1)
doParallel::registerDoParallel(cl)
```

Set up the function for generating the spatial weights matrix and mSAR model:

```{r include=F}

library(sp,quietly=T)
library(spdep,quietly=T)
library(spatialreg,quietly=T)

sar_model_ipw <- function(d) {
 ipw <- d$ipw
 # Create the weights matrix
 df.sp <- as_Spatial(d)
 df.sp <- remove.duplicates(df.sp)
 coords <- coordinates(df.sp) # grab the coordinates
 ids <- row.names(as(df.sp,"data.frame")) # grab the ids
 list_nb <- tri2nb(coords, row.names=ids)
 W <- nb2listw(list_nb, style="W", zero.policy=FALSE) # the weights matrix
 # Set up the model
 model.sar <- 
  spautolm(log(frp) ~ aspen_pct + evi_mn + elev + slope + roughness + 
            vs_max + bi_max + vpd_max + pct_tree + pct_notree_veg + pct_noveg, 
         data=df.sp@data, 
         listw = W, 
         family = "SAR", 
         method = "MC", 
         weights = ipw)
 # Store the model effects as a data frame
 model.effects <- data.frame(coef(model.sar)) %>%
  rename(effect = coef.model.sar.) %>%
  tibble::rownames_to_column(.)
 # Add the AIC
 return(model.effects)
}

```

```{r}

frp.sp <- frp.sp %>%
 left_join(frp.df%>%select(id,ipw),by="id") %>%
 mutate_at(c("aspen_pct","evi_mn","cbd_mn","cbh_mn",
              "vs_max","bi_max","vpd_max",
              "elev","slope","roughness",
              "pct_tree","pct_notree_veg","pct_noveg"), 
            ~(scale(.) %>% as.vector)) %>%
 filter(frp > 0)

# Split the data frame by Fire ID
# results <- split(frp.sp, frp.df$mtbs_id) # split the data frame into groups by fire id

# Run in parallel
dfs <- list()
fires <- unique(frp.sp$mtbs_id)
for (i in 1:length(fires)) {
 
 print(fires[i])
 
 # Get the fire data frame, y and x variables
 df <- frp.sp %>% filter(mtbs_id == fires[i]) %>% drop_na()
 
 # Run the SAR model, retrieving model effects
 df.sar <- sar_model_ipw(df)
 
 dfs[[i]] <- df.sar %>%
  mutate(fire = as.character(fires[i]))
}

# Bind the rows back together
sar.effects <- bind_rows(dfs)
glimpse(sar.effects)
```

Box-plot of effects:

```{r}
# By fire
ggplot(data=sar.effects %>% filter(rowname != "(Intercept)" & rowname != "lambda"),
       aes(y=rowname, x=effect)) +
 geom_boxplot() +
 xlim(-1,1) +
 theme_bw(14)
```

Run a glmer as well:

```{r}

```

## OLS Testing for Spatial Dependency

Test for spatial dependency in the data frame ...

First, run an OLS regression without the IPW and test for correlations using the VIF function:

```{r}

# Run the generalized OLS with IPW weights

model.ols <- lm(log(frp) ~ aspen_pct + lfcbd_avg + lfcbh_avg + 
                  chili + slope + vs_max + bi_max + vpd_max + pct_tree + pct_notree_veg,
               data = mod.df)
summary(model.ols)

#calculate the VIF for each predictor variable in the model
print("Variance Inflation Factor (VIF) results: ")
vif(model.ols)

#test for normality in the residuals
hist(model.ols$residuals, breaks = 20)

```

We can also look at the correlation plot:

```{r}

df <- mod.df %>% 
    st_set_geometry(NULL) %>% 
    as_tibble() %>%
    select(-c(GID,acq_date,LONGITUDE,LATITUDE,frp,ipw))

corr <- round(cor(df), 1)
p.mat <- cor_pmat(df)

corrp <- ggcorrplot(corr, hc.order = TRUE,
           type = "lower", p.mat = p.mat,
           lab = TRUE, 
           colors = c("#ca0020", "#f7f7f7", "#0571b0")) +
  theme_bw(8) +
  theme(axis.text.x = element_text(angle=35,hjust=1),
        axis.title = element_blank())
corrp

ggsave(corrp,file="../../figures/frp/correlations.png",dpi=150)

rm(corr,p.mat,df)

```

Seems like we might be OK in terms of correlated predictors. Now run the OLS with the IPW weights:

```{r}

model.ols_ipw <- lm(log(frp) ~ aspen_pct + lfcbd_avg + lfcbh_avg + 
                  chili + slope + vs_max + bi_max + vpd_max + pct_notree_veg + pct_tree,
               data = mod.df, weights = ipw)
summary(model.ols_ipw)

# # compare with anova
# print("Results from ANOVA: ")
# tidy(anova(model.ols, model.ols_ipw))
# hist(model.ols$residuals, breaks = 20)
# plot(model.ols)

```

Plot the spatially lagged frp:

```{r}

frp.lag <- lag.listw(W, mod.df$frp)

plot(frp.lag ~ mod.df$frp, pch=16, asp=1)
abline(lm(frp.lag ~ mod.df$frp), col="blue")

```

Now run the Moran's I test on the weighted model:

```{r}
# Run the Moran's I test
moran.lm <- lm.morantest(model.ols_ipw, W, alternative="two.sided")
print(moran.lm)
if (moran.lm$p.value < 0.5) {
  print("Null rejected, spatial dependency exists ...")
}

# Moran plot
moran.plot(log(mod.df$frp),W)

# Lm test
lmLMtests <- lm.LMtests(model.ols_ipw, W, test="all")
lmLMtests

# Tidy up
rm(moran.lm, lmLMtests)
```

Plot the residuals from the OLS model:

```{r}

df <- frp %>% 
  mutate(olsresids = resid(model.ols_ipw))
glimpse(df)

hist(df$olsresids)

ggplot(data=df) +
  geom_sf(aes(color=olsresids)) +
  scale_color_steps(
    name = "OLS Residuals",
    low = "lightsteelblue1",
    high = "tomato1",
    n.breaks = 7,
    show.limits = T) +
  theme_void()

rm(df)

```

We have high spatial dependence in simple OLS regression, indicating that we should use a spatial model.

Start with the most basic SAR model with IPW weights and spatial weights matrix:

```{r}

library(spatialreg,quietly=T)

model.sar <- spautolm(log(frp) ~ aspen_pct + lfcbd_avg + lfcbh_avg + chili + slope + vs_max + bi_max
                                  + vpd_max + pct_tree + pct_notree_veg, 
         data=spat.df@data, 
         listw = W, 
         family = "SAR", 
         method="MC", 
         weights = ipw)

summary(model.sar,Nagelkerke=T,adj.se=T)
coef(model.sar)
AIC(model.ols,model.ols_ipw,model.sar)

```

Check out some of the model parameters:

```{r}
resids <- residuals(model.sar)
hist(resids)
moran.test(resids,listw = W)
```

Plot the effects:

```{r}

sar.effects <- data.frame(coef(model.sar)) %>%
  rename(effect = coef.model.sar.) %>%
  mutate(sign = if_else(effect<0,"negative","positive"))
sar.effects <- tibble::rownames_to_column(sar.effects, "variable")
(sar.effects)

sar.effects$variable

sar.effects <- sar.effects %>% filter(variable != "(Intercept)" & variable != "lambda")

# Reorder band factors
sar.effects$variable <- factor(sar.effects$variable, 
                               levels = c("pct_tree","pct_notree_veg","vpd_max","bi_max","vs_max",
                                          "slope","chili","lfcbh_avg","lfcbd_avg","aspen_pct"))
  
sar.eff.plot <- ggplot(data=sar.effects,
                       aes(y=variable, x=effect, color=sign,label=round(effect,2))) +
  geom_point() +
  geom_text(vjust="inward",hjust="inward") +
  geom_vline(xintercept=0,color="grey60",size=0.4) +
  labs(x="Estimate") +
  theme_bw(9) +
  theme(legend.position = "none",
        axis.title.y = element_blank())
sar.eff.plot

```

Look at estimates from all models:

```{r}

library(sjPlot)
theme_sjplot(base_size = 7, base_family = "")

sjPlot::tab_model(model.ols, 
                  show.re.var= TRUE)

sjPlot::tab_model(model.ols_ipw, 
                  show.re.var= TRUE)

arrplot <- cowplot::plot_grid(
  plot_model(model.ols,show.values = TRUE, value.offset = .3, vline.color="grey60", title="") + theme_bw(9),
  plot_model(model.ols_ipw,show.values = TRUE, value.offset = .3, vline.color="grey60",title="") + theme_bw(9),
  sar.eff.plot,
  labels = c('A', 'B', 'C'),
  nrow=1, ncol=3
)
arrplot

ggsave(arrplot, file="../../figures/frp/model_effects_grid.png", width=9, height=4)

```


Set up the equation to generate Inverse Probability Weights (IPW) for aspen percentage:

```{r}

# The numerator is the probability distribution of just the treatment variable.
# We'll use a normal distribution for it (hence dnorm()). We need to feed
# dnorm() the grant amount for each person, the predicted value from a simple
# grant ~ 1 model, and the sd of the residuals from that model
model_num <- glm(aspen_prop_c ~ 1, data = model.df_sc)
num <- dnorm(model.df_sc$aspen_prop_c,
             predict(model_num),
             sd(model_num$residuals))

# The denominator is the probability distribution of the treatment variable
# explained by the confounders. We'll again use a normal distribution for it.
# We'll feed dnorm() the grant amount, the predicted value from a model that
# includes the confounders, and the sd of the residuals from that model
model_den <- glm(aspen_prop_c ~ lfcbh_avg + vs_p90 + 
    vpd_p90 + fm1000_p90 + elev_sd + aspect_mean + modis_pct_notree_veg, 
                 data = model.df_sc)
den <- dnorm(model.df_sc$aspen_prop_c,
             predict(model_den),
             sd(model_den$residuals))

model.df_ipw <- model.df_sc %>% 
  mutate(ipw = num / den)

head(model.df_ipw)

rm(num,model_num,model_den)

```

Look at estimates of both models:

Check assumptions:

```{r}
plot(model)
plot(model.ipw)
```

GLMM with nested effects for date/plot:

```{r}

model.df_ipw$day <- as.numeric(model.df_ipw$acq_date)

library(lme4,quietly=T)

model.ipw.glmm <- lmer(log(frp) ~ aspen_prop_c + lfcbh_avg + vs_p90 + 
                          vpd_p90 + fm1000_p90 + elev_sd + aspect_mean + modis_pct_notree_veg + (1|day),
                        data = model.df_ipw, weights=ipw)
summary(model.ipw.glmm)

```

```{r}
cowplot::plot_grid(
  plot_model(model.ipw.glmm,show.values = TRUE, value.offset = .3)+theme_minimal(10),
  plot_model(model.ipw.glmm, "re")+theme_minimal(10)
) +
  theme_bw(10)
```

```{r}
effects_aspen <- effects::effect(term= "aspen_prop_c", mod= model.ipw.glmm)
summary(effects_aspen) #output of what the values are
effects_aspen <- as.data.frame(effects_aspen)
```

```{r}
sjPlot::tab_model(model.ipw.glmm, 
                  show.re.var= TRUE)
```

## SAR Model

Time-series:

```{r}

ts.df <- model.df %>%
  st_set_geometry(NULL) %>% as_tibble() %>%
  select(-c(LATITUDE,LONGITUDE,GID,aspen_noaspen)) %>%
  group_by(acq_date) %>%
  summarize_all(list(mean))

ts.df <- ts.df %>%       
  mutate_at(c("aspen_prop_c", "lfcbd_avg", "lfcbh_avg", "vs_p90", "tmmx_p90",
              "bi_p90", "vpd_p90", "fm1000_p90", "elev_sd", "slope_mean",
              "aspect_mean", "modis_pct_notree_veg", "modis_pct_noveg"), 
            ~(scale(.) %>% as.vector))
glimpse(ts.df)

# # convert to multivariate time-series
# ts.df <- xts(ts.df[,-1], order.by=as.POSIXct(ts.df$acq_date))

```

Create the spatial weights matrix based on nearest neighbor:

```{r}

library(spdep)

coords<-cbind(model.df$LONGITUDE,model.df$LATITUDE)
coords<-as.matrix(coords)

nb <- dnearneigh(coords, 0, 2000, row.names = NULL, longlat = TRUE)
nb.w <- nb2listw(nb, glist=NULL, style="W", zero.policy=FALSE)

```

SAR model:

```{r}

library(spatialreg)
sar.chi <- lagsarlm(log(frp)~ aspen_prop_c + lfcbh_avg + vs_p90 + 
                      vpd_p90 + fm1000_p90 + elev_sd + aspect_mean + modis_pct_notree_veg + 
                      modis_pct_noveg, 
                    data=model.df, nb.w)
summary(sar.chi)

```


---
title: "frp-models"
output: html_document
date: "2023-07-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(sf)
library(car)

getwd()

proj <- st_crs("ESRI:102039")

# Tidy the model data frame (daily FRP observations)

# Spatial data (for SRME)
frp.sp <- st_read("../../data/spatial/mod/vnp14img_srme_spatial_w_attr.gpkg") %>%
 # filter(daynight == "D") %>% # keep only daily observations for now
 # tidy the frame, select model coefficients
 select(
  id,mtbs_id,acq_date,frp,
  aspen_pct,cbd_mn,cbh_mn,
  vs_max,bi_max,vpd_max,
  elev,slope,roughness,
  evi_mn,pct_tree,pct_notree_veg,pct_noveg,
  geom
 ) %>%
 mutate(ig_year = lubridate::year(acq_date)) %>%
 # Filter to get fires >= ig_year 2019 (matching w/ aspen classification)
 filter(ig_year >= 2019) %>%
 # Convert back to centroid (points)
 st_centroid() %>%
 st_transform(proj)

# Tabular format
frp.df <- frp.sp %>% st_set_geometry(NULL)

```

```{r}
summary(frp.df$ig_year)
```

Filter out events with too few observations:

```{r}
groups <- frp.df %>% 
 group_by(mtbs_id) %>% 
 summarize(total_obs = n()) %>%
 ungroup() %>%
 filter(total_obs >= 10)

frp.sp <- frp.sp %>% filter(mtbs_id %in% groups$mtbs_id)
frp.df <- frp.df %>% filter(mtbs_id %in% groups$mtbs_id)

rm(groups)
```

```{r}
glimpse(frp.df)
```

Grab some summaries of the data:

```{r}
print(paste0("Number of events: ",length(unique(frp.df$mtbs_id))))
```

## Setting up the models

```{r}
hist(log(frp.df$frp))
```

# Generate the Inverse Probability Weight (IPW) weights for aspen percent cover within FRP observations

Following methods of causal inference in ecology, we will generate Inverse Probability Weights (IPW) for the continuous treatment (aspen percentage). Because we are running the models for each fire individually, we need to generate the IPW values for individual fires.

```{r}

# Center and scale the variables
sc.ipw <- frp.df %>%       
  mutate_at(c("cbd_mn","cbh_mn","evi_mn",
              "vs_max","bi_max","vpd_max",
              "elev","slope","roughness",
              "pct_tree","pct_notree_veg","pct_noveg"), 
            ~(scale(.) %>% as.vector))

# Loop through wildfires, calculating the IPW
dfs <- list()
fires <- unique(sc.ipw$mtbs_id)
for (i in 1:length(fires)) {

 # Get the fire data frame, y and x variables
 df <- sc.ipw %>% filter(mtbs_id == fires[i]) %>% drop_na()

 num <- 0
 den <- 0
 
 # Calculate the IPW for the fire
 # Calculate the numerator (expected distribution of aspen %)
 model_num <- lm(aspen_pct ~ 1, data = df)
 num <- dnorm(df$aspen_pct, predict(model_num), sd(model_num$residuals))
 
 # Now calculate the denominator (exp. distribution regressed against confounders)
 model_den <- lm(
  aspen_pct ~ cbd_mn + cbh_mn + vs_max + bi_max + vpd_max + 
   elev + slope + roughness + evi_mn +
   pct_tree + pct_notree_veg + pct_noveg, data=df)
 den <- dnorm(df$aspen_pct, predict(model_den), sd(model_den$residuals))
 # Add the IPW column to the data frame
 df <- df %>% mutate(ipw = num / den)
 
 dfs[[i]] <- df
}

# Bind the rows back together
frp.df <- bind_rows(dfs)
glimpse(frp.df)

# Tidy up
rm(model_num,model_den,num,den,df,dfs,i,sc.ipw)

```

# Step 1: Simple Generalized Linear Model (GLM)

# Scale the data

```{r}
# Center and scale the variables (only need to scale aspen percent)
sc <- frp.df %>%       
  mutate_at(c("aspen_pct"), 
            ~(scale(.) %>% as.vector))
glimpse(sc)
```

```{r}

# Run the GLM without model selection
model.glm <- glm(log(frp) ~ 1 + #log-scaled Fire Radiative Power (FRP)
                 aspen_pct + cbd_mn + cbh_mn + vs_max + bi_max + vpd_max +
                 elev + slope + roughness + evi_mn + pct_tree + pct_notree_veg,
               data = sc, weights = ipw)
summary(model.glm)

```

```{r}
#calculate the VIF for each predictor variable in the model
print("Variance Inflation Factor (VIF) results: ")
car::vif(model.ols)
```

Let's take a look at the correlation plot:

```{r message=F}

df <- sc %>% select(-c(id,mtbs_id,acq_date,frp,ipw))

corr <- round(cor(df), 1)

corrp <- ggcorrplot::ggcorrplot(corr, hc.order = TRUE,
           type = "lower",
           lab = TRUE, 
           colors = c("#ca0020", "#f7f7f7", "#0571b0")) +
  theme_bw(8) +
  theme(axis.text.x = element_text(angle=35,hjust=1),
        axis.title = element_blank())
corrp

ggsave(corrp,file="../../figures/frp/correlations.png",dpi=150)

rm(corr,df)

```

Remove highly correlated variables:

```{r}
model.glm_ <- update(model.glm, . ~ . - cbh_mn - slope)
summary(model.glm_)
```

```{r}
#calculate the VIF for each predictor variable in the model
print("Variance Inflation Factor (VIF) results (round 2): ")
car::vif(model.glm_)
```

```{r}
#test for normality in the residuals
hist(model.glm$residuals, breaks = 20)
plot(model.glm)
```

## Testing for Spatial Dependency

Test for spatial dependency in the data frame ...

First, run an OLS regression without the IPW and test for correlations using the VIF function:

```{r}

# Run the generalized OLS with IPW weights

model.ols <- lm(log(frp) ~ aspen_pct + lfcbd_avg + lfcbh_avg + 
                  chili + slope + vs_max + bi_max + vpd_max + pct_tree + pct_notree_veg,
               data = mod.df)
summary(model.ols)

#calculate the VIF for each predictor variable in the model
print("Variance Inflation Factor (VIF) results: ")
vif(model.ols)

#test for normality in the residuals
hist(model.ols$residuals, breaks = 20)

```

We can also look at the correlation plot:



Seems like we might be OK in terms of correlated predictors. Now run the OLS with the IPW weights:

```{r}

model.ols_ipw <- lm(log(frp) ~ aspen_pct + lfcbd_avg + lfcbh_avg + 
                  chili + slope + vs_max + bi_max + vpd_max + pct_notree_veg + pct_tree,
               data = mod.df, weights = ipw)
summary(model.ols_ipw)

# # compare with anova
# print("Results from ANOVA: ")
# tidy(anova(model.ols, model.ols_ipw))
# hist(model.ols$residuals, breaks = 20)
# plot(model.ols)

```

Plot the spatially lagged frp:

```{r}

frp.lag <- lag.listw(W, mod.df$frp)

plot(frp.lag ~ mod.df$frp, pch=16, asp=1)
abline(lm(frp.lag ~ mod.df$frp), col="blue")

```

Now run the Moran's I test on the weighted model:

```{r}
# Run the Moran's I test
moran.lm <- lm.morantest(model.ols_ipw, W, alternative="two.sided")
print(moran.lm)
if (moran.lm$p.value < 0.5) {
  print("Null rejected, spatial dependency exists ...")
}

# Moran plot
moran.plot(log(mod.df$frp),W)

# Lm test
lmLMtests <- lm.LMtests(model.ols_ipw, W, test="all")
lmLMtests

# Tidy up
rm(moran.lm, lmLMtests)
```

Plot the residuals from the OLS model:

```{r}

df <- frp %>% 
  mutate(olsresids = resid(model.ols_ipw))
glimpse(df)

hist(df$olsresids)

ggplot(data=df) +
  geom_sf(aes(color=olsresids)) +
  scale_color_steps(
    name = "OLS Residuals",
    low = "lightsteelblue1",
    high = "tomato1",
    n.breaks = 7,
    show.limits = T) +
  theme_void()

rm(df)

```

We have high spatial dependence in simple OLS regression, indicating that we should use a spatial model.

Start with the most basic SAR model with IPW weights and spatial weights matrix:

```{r}

library(spatialreg,quietly=T)

model.sar <- spautolm(log(frp) ~ aspen_pct + lfcbd_avg + lfcbh_avg + chili + slope + vs_max + bi_max
                                  + vpd_max + pct_tree + pct_notree_veg, 
         data=spat.df@data, 
         listw = W, 
         family = "SAR", 
         method="MC", 
         weights = ipw)

summary(model.sar,Nagelkerke=T,adj.se=T)
coef(model.sar)
AIC(model.ols,model.ols_ipw,model.sar)

```

Check out some of the model parameters:

```{r}
resids <- residuals(model.sar)
hist(resids)
moran.test(resids,listw = W)
```

Plot the effects:

```{r}

sar.effects <- data.frame(coef(model.sar)) %>%
  rename(effect = coef.model.sar.) %>%
  mutate(sign = if_else(effect<0,"negative","positive"))
sar.effects <- tibble::rownames_to_column(sar.effects, "variable")
(sar.effects)

sar.effects$variable

sar.effects <- sar.effects %>% filter(variable != "(Intercept)" & variable != "lambda")

# Reorder band factors
sar.effects$variable <- factor(sar.effects$variable, 
                               levels = c("pct_tree","pct_notree_veg","vpd_max","bi_max","vs_max",
                                          "slope","chili","lfcbh_avg","lfcbd_avg","aspen_pct"))
  
sar.eff.plot <- ggplot(data=sar.effects,
                       aes(y=variable, x=effect, color=sign,label=round(effect,2))) +
  geom_point() +
  geom_text(vjust="inward",hjust="inward") +
  geom_vline(xintercept=0,color="grey60",size=0.4) +
  labs(x="Estimate") +
  theme_bw(9) +
  theme(legend.position = "none",
        axis.title.y = element_blank())
sar.eff.plot

```

Look at estimates from all models:

```{r}

library(sjPlot)
theme_sjplot(base_size = 7, base_family = "")

sjPlot::tab_model(model.ols, 
                  show.re.var= TRUE)

sjPlot::tab_model(model.ols_ipw, 
                  show.re.var= TRUE)

arrplot <- cowplot::plot_grid(
  plot_model(model.ols,show.values = TRUE, value.offset = .3, vline.color="grey60", title="") + theme_bw(9),
  plot_model(model.ols_ipw,show.values = TRUE, value.offset = .3, vline.color="grey60",title="") + theme_bw(9),
  sar.eff.plot,
  labels = c('A', 'B', 'C'),
  nrow=1, ncol=3
)
arrplot

ggsave(arrplot, file="../../figures/frp/model_effects_grid.png", width=9, height=4)

```


Set up the equation to generate Inverse Probability Weights (IPW) for aspen percentage:

```{r}

# The numerator is the probability distribution of just the treatment variable.
# We'll use a normal distribution for it (hence dnorm()). We need to feed
# dnorm() the grant amount for each person, the predicted value from a simple
# grant ~ 1 model, and the sd of the residuals from that model
model_num <- glm(aspen_prop_c ~ 1, data = model.df_sc)
num <- dnorm(model.df_sc$aspen_prop_c,
             predict(model_num),
             sd(model_num$residuals))

# The denominator is the probability distribution of the treatment variable
# explained by the confounders. We'll again use a normal distribution for it.
# We'll feed dnorm() the grant amount, the predicted value from a model that
# includes the confounders, and the sd of the residuals from that model
model_den <- glm(aspen_prop_c ~ lfcbh_avg + vs_p90 + 
    vpd_p90 + fm1000_p90 + elev_sd + aspect_mean + modis_pct_notree_veg, 
                 data = model.df_sc)
den <- dnorm(model.df_sc$aspen_prop_c,
             predict(model_den),
             sd(model_den$residuals))

model.df_ipw <- model.df_sc %>% 
  mutate(ipw = num / den)

head(model.df_ipw)

rm(num,model_num,model_den)

```

Look at estimates of both models:

Check assumptions:

```{r}
plot(model)
plot(model.ipw)
```

GLMM with nested effects for date/plot:

```{r}

model.df_ipw$day <- as.numeric(model.df_ipw$acq_date)

library(lme4,quietly=T)

model.ipw.glmm <- lmer(log(frp) ~ aspen_prop_c + lfcbh_avg + vs_p90 + 
                          vpd_p90 + fm1000_p90 + elev_sd + aspect_mean + modis_pct_notree_veg + (1|day),
                        data = model.df_ipw, weights=ipw)
summary(model.ipw.glmm)

```

```{r}
cowplot::plot_grid(
  plot_model(model.ipw.glmm,show.values = TRUE, value.offset = .3)+theme_minimal(10),
  plot_model(model.ipw.glmm, "re")+theme_minimal(10)
) +
  theme_bw(10)
```

```{r}
effects_aspen <- effects::effect(term= "aspen_prop_c", mod= model.ipw.glmm)
summary(effects_aspen) #output of what the values are
effects_aspen <- as.data.frame(effects_aspen)
```

```{r}
sjPlot::tab_model(model.ipw.glmm, 
                  show.re.var= TRUE)
```

## SAR Model

Time-series:

```{r}

ts.df <- model.df %>%
  st_set_geometry(NULL) %>% as_tibble() %>%
  select(-c(LATITUDE,LONGITUDE,GID,aspen_noaspen)) %>%
  group_by(acq_date) %>%
  summarize_all(list(mean))

ts.df <- ts.df %>%       
  mutate_at(c("aspen_prop_c", "lfcbd_avg", "lfcbh_avg", "vs_p90", "tmmx_p90",
              "bi_p90", "vpd_p90", "fm1000_p90", "elev_sd", "slope_mean",
              "aspect_mean", "modis_pct_notree_veg", "modis_pct_noveg"), 
            ~(scale(.) %>% as.vector))
glimpse(ts.df)

# # convert to multivariate time-series
# ts.df <- xts(ts.df[,-1], order.by=as.POSIXct(ts.df$acq_date))

```

Create the spatial weights matrix based on nearest neighbor:

```{r}

library(spdep)

coords<-cbind(model.df$LONGITUDE,model.df$LATITUDE)
coords<-as.matrix(coords)

nb <- dnearneigh(coords, 0, 2000, row.names = NULL, longlat = TRUE)
nb.w <- nb2listw(nb, glist=NULL, style="W", zero.policy=FALSE)

```

SAR model:

```{r}

library(spatialreg)
sar.chi <- lagsarlm(log(frp)~ aspen_prop_c + lfcbh_avg + vs_p90 + 
                      vpd_p90 + fm1000_p90 + elev_sd + aspect_mean + modis_pct_notree_veg + 
                      modis_pct_noveg, 
                    data=model.df, nb.w)
summary(sar.chi)

```

